{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vtab_1k\n",
    "\n",
    "> https://google-research.github.io/task_adaptation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://paperswithcode.com/sota/image-classification-on-vtab-1k-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.vtab_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.data.from_ssf.vtab import VtabSplit, VtabDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAIN', 'VAL', 'TEST', 'TRAIN_AND_VAL']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VtabSplit._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset VtabDataset\n",
       "    Number of datapoints: 800\n",
       "    Root location: /home/ycm/datasets/vtab-1k/cifar"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "vtab_dir = \"/home/ycm/datasets/vtab-1k\"\n",
    "subset_name = \"cifar\"\n",
    "train_dataset = VtabDataset(vtab_dir=vtab_dir, subset_name=subset_name, split=VtabSplit.TRAIN)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Union\n",
    "import torchvision.datasets\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "class VTAB_1K(torchvision.datasets.VisionDataset):\n",
    "    mirrors = [\n",
    "        \"https://cloud.tsinghua.edu.cn/d/0d9f3b5787ab4cdab322/?dl=1\",\n",
    "    ]\n",
    "    resources = [\n",
    "        (\"vtab-1k.tar.gz.part1\", \"b567f482832bf98fa20e29c2c11501a7\"),\n",
    "        (\"vtab-1k.tar.gz.part2\", \"700f6ba9c2ddb2beeb707420f89d92b4\"),\n",
    "        (\"vtab-1k.tar.gz.part3\", \"249d036285d9abff1bde741833352b22\"),\n",
    "        (\"vtab-1k.tar.gz.part4\", \"57de07aec66242040573a873604125b9\"),\n",
    "        (\"vtab-1k.tar.gz.part5\", \"3cc060311d5804d0db2985234e0de233\"),\n",
    "    ]\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[str, Path],\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "        if download:\n",
    "            self.download()\n",
    "            \n",
    "    download = MNIST.download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
      "\n",
      "Args:\n",
      "    root (str or ``pathlib.Path``): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\n",
      "        and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
      "        otherwise from ``t10k-images-idx3-ubyte``.\n",
      "    download (bool, optional): If True, downloads the dataset from the internet and\n",
      "        puts it in root directory. If dataset is already downloaded, it is not\n",
      "        downloaded again.\n",
      "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
      "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "    target_transform (callable, optional): A function/transform that takes in the\n",
      "        target and transforms it.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/torchvision/datasets/mnist.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     FashionMNIST, KMNIST, EMNIST, QMNIST"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets\n",
    "torchvision.datasets.MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 4021.10it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5428.93it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5862.49it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5837.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5871.01it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5082.24it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5279.28it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 5430.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 ms ± 7.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bar = tqdm(train_dataset)\n",
    "for i, data in enumerate(bar):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an account on https://lightning.ai/ to optimize your data faster using multiple nodes and large machines.\n",
      "Setting multiprocessing start_method to fork. Tip: Libraries relying on lock can hang with `fork`. To use `spawn` in notebooks, move your code to files and import it within the notebook.\n",
      "Storing the files under /home/ycm/repos/novelties/cv/cls/NamableClassify/src/notebooks/02data/vtab_1k/cifar100/train\n",
      "Setup started with fast_dev_run=False.\n",
      "Setup finished in 0.001 seconds. Found 800 items to process.\n",
      "Starting 4 workers with 800 items. The progress bar is only updated when a worker finishes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers are ready ! Starting data processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae574e51e4a14cf38ccf696839897029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['int', 'pil', 'int']` data format.\n",
      "Rank 1 inferred the following `['int', 'pil', 'int']` data format.Rank 2 inferred the following `['int', 'pil', 'int']` data format.Rank 3 inferred the following `['int', 'pil', 'int']` data format.\n",
      "\n",
      "\n",
      "Worker 0 is terminating.\n",
      "Worker 2 is terminating.Worker 1 is terminating.Worker 3 is terminating.\n",
      "\n",
      "\n",
      "Worker 0 is done.\n",
      "Worker 2 is done.Worker 3 is done.Worker 1 is done.\n",
      "\n",
      "\n",
      "Workers are finished.\n",
      "Finished data processing!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lightning.data import optimize\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Store random images into the chunks\n",
    "def images(index):\n",
    "    data = {\n",
    "        \"index\": index,\n",
    "        \"image\": train_dataset[index][0],\n",
    "        \"class\": train_dataset[index][1],\n",
    "    }\n",
    "    return data # The data is serialized into bytes and stored into chunks by the optimize operator.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimize(\n",
    "        fn=images,  # The function applied over each input.\n",
    "        inputs=list(range(len(train_dataset))),  # Provide any inputs. The fn is applied on each item.\n",
    "        output_dir=\"vtab_1k/cifar100/train\",  # The directory where the optimized data are stored.\n",
    "        num_workers=4,  # The number of workers. The inputs are distributed among them.\n",
    "        chunk_bytes=\"64MB\"  # The maximum number of bytes to write into a chunk.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.data import StreamingDataset\n",
    "lit_dataset = StreamingDataset(input_dir=\"vtab_1k/cifar100/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 6842.75it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6390.35it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6951.89it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7317.17it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7097.98it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6737.78it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6773.30it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7156.34it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6963.54it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7626.63it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8177.07it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7458.07it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7268.98it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7362.77it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8004.57it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8011.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8455.94it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7245.63it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6537.63it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7011.00it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7376.29it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8022.41it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7763.83it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8278.97it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8326.35it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8054.06it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8209.80it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8080.65it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8086.59it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7640.05it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6804.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7207.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7247.49it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8313.78it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8259.15it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8495.80it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8046.74it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8102.47it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8102.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8019.13it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8000.66it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8228.74it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8228.91it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8113.73it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7055.15it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7661.20it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8274.67it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8107.09it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8415.39it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8498.08it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8342.02it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8259.92it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8351.96it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8449.74it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8338.45it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8180.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8295.80it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6971.77it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6812.20it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7665.01it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8082.46it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8146.85it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8075.33it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8098.21it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8175.53it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8209.38it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8127.69it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7062.95it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7423.55it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7418.23it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8406.85it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8474.60it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8399.46it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8367.00it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8205.44it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8563.06it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8373.54it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8506.06it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8462.96it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8748.84it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8319.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 ms ± 3.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bar = tqdm(lit_dataset)\n",
    "for i, data in enumerate(bar):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
