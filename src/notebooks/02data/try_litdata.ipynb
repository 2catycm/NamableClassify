{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an account on https://lightning.ai/ to optimize your data faster using multiple nodes and large machines.\n",
      "Setting multiprocessing start_method to fork. Tip: Libraries relying on lock can hang with `fork`. To use `spawn` in notebooks, move your code to files and import it within the notebook.\n",
      "Storing the files under /home/ycm/repos/novelties/cv/cls/NamableClassify/src/notebooks/02data/my_dataset\n",
      "Setup started with fast_dev_run=False.\n",
      "Setup finished in 0.002 seconds. Found 1000 items to process.\n",
      "Starting 4 workers with 1000 items. The progress bar is only updated when a worker finishes.\n",
      "Workers are ready ! Starting data processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c1135af8e840da877068660a5246be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['int', 'pil', 'int']` data format.Rank 2 inferred the following `['int', 'pil', 'int']` data format.Rank 2 inferred the following `['int', 'pil', 'int']` data format.Rank 1 inferred the following `['int', 'pil', 'int']` data format.\n",
      "\n",
      "\n",
      "Rank 3 inferred the following `['int', 'pil', 'int']` data format.\n",
      "Worker 2 is terminating.Worker 0 is terminating.Worker 1 is terminating.\n",
      "\n",
      "\n",
      "Worker 3 is terminating.\n",
      "Worker 0 is done.Worker 2 is done.Worker 1 is done.\n",
      "\n",
      "\n",
      "Worker 3 is done.\n",
      "Workers are finished.\n",
      "Finished data processing!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lightning.data import optimize\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Store random images into the chunks\n",
    "def random_images(index):\n",
    "    data = {\n",
    "        \"index\": index,\n",
    "        \"image\": Image.fromarray(np.random.randint(0, 256, (32, 32, 3), np.uint8)),\n",
    "        \"class\": np.random.randint(10),\n",
    "    }\n",
    "    return data # The data is serialized into bytes and stored into chunks by the optimize operator.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimize(\n",
    "        fn=random_images,  # The function applied over each input.\n",
    "        inputs=list(range(1000)),  # Provide any inputs. The fn is applied on each item.\n",
    "        output_dir=\"my_dataset\",  # The directory where the optimized data are stored.\n",
    "        num_workers=4,  # The number of workers. The inputs are distributed among them.\n",
    "        chunk_bytes=\"64MB\"  # The maximum number of bytes to write into a chunk.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "from lightning.data import StreamingDataset\n",
    "\n",
    "dataset = StreamingDataset(input_dir=\"output_dir\")\n",
    "\n",
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4],\n",
      "        [4, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import thunder\n",
    "\n",
    "\n",
    "def foo(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "jfoo = thunder.jit(foo)\n",
    "\n",
    "a = torch.full((2, 2), 1)\n",
    "b = torch.full((2, 2), 3)\n",
    "\n",
    "result = jfoo(a, b)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# prints\n",
    "# tensor(\n",
    "#  [[4, 4]\n",
    "#   [4, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.9 μs ± 2.32 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "cfoo = torch.compile(foo)\n",
    "result = cfoo(a, b)\n",
    "%timeit cfoo(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 μs ± 2.15 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jfoo(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 μs ± 42.6 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit foo(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Constructed by Unwrap the actual return value\n",
      "import torch\n",
      "from thunder.executors.torchex import no_autocast\n",
      "\n",
      "@torch.no_grad()\n",
      "@no_autocast\n",
      "def computation(a, b):\n",
      "  # a: \"cpu i64[2, 2]\"\n",
      "  # b: \"cpu i64[2, 2]\"\n",
      "  t0 = torch.add(a, b, alpha=1)  # t0: \"cpu i64[2, 2]\"\n",
      "  return t0\n"
     ]
    }
   ],
   "source": [
    "forward_trace = thunder.last_traces(jfoo)[-1].python()\n",
    "print(forward_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-02 18:18:53,148] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/home_program_files/miniconda3/envs/fastai/bin/../lib/gcc/x86_64-conda-linux-gnu/14.1.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ycm/home_program_files/miniconda3/envs/fastai/bin/../lib/gcc/x86_64-conda-linux-gnu/14.1.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "waver = AutoModel.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-3.3025,  2.8405, -0.7017,  ...,  3.1342, -2.1901, -0.5218],\n",
       "         [ 4.5429,  1.4459,  0.3152,  ..., -0.2648, -0.1555,  4.5015],\n",
       "         [-0.2858, -2.4147,  4.4447,  ...,  0.6189, -0.2994,  3.0078],\n",
       "         ...,\n",
       "         [-1.7849,  0.6872,  0.4351,  ..., -0.3587, -3.2702,  4.9222],\n",
       "         [-0.3610, -1.0604,  1.3458,  ...,  7.5843, -1.9183, -4.2016],\n",
       "         [ 4.6024,  1.4617,  0.3085,  ..., -0.2763, -0.1641,  4.4907]],\n",
       "\n",
       "        [[-1.1080,  1.5895, -0.3872,  ...,  2.8872, -3.5670, -0.5306],\n",
       "         [ 4.5562,  1.5344,  0.3976,  ..., -0.1860, -0.2100,  4.4941],\n",
       "         [-0.9599,  4.5433, -1.3830,  ...,  0.4129, -0.8785, -1.9705],\n",
       "         ...,\n",
       "         [-3.2645,  5.4202, -2.4858,  ..., 10.9160, -2.7958,  5.3014],\n",
       "         [ 0.7531,  1.0529,  1.4106,  ...,  6.5194, -4.0522,  3.5646],\n",
       "         [ 4.5706,  1.4622,  0.2558,  ..., -0.3123, -0.1581,  4.4838]],\n",
       "\n",
       "        [[-2.4171,  1.9071, -0.2706,  ...,  2.8857, -2.4634,  0.7375],\n",
       "         [ 4.5971,  1.5091,  0.2894,  ..., -0.1104, -0.1489,  4.4905],\n",
       "         [-5.8262,  2.6045,  3.7026,  ...,  0.7254, -1.0343,  5.0710],\n",
       "         ...,\n",
       "         [-4.6536,  3.8988,  0.1406,  ...,  9.6346, -1.0801, 11.1718],\n",
       "         [-1.6042, -1.4435,  4.1817,  ..., -0.0678, -3.4931,  3.7237],\n",
       "         [ 4.6857,  1.4782,  0.2434,  ..., -0.2591, -0.1375,  4.4900]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4372,  2.5577, -0.4660,  ...,  2.4660, -2.7434, -1.3364],\n",
       "         [ 4.5552,  1.4706,  0.3129,  ..., -0.2636, -0.1240,  4.4069],\n",
       "         [-3.5237,  7.4659, -4.1596,  ..., -0.4318, -1.8162, -5.4958],\n",
       "         ...,\n",
       "         [ 1.5210, -3.3591, -0.8129,  ..., -1.7165, -4.5610,  0.5474],\n",
       "         [-5.8159,  0.9328,  2.8894,  ..., -0.0365, -3.5485,  1.9335],\n",
       "         [ 4.5756,  1.4450,  0.2504,  ..., -0.3382, -0.1762,  4.4657]],\n",
       "\n",
       "        [[-2.8359,  2.0014, -0.8466,  ...,  3.7107, -2.1237, -1.0213],\n",
       "         [ 4.5596,  1.4586,  0.2579,  ..., -0.2477, -0.1229,  4.4832],\n",
       "         [-4.5037,  2.1903,  0.2716,  ...,  6.4734, -0.9823,  3.4082],\n",
       "         ...,\n",
       "         [-1.5158,  0.7279, -1.0893,  ...,  5.3705, -2.6731,  2.9078],\n",
       "         [-6.3516,  2.7355,  3.5235,  ...,  0.8604, -6.3928,  3.8458],\n",
       "         [ 4.5970,  1.4604,  0.2802,  ..., -0.2466, -0.1089,  4.4556]],\n",
       "\n",
       "        [[-1.2522,  1.6512, -0.0926,  ...,  2.3970, -2.9169,  0.5315],\n",
       "         [ 4.6205,  1.4739,  0.3091,  ..., -0.2014, -0.1269,  4.5158],\n",
       "         [-3.2977,  4.4096, -2.7455,  ...,  1.3435,  3.7285, -5.4613],\n",
       "         ...,\n",
       "         [ 1.0834, -2.5058,  0.8151,  ..., -0.0246, -4.6200,  6.0776],\n",
       "         [ 0.1731,  0.8988,  4.3087,  ...,  1.3096, -2.0204, -1.3821],\n",
       "         [ 4.7197,  1.4847,  0.2515,  ..., -0.2850, -0.1114,  4.4650]]],\n",
       "       device='cuda:0', grad_fn=<ThunderFunctionBackward>), pooler_output=tensor([[-0.4006,  0.5210, -0.4806,  ..., -0.6595, -0.7650,  0.6078],\n",
       "        [-0.4345,  0.5118, -0.3038,  ..., -0.5918, -0.8504,  0.3830],\n",
       "        [-0.4280,  0.3827, -0.2940,  ..., -0.4921, -0.9018,  0.5553],\n",
       "        ...,\n",
       "        [-0.2674,  0.5529, -0.3919,  ..., -0.6565, -0.7561,  0.6611],\n",
       "        [-0.4433,  0.5676, -0.2559,  ..., -0.7277, -0.7647,  0.5048],\n",
       "        [-0.4425,  0.4026, -0.1793,  ..., -0.4023, -0.9031,  0.4237]],\n",
       "       device='cuda:0', grad_fn=<ThunderFunctionBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jwaver = thunder.jit(waver)\n",
    "jwaver(torch.randn(10, 3, 224, 224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-2.2590e+00,  1.7578e+00, -7.3131e-01,  ...,  2.9966e+00,\n",
       "          -2.0744e+00, -7.8527e-01],\n",
       "         [ 4.6210e+00,  1.4167e+00,  3.1339e-01,  ..., -2.6328e-01,\n",
       "          -9.8359e-02,  4.4552e+00],\n",
       "         [-4.1646e+00, -1.6913e+00,  3.1243e+00,  ...,  8.5702e-01,\n",
       "          -1.0600e+00,  3.9907e-01],\n",
       "         ...,\n",
       "         [ 3.2548e+00, -3.2518e+00,  3.6374e-01,  ...,  4.6018e+00,\n",
       "          -2.6716e+00,  2.3575e+00],\n",
       "         [-4.4710e+00,  1.6181e+00, -1.0101e+00,  ...,  5.7543e+00,\n",
       "           8.4177e-01,  5.1077e+00],\n",
       "         [ 4.5062e+00,  1.4906e+00,  2.5597e-01,  ..., -2.8433e-01,\n",
       "          -2.1718e-01,  4.6268e+00]],\n",
       "\n",
       "        [[-1.5436e+00,  2.8625e+00, -7.5964e-01,  ...,  3.3870e+00,\n",
       "          -2.6895e+00, -1.4310e+00],\n",
       "         [ 4.6498e+00,  1.4954e+00,  2.9299e-01,  ..., -2.6039e-01,\n",
       "          -1.5948e-01,  4.3655e+00],\n",
       "         [ 4.4695e+00,  1.4990e+00,  3.7191e-01,  ..., -4.2178e-02,\n",
       "          -2.9419e-01,  4.4411e+00],\n",
       "         ...,\n",
       "         [ 4.2313e+00,  1.0352e+00,  3.3717e+00,  ...,  2.0784e+00,\n",
       "          -9.1586e-01,  1.2744e+01],\n",
       "         [-9.0980e-01,  1.8272e-01, -5.9715e-01,  ...,  2.9617e+00,\n",
       "          -4.6600e+00,  6.5463e+00],\n",
       "         [ 4.5938e+00,  1.4249e+00,  2.6870e-01,  ..., -2.8153e-01,\n",
       "          -1.8455e-01,  4.5529e+00]],\n",
       "\n",
       "        [[-1.1871e+00,  2.7701e+00, -3.3929e-01,  ...,  3.1911e+00,\n",
       "          -2.3772e+00,  9.0224e-01],\n",
       "         [ 4.5673e+00,  1.5005e+00,  2.7538e-01,  ..., -1.8274e-01,\n",
       "          -1.2156e-01,  4.3837e+00],\n",
       "         [ 7.6161e-01, -3.0042e+00,  2.9155e-01,  ...,  2.8136e+00,\n",
       "          -3.6297e+00, -1.5371e+00],\n",
       "         ...,\n",
       "         [ 2.0380e+00, -4.0271e-01, -1.1190e+00,  ...,  5.9748e+00,\n",
       "          -3.8461e+00,  7.2498e+00],\n",
       "         [ 4.8361e+00,  4.4398e-01,  5.5189e-01,  ..., -3.1654e-01,\n",
       "          -5.0080e+00,  2.9414e+00],\n",
       "         [ 4.5915e+00,  1.4875e+00,  2.6323e-01,  ..., -2.5022e-01,\n",
       "          -2.2116e-01,  4.6468e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6489e+00,  2.0460e+00, -1.3092e+00,  ...,  3.0448e+00,\n",
       "          -2.5178e+00, -3.9585e-01],\n",
       "         [ 4.5128e+00,  1.4737e+00,  3.1015e-01,  ..., -1.4773e-01,\n",
       "          -7.0861e-02,  4.4588e+00],\n",
       "         [-3.2443e+00, -2.2360e-01,  1.9996e-01,  ..., -6.9380e-01,\n",
       "          -1.5046e+00,  4.0667e+00],\n",
       "         ...,\n",
       "         [-8.4966e-01,  4.2686e+00,  2.5372e+00,  ...,  2.2681e+00,\n",
       "          -3.9753e+00,  1.4985e+00],\n",
       "         [-2.2670e+00, -2.2081e+00, -4.1326e+00,  ...,  3.7083e+00,\n",
       "          -7.8349e-01,  5.5215e+00],\n",
       "         [ 4.5616e+00,  1.4794e+00,  2.7235e-01,  ..., -2.4470e-01,\n",
       "          -1.7234e-01,  4.5331e+00]],\n",
       "\n",
       "        [[-1.5044e+00,  2.8035e+00, -7.6442e-01,  ...,  3.5411e+00,\n",
       "          -2.1033e+00, -1.4980e+00],\n",
       "         [ 4.5025e+00,  1.4363e+00,  3.3772e-01,  ..., -1.8297e-01,\n",
       "          -1.0901e-01,  4.4038e+00],\n",
       "         [-1.4105e+00,  7.0813e+00, -8.1172e-01,  ...,  8.7928e+00,\n",
       "          -5.0841e+00,  5.3513e+00],\n",
       "         ...,\n",
       "         [ 4.9700e-01,  1.6885e+00, -5.6963e+00,  ...,  6.4635e+00,\n",
       "          -7.5882e-01,  1.1187e+00],\n",
       "         [ 2.8607e+00, -2.5046e+00,  4.1664e+00,  ..., -1.7256e+00,\n",
       "           7.5034e-03,  1.6479e+00],\n",
       "         [ 4.6087e+00,  1.4694e+00,  2.4182e-01,  ..., -2.6974e-01,\n",
       "          -1.1869e-01,  4.4784e+00]],\n",
       "\n",
       "        [[-1.7486e+00,  2.4140e+00, -2.9812e-01,  ...,  2.4633e+00,\n",
       "          -2.4518e+00,  1.6995e+00],\n",
       "         [ 4.5993e+00,  1.4641e+00,  3.4287e-01,  ..., -2.6973e-01,\n",
       "          -9.2206e-02,  4.5608e+00],\n",
       "         [-6.8225e+00,  1.5248e+00,  1.9316e+00,  ...,  1.6288e+00,\n",
       "          -2.6043e+00, -3.0923e+00],\n",
       "         ...,\n",
       "         [-7.5337e+00,  5.6354e+00, -8.6891e-01,  ...,  4.3114e+00,\n",
       "           2.1802e+00,  2.6040e+00],\n",
       "         [-3.1910e+00,  1.9929e+00,  1.4879e+00,  ..., -7.5405e-01,\n",
       "          -4.9486e-01,  5.0174e+00],\n",
       "         [ 4.6136e+00,  1.5455e+00,  2.6614e-01,  ..., -2.5581e-01,\n",
       "          -1.9608e-01,  4.6048e+00]]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-0.4566,  0.4518, -0.2602,  ..., -0.5681, -0.7849,  0.4856],\n",
       "        [-0.4281,  0.5847, -0.4643,  ..., -0.6895, -0.7848,  0.7149],\n",
       "        [-0.4339,  0.4531, -0.2389,  ..., -0.5634, -0.8737,  0.5794],\n",
       "        ...,\n",
       "        [-0.4885,  0.4212, -0.2907,  ..., -0.6861, -0.8332,  0.4407],\n",
       "        [-0.4319,  0.4155, -0.2663,  ..., -0.7319, -0.8441,  0.4110],\n",
       "        [ 0.0057,  0.3747, -0.2461,  ..., -0.5682, -0.8724,  0.3958]],\n",
       "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwaver = torch.compile(waver)\n",
    "cwaver(torch.randn(10, 3, 224, 224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.8 ms ± 1.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit waver(torch.randn(10, 3, 224, 224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 ms ± 254 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cwaver(torch.randn(10, 3, 224, 224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 ms ± 1.45 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jwaver(torch.randn(10, 3, 224, 224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Constructed by Delete Last Used (took 10 milliseconds)\n",
      "import torch\n",
      "import torch.nn.functional\n",
      "from thunder.executors.torchex import no_autocast\n",
      "\n",
      "@torch.no_grad()\n",
      "@no_autocast\n",
      "def computation(pixel_values, t_embeddings_cls_token, bias, weight, t_embeddings_position_embeddings, t_encoder_layer_0_attention_attention_key_bias, t_encoder_layer_0_attention_attention_key_weight, t_encoder_layer_0_attention_attention_query_bias, t_encoder_layer_0_attention_attention_query_weight, t_encoder_layer_0_attention_attention_value_bias, t_encoder_layer_0_attention_attention_value_weight, t_encoder_layer_0_attention_output_dense_bias, t_encoder_layer_0_attention_output_dense_weight, t_encoder_layer_0_intermediate_dense_bias, t_encoder_layer_0_intermediate_dense_weight, t_encoder_layer_0_layernorm_after_bias, t_encoder_layer_0_layernorm_after_weight, t_encoder_layer_0_layernorm_before_bias, t_encoder_layer_0_layernorm_before_weight, t_encoder_layer_0_output_dense_bias, t_encoder_layer_0_output_dense_weight, t_encoder_layer_1_attention_attention_key_bias, t_encoder_layer_1_attention_attention_key_weight, t_encoder_layer_1_attention_attention_query_bias, t_encoder_layer_1_attention_attention_query_weight, t_encoder_layer_1_attention_attention_value_bias, t_encoder_layer_1_attention_attention_value_weight, t_encoder_layer_1_attention_output_dense_bias, t_encoder_layer_1_attention_output_dense_weight, t_encoder_layer_1_intermediate_dense_bias, t_encoder_layer_1_intermediate_dense_weight, t_encoder_layer_1_layernorm_after_bias, t_encoder_layer_1_layernorm_after_weight, t_encoder_layer_1_layernorm_before_bias, t_encoder_layer_1_layernorm_before_weight, t_encoder_layer_1_output_dense_bias, t_encoder_layer_1_output_dense_weight, t_encoder_layer_2_attention_attention_key_bias, t_encoder_layer_2_attention_attention_key_weight, t_encoder_layer_2_attention_attention_query_bias, t_encoder_layer_2_attention_attention_query_weight, t_encoder_layer_2_attention_attention_value_bias, t_encoder_layer_2_attention_attention_value_weight, t_encoder_layer_2_attention_output_dense_bias, t_encoder_layer_2_attention_output_dense_weight, t_encoder_layer_2_intermediate_dense_bias, t_encoder_layer_2_intermediate_dense_weight, t_encoder_layer_2_layernorm_after_bias, t_encoder_layer_2_layernorm_after_weight, t_encoder_layer_2_layernorm_before_bias, t_encoder_layer_2_layernorm_before_weight, t_encoder_layer_2_output_dense_bias, t_encoder_layer_2_output_dense_weight, t_encoder_layer_3_attention_attention_key_bias, t_encoder_layer_3_attention_attention_key_weight, t_encoder_layer_3_attention_attention_query_bias, t_encoder_layer_3_attention_attention_query_weight, t_encoder_layer_3_attention_attention_value_bias, t_encoder_layer_3_attention_attention_value_weight, t_encoder_layer_3_attention_output_dense_bias, t_encoder_layer_3_attention_output_dense_weight, t_encoder_layer_3_intermediate_dense_bias, t_encoder_layer_3_intermediate_dense_weight, t_encoder_layer_3_layernorm_after_bias, t_encoder_layer_3_layernorm_after_weight, t_encoder_layer_3_layernorm_before_bias, t_encoder_layer_3_layernorm_before_weight, t_encoder_layer_3_output_dense_bias, t_encoder_layer_3_output_dense_weight, t_encoder_layer_4_attention_attention_key_bias, t_encoder_layer_4_attention_attention_key_weight, t_encoder_layer_4_attention_attention_query_bias, t_encoder_layer_4_attention_attention_query_weight, t_encoder_layer_4_attention_attention_value_bias, t_encoder_layer_4_attention_attention_value_weight, t_encoder_layer_4_attention_output_dense_bias, t_encoder_layer_4_attention_output_dense_weight, t_encoder_layer_4_intermediate_dense_bias, t_encoder_layer_4_intermediate_dense_weight, t_encoder_layer_4_layernorm_after_bias, t_encoder_layer_4_layernorm_after_weight, t_encoder_layer_4_layernorm_before_bias, t_encoder_layer_4_layernorm_before_weight, t_encoder_layer_4_output_dense_bias, t_encoder_layer_4_output_dense_weight, t_encoder_layer_5_attention_attention_key_bias, t_encoder_layer_5_attention_attention_key_weight, t_encoder_layer_5_attention_attention_query_bias, t_encoder_layer_5_attention_attention_query_weight, t_encoder_layer_5_attention_attention_value_bias, t_encoder_layer_5_attention_attention_value_weight, t_encoder_layer_5_attention_output_dense_bias, t_encoder_layer_5_attention_output_dense_weight, t_encoder_layer_5_intermediate_dense_bias, t_encoder_layer_5_intermediate_dense_weight, t_encoder_layer_5_layernorm_after_bias, t_encoder_layer_5_layernorm_after_weight, t_encoder_layer_5_layernorm_before_bias, t_encoder_layer_5_layernorm_before_weight, t_encoder_layer_5_output_dense_bias, t_encoder_layer_5_output_dense_weight, t_encoder_layer_6_attention_attention_key_bias, t_encoder_layer_6_attention_attention_key_weight, t_encoder_layer_6_attention_attention_query_bias, t_encoder_layer_6_attention_attention_query_weight, t_encoder_layer_6_attention_attention_value_bias, t_encoder_layer_6_attention_attention_value_weight, t_encoder_layer_6_attention_output_dense_bias, t_encoder_layer_6_attention_output_dense_weight, t_encoder_layer_6_intermediate_dense_bias, t_encoder_layer_6_intermediate_dense_weight, t_encoder_layer_6_layernorm_after_bias, t_encoder_layer_6_layernorm_after_weight, t_encoder_layer_6_layernorm_before_bias, t_encoder_layer_6_layernorm_before_weight, t_encoder_layer_6_output_dense_bias, t_encoder_layer_6_output_dense_weight, t_encoder_layer_7_attention_attention_key_bias, t_encoder_layer_7_attention_attention_key_weight, t_encoder_layer_7_attention_attention_query_bias, t_encoder_layer_7_attention_attention_query_weight, t_encoder_layer_7_attention_attention_value_bias, t_encoder_layer_7_attention_attention_value_weight, t_encoder_layer_7_attention_output_dense_bias, t_encoder_layer_7_attention_output_dense_weight, t_encoder_layer_7_intermediate_dense_bias, t_encoder_layer_7_intermediate_dense_weight, t_encoder_layer_7_layernorm_after_bias, t_encoder_layer_7_layernorm_after_weight, t_encoder_layer_7_layernorm_before_bias, t_encoder_layer_7_layernorm_before_weight, t_encoder_layer_7_output_dense_bias, t_encoder_layer_7_output_dense_weight, t_encoder_layer_8_attention_attention_key_bias, t_encoder_layer_8_attention_attention_key_weight, t_encoder_layer_8_attention_attention_query_bias, t_encoder_layer_8_attention_attention_query_weight, t_encoder_layer_8_attention_attention_value_bias, t_encoder_layer_8_attention_attention_value_weight, t_encoder_layer_8_attention_output_dense_bias, t_encoder_layer_8_attention_output_dense_weight, t_encoder_layer_8_intermediate_dense_bias, t_encoder_layer_8_intermediate_dense_weight, t_encoder_layer_8_layernorm_after_bias, t_encoder_layer_8_layernorm_after_weight, t_encoder_layer_8_layernorm_before_bias, t_encoder_layer_8_layernorm_before_weight, t_encoder_layer_8_output_dense_bias, t_encoder_layer_8_output_dense_weight, t_encoder_layer_9_attention_attention_key_bias, t_encoder_layer_9_attention_attention_key_weight, t_encoder_layer_9_attention_attention_query_bias, t_encoder_layer_9_attention_attention_query_weight, t_encoder_layer_9_attention_attention_value_bias, t_encoder_layer_9_attention_attention_value_weight, t_encoder_layer_9_attention_output_dense_bias, t_encoder_layer_9_attention_output_dense_weight, t_encoder_layer_9_intermediate_dense_bias, t_encoder_layer_9_intermediate_dense_weight, t_encoder_layer_9_layernorm_after_bias, t_encoder_layer_9_layernorm_after_weight, t_encoder_layer_9_layernorm_before_bias, t_encoder_layer_9_layernorm_before_weight, t_encoder_layer_9_output_dense_bias, t_encoder_layer_9_output_dense_weight, t_encoder_layer_10_attention_attention_key_bias, t_encoder_layer_10_attention_attention_key_weight, t_encoder_layer_10_attention_attention_query_bias, t_encoder_layer_10_attention_attention_query_weight, t_encoder_layer_10_attention_attention_value_bias, t_encoder_layer_10_attention_attention_value_weight, t_encoder_layer_10_attention_output_dense_bias, t_encoder_layer_10_attention_output_dense_weight, t_encoder_layer_10_intermediate_dense_bias, t_encoder_layer_10_intermediate_dense_weight, t_encoder_layer_10_layernorm_after_bias, t_encoder_layer_10_layernorm_after_weight, t_encoder_layer_10_layernorm_before_bias, t_encoder_layer_10_layernorm_before_weight, t_encoder_layer_10_output_dense_bias, t_encoder_layer_10_output_dense_weight, t_encoder_layer_11_attention_attention_key_bias, t_encoder_layer_11_attention_attention_key_weight, t_encoder_layer_11_attention_attention_query_bias, t_encoder_layer_11_attention_attention_query_weight, t_encoder_layer_11_attention_attention_value_bias, t_encoder_layer_11_attention_attention_value_weight, t_encoder_layer_11_attention_output_dense_bias, t_encoder_layer_11_attention_output_dense_weight, t_encoder_layer_11_intermediate_dense_bias, t_encoder_layer_11_intermediate_dense_weight, t_encoder_layer_11_layernorm_after_bias, t_encoder_layer_11_layernorm_after_weight, t_encoder_layer_11_layernorm_before_bias, t_encoder_layer_11_layernorm_before_weight, t_encoder_layer_11_output_dense_bias, t_encoder_layer_11_output_dense_weight, t_layernorm_bias, t_layernorm_weight, t_pooler_dense_bias, t_pooler_dense_weight):\n",
      "  # pixel_values: \"cuda:0 f32[10, 3, 224, 224]\"\n",
      "  # t_embeddings_cls_token: \"cuda:0 f32[1, 1, 192]\"\n",
      "  # bias: \"cuda:0 f32[192]\"\n",
      "  # weight: \"cuda:0 f32[192, 3, 16, 16]\"\n",
      "  # t_embeddings_position_embeddings: \"cuda:0 f32[1, 197, 192]\"\n",
      "  # t_encoder_layer_0_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_0_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_0_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_0_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_0_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_0_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_0_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_0_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_1_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_1_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_1_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_1_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_1_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_1_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_1_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_1_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_2_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_2_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_2_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_2_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_2_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_2_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_2_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_2_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_3_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_3_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_3_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_3_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_3_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_3_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_3_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_3_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_4_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_4_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_4_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_4_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_4_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_4_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_4_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_4_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_5_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_5_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_5_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_5_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_5_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_5_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_5_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_5_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_6_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_6_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_6_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_6_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_6_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_6_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_6_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_6_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_7_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_7_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_7_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_7_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_7_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_7_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_7_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_7_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_8_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_8_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_8_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_8_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_8_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_8_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_8_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_8_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_9_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_9_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_9_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_9_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_9_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_9_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_9_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_9_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_10_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_10_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_10_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_10_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_10_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_10_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_10_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_10_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_encoder_layer_11_attention_attention_key_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_attention_attention_key_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_11_attention_attention_query_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_attention_attention_query_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_11_attention_attention_value_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_attention_attention_value_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_11_attention_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_attention_output_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  # t_encoder_layer_11_intermediate_dense_bias: \"cuda:0 f32[768]\"\n",
      "  # t_encoder_layer_11_intermediate_dense_weight: \"cuda:0 f32[768, 192]\"\n",
      "  # t_encoder_layer_11_layernorm_after_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_layernorm_after_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_layernorm_before_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_layernorm_before_weight: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_output_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_encoder_layer_11_output_dense_weight: \"cuda:0 f32[192, 768]\"\n",
      "  # t_layernorm_bias: \"cuda:0 f32[192]\"\n",
      "  # t_layernorm_weight: \"cuda:0 f32[192]\"\n",
      "  # t_pooler_dense_bias: \"cuda:0 f32[192]\"\n",
      "  # t_pooler_dense_weight: \"cuda:0 f32[192, 192]\"\n",
      "  t33 = torch.convolution(pixel_values, weight, bias, (16, 16), (0, 0), (1, 1), False, (0, 0), 1)  # t33: \"cuda:0 f32[10, 192, 14, 14]\"\n",
      "  [input] = TorchCompile0(t33, t_embeddings_cls_token, t_embeddings_position_embeddings)\n",
      "  del t33\n",
      "  [t1675, t1679, hidden_states] = nvFusion0(input, t_encoder_layer_0_layernorm_before_weight, t_encoder_layer_0_layernorm_before_bias)\n",
      "  mixed_query_layer = torch.nn.functional.linear(hidden_states, t_encoder_layer_0_attention_attention_query_weight, t_encoder_layer_0_attention_attention_query_bias)  # mixed_query_layer: \"cuda:0 f32[10, 197, 192]\"\n",
      "  x = torch.nn.functional.linear(hidden_states, t_encoder_layer_0_attention_attention_key_weight, t_encoder_layer_0_attention_attention_key_bias)  # x: \"cuda:0 f32[10, 197, 192]\"\n",
      "  a = torch.nn.functional.linear(hidden_states, t_encoder_layer_0_attention_attention_value_weight, t_encoder_layer_0_attention_attention_value_bias)  # a: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [value_layer, query_layer, t103] = nvFusion1(x, a, mixed_query_layer)\n",
      "  del x, a, mixed_query_layer\n",
      "  attention_scores = torch.matmul(query_layer, t103)  # attention_scores: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [attention_probs] = nvFusion2(attention_scores)\n",
      "  del attention_scores\n",
      "  context_layer = torch.matmul(attention_probs, value_layer)  # context_layer: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t122] = nvFusion3(context_layer)\n",
      "  del context_layer\n",
      "  attention_output = torch.nn.functional.linear(t122, t_encoder_layer_0_attention_output_dense_weight, t_encoder_layer_0_attention_output_dense_bias)  # attention_output: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [input_tensor, t1736, t1741, layer_output] = nvFusion4(attention_output, input, t_encoder_layer_0_layernorm_after_weight, t_encoder_layer_0_layernorm_after_bias)\n",
      "  del attention_output\n",
      "  t162 = torch.nn.functional.linear(layer_output, t_encoder_layer_0_intermediate_dense_weight, t_encoder_layer_0_intermediate_dense_bias)  # t162: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t167] = nvFusion5(t162)\n",
      "  t174 = torch.nn.functional.linear(t167, t_encoder_layer_0_output_dense_weight, t_encoder_layer_0_output_dense_bias)  # t174: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t178, t1763, t1768, t204] = nvFusion6(t174, input_tensor, t_encoder_layer_1_layernorm_before_weight, t_encoder_layer_1_layernorm_before_bias)\n",
      "  del t174\n",
      "  t216 = torch.nn.functional.linear(t204, t_encoder_layer_1_attention_attention_query_weight, t_encoder_layer_1_attention_attention_query_bias)  # t216: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t221 = torch.nn.functional.linear(t204, t_encoder_layer_1_attention_attention_key_weight, t_encoder_layer_1_attention_attention_key_bias)  # t221: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t230 = torch.nn.functional.linear(t204, t_encoder_layer_1_attention_attention_value_weight, t_encoder_layer_1_attention_attention_value_bias)  # t230: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t232, t234, t235] = nvFusion7(t221, t230, t216)\n",
      "  del t221, t230, t216\n",
      "  t236 = torch.matmul(t234, t235)  # t236: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t246] = nvFusion8(t236)\n",
      "  del t236\n",
      "  t250 = torch.matmul(t246, t232)  # t250: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t254] = nvFusion9(t250)\n",
      "  del t250\n",
      "  t261 = torch.nn.functional.linear(t254, t_encoder_layer_1_attention_output_dense_weight, t_encoder_layer_1_attention_output_dense_bias)  # t261: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t265, t1843, t1848, t287] = nvFusion10(t261, t178, t_encoder_layer_1_layernorm_after_weight, t_encoder_layer_1_layernorm_after_bias)\n",
      "  del t261\n",
      "  t294 = torch.nn.functional.linear(t287, t_encoder_layer_1_intermediate_dense_weight, t_encoder_layer_1_intermediate_dense_bias)  # t294: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t299] = nvFusion11(t294)\n",
      "  t306 = torch.nn.functional.linear(t299, t_encoder_layer_1_output_dense_weight, t_encoder_layer_1_output_dense_bias)  # t306: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t310, t1873, t1878, t336] = nvFusion12(t306, t265, t_encoder_layer_2_layernorm_before_weight, t_encoder_layer_2_layernorm_before_bias)\n",
      "  del t306\n",
      "  t348 = torch.nn.functional.linear(t336, t_encoder_layer_2_attention_attention_query_weight, t_encoder_layer_2_attention_attention_query_bias)  # t348: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t353 = torch.nn.functional.linear(t336, t_encoder_layer_2_attention_attention_key_weight, t_encoder_layer_2_attention_attention_key_bias)  # t353: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t362 = torch.nn.functional.linear(t336, t_encoder_layer_2_attention_attention_value_weight, t_encoder_layer_2_attention_attention_value_bias)  # t362: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t364, t366, t367] = nvFusion13(t353, t362, t348)\n",
      "  del t353, t362, t348\n",
      "  t368 = torch.matmul(t366, t367)  # t368: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t378] = nvFusion14(t368)\n",
      "  del t368\n",
      "  t382 = torch.matmul(t378, t364)  # t382: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t386] = nvFusion15(t382)\n",
      "  del t382\n",
      "  t393 = torch.nn.functional.linear(t386, t_encoder_layer_2_attention_output_dense_weight, t_encoder_layer_2_attention_output_dense_bias)  # t393: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t397, t1953, t1958, t419] = nvFusion16(t393, t310, t_encoder_layer_2_layernorm_after_weight, t_encoder_layer_2_layernorm_after_bias)\n",
      "  del t393\n",
      "  t426 = torch.nn.functional.linear(t419, t_encoder_layer_2_intermediate_dense_weight, t_encoder_layer_2_intermediate_dense_bias)  # t426: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t431] = nvFusion17(t426)\n",
      "  t438 = torch.nn.functional.linear(t431, t_encoder_layer_2_output_dense_weight, t_encoder_layer_2_output_dense_bias)  # t438: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t442, t1983, t1988, t468] = nvFusion18(t438, t397, t_encoder_layer_3_layernorm_before_weight, t_encoder_layer_3_layernorm_before_bias)\n",
      "  del t438\n",
      "  t480 = torch.nn.functional.linear(t468, t_encoder_layer_3_attention_attention_query_weight, t_encoder_layer_3_attention_attention_query_bias)  # t480: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t485 = torch.nn.functional.linear(t468, t_encoder_layer_3_attention_attention_key_weight, t_encoder_layer_3_attention_attention_key_bias)  # t485: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t494 = torch.nn.functional.linear(t468, t_encoder_layer_3_attention_attention_value_weight, t_encoder_layer_3_attention_attention_value_bias)  # t494: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t496, t498, t499] = nvFusion19(t485, t494, t480)\n",
      "  del t485, t494, t480\n",
      "  t500 = torch.matmul(t498, t499)  # t500: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t510] = nvFusion20(t500)\n",
      "  del t500\n",
      "  t514 = torch.matmul(t510, t496)  # t514: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t518] = nvFusion21(t514)\n",
      "  del t514\n",
      "  t525 = torch.nn.functional.linear(t518, t_encoder_layer_3_attention_output_dense_weight, t_encoder_layer_3_attention_output_dense_bias)  # t525: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t529, t2063, t2068, t551] = nvFusion22(t525, t442, t_encoder_layer_3_layernorm_after_weight, t_encoder_layer_3_layernorm_after_bias)\n",
      "  del t525\n",
      "  t558 = torch.nn.functional.linear(t551, t_encoder_layer_3_intermediate_dense_weight, t_encoder_layer_3_intermediate_dense_bias)  # t558: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t563] = nvFusion23(t558)\n",
      "  t570 = torch.nn.functional.linear(t563, t_encoder_layer_3_output_dense_weight, t_encoder_layer_3_output_dense_bias)  # t570: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t574, t2093, t2098, t600] = nvFusion24(t570, t529, t_encoder_layer_4_layernorm_before_weight, t_encoder_layer_4_layernorm_before_bias)\n",
      "  del t570\n",
      "  t612 = torch.nn.functional.linear(t600, t_encoder_layer_4_attention_attention_query_weight, t_encoder_layer_4_attention_attention_query_bias)  # t612: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t617 = torch.nn.functional.linear(t600, t_encoder_layer_4_attention_attention_key_weight, t_encoder_layer_4_attention_attention_key_bias)  # t617: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t626 = torch.nn.functional.linear(t600, t_encoder_layer_4_attention_attention_value_weight, t_encoder_layer_4_attention_attention_value_bias)  # t626: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t628, t630, t631] = nvFusion25(t617, t626, t612)\n",
      "  del t617, t626, t612\n",
      "  t632 = torch.matmul(t630, t631)  # t632: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t642] = nvFusion26(t632)\n",
      "  del t632\n",
      "  t646 = torch.matmul(t642, t628)  # t646: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t650] = nvFusion27(t646)\n",
      "  del t646\n",
      "  t657 = torch.nn.functional.linear(t650, t_encoder_layer_4_attention_output_dense_weight, t_encoder_layer_4_attention_output_dense_bias)  # t657: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t661, t2173, t2178, t683] = nvFusion28(t657, t574, t_encoder_layer_4_layernorm_after_weight, t_encoder_layer_4_layernorm_after_bias)\n",
      "  del t657\n",
      "  t690 = torch.nn.functional.linear(t683, t_encoder_layer_4_intermediate_dense_weight, t_encoder_layer_4_intermediate_dense_bias)  # t690: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t695] = nvFusion29(t690)\n",
      "  t702 = torch.nn.functional.linear(t695, t_encoder_layer_4_output_dense_weight, t_encoder_layer_4_output_dense_bias)  # t702: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t706, t2203, t2208, t732] = nvFusion30(t702, t661, t_encoder_layer_5_layernorm_before_weight, t_encoder_layer_5_layernorm_before_bias)\n",
      "  del t702\n",
      "  t744 = torch.nn.functional.linear(t732, t_encoder_layer_5_attention_attention_query_weight, t_encoder_layer_5_attention_attention_query_bias)  # t744: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t749 = torch.nn.functional.linear(t732, t_encoder_layer_5_attention_attention_key_weight, t_encoder_layer_5_attention_attention_key_bias)  # t749: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t758 = torch.nn.functional.linear(t732, t_encoder_layer_5_attention_attention_value_weight, t_encoder_layer_5_attention_attention_value_bias)  # t758: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t760, t762, t763] = nvFusion31(t749, t758, t744)\n",
      "  del t749, t758, t744\n",
      "  t764 = torch.matmul(t762, t763)  # t764: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t774] = nvFusion32(t764)\n",
      "  del t764\n",
      "  t778 = torch.matmul(t774, t760)  # t778: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t782] = nvFusion33(t778)\n",
      "  del t778\n",
      "  t789 = torch.nn.functional.linear(t782, t_encoder_layer_5_attention_output_dense_weight, t_encoder_layer_5_attention_output_dense_bias)  # t789: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t793, t2283, t2288, t815] = nvFusion34(t789, t706, t_encoder_layer_5_layernorm_after_weight, t_encoder_layer_5_layernorm_after_bias)\n",
      "  del t789\n",
      "  t822 = torch.nn.functional.linear(t815, t_encoder_layer_5_intermediate_dense_weight, t_encoder_layer_5_intermediate_dense_bias)  # t822: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t827] = nvFusion35(t822)\n",
      "  t834 = torch.nn.functional.linear(t827, t_encoder_layer_5_output_dense_weight, t_encoder_layer_5_output_dense_bias)  # t834: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t838, t2313, t2318, t864] = nvFusion36(t834, t793, t_encoder_layer_6_layernorm_before_weight, t_encoder_layer_6_layernorm_before_bias)\n",
      "  del t834\n",
      "  t876 = torch.nn.functional.linear(t864, t_encoder_layer_6_attention_attention_query_weight, t_encoder_layer_6_attention_attention_query_bias)  # t876: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t881 = torch.nn.functional.linear(t864, t_encoder_layer_6_attention_attention_key_weight, t_encoder_layer_6_attention_attention_key_bias)  # t881: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t890 = torch.nn.functional.linear(t864, t_encoder_layer_6_attention_attention_value_weight, t_encoder_layer_6_attention_attention_value_bias)  # t890: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t892, t894, t895] = nvFusion37(t881, t890, t876)\n",
      "  del t881, t890, t876\n",
      "  t896 = torch.matmul(t894, t895)  # t896: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t906] = nvFusion38(t896)\n",
      "  del t896\n",
      "  t910 = torch.matmul(t906, t892)  # t910: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t914] = nvFusion39(t910)\n",
      "  del t910\n",
      "  t921 = torch.nn.functional.linear(t914, t_encoder_layer_6_attention_output_dense_weight, t_encoder_layer_6_attention_output_dense_bias)  # t921: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t925, t2393, t2398, t947] = nvFusion40(t921, t838, t_encoder_layer_6_layernorm_after_weight, t_encoder_layer_6_layernorm_after_bias)\n",
      "  del t921\n",
      "  t954 = torch.nn.functional.linear(t947, t_encoder_layer_6_intermediate_dense_weight, t_encoder_layer_6_intermediate_dense_bias)  # t954: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t959] = nvFusion41(t954)\n",
      "  t966 = torch.nn.functional.linear(t959, t_encoder_layer_6_output_dense_weight, t_encoder_layer_6_output_dense_bias)  # t966: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t970, t2423, t2428, t996] = nvFusion42(t966, t925, t_encoder_layer_7_layernorm_before_weight, t_encoder_layer_7_layernorm_before_bias)\n",
      "  del t966\n",
      "  t1008 = torch.nn.functional.linear(t996, t_encoder_layer_7_attention_attention_query_weight, t_encoder_layer_7_attention_attention_query_bias)  # t1008: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1013 = torch.nn.functional.linear(t996, t_encoder_layer_7_attention_attention_key_weight, t_encoder_layer_7_attention_attention_key_bias)  # t1013: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1022 = torch.nn.functional.linear(t996, t_encoder_layer_7_attention_attention_value_weight, t_encoder_layer_7_attention_attention_value_bias)  # t1022: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1024, t1026, t1027] = nvFusion43(t1013, t1022, t1008)\n",
      "  del t1013, t1022, t1008\n",
      "  t1028 = torch.matmul(t1026, t1027)  # t1028: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t1038] = nvFusion44(t1028)\n",
      "  del t1028\n",
      "  t1042 = torch.matmul(t1038, t1024)  # t1042: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t1046] = nvFusion45(t1042)\n",
      "  del t1042\n",
      "  t1053 = torch.nn.functional.linear(t1046, t_encoder_layer_7_attention_output_dense_weight, t_encoder_layer_7_attention_output_dense_bias)  # t1053: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1057, t2503, t2508, t1079] = nvFusion46(t1053, t970, t_encoder_layer_7_layernorm_after_weight, t_encoder_layer_7_layernorm_after_bias)\n",
      "  del t1053\n",
      "  t1086 = torch.nn.functional.linear(t1079, t_encoder_layer_7_intermediate_dense_weight, t_encoder_layer_7_intermediate_dense_bias)  # t1086: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t1091] = nvFusion47(t1086)\n",
      "  t1098 = torch.nn.functional.linear(t1091, t_encoder_layer_7_output_dense_weight, t_encoder_layer_7_output_dense_bias)  # t1098: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1102, t2533, t2538, t1128] = nvFusion48(t1098, t1057, t_encoder_layer_8_layernorm_before_weight, t_encoder_layer_8_layernorm_before_bias)\n",
      "  del t1098\n",
      "  t1140 = torch.nn.functional.linear(t1128, t_encoder_layer_8_attention_attention_query_weight, t_encoder_layer_8_attention_attention_query_bias)  # t1140: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1145 = torch.nn.functional.linear(t1128, t_encoder_layer_8_attention_attention_key_weight, t_encoder_layer_8_attention_attention_key_bias)  # t1145: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1154 = torch.nn.functional.linear(t1128, t_encoder_layer_8_attention_attention_value_weight, t_encoder_layer_8_attention_attention_value_bias)  # t1154: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1156, t1158, t1159] = nvFusion49(t1145, t1154, t1140)\n",
      "  del t1145, t1154, t1140\n",
      "  t1160 = torch.matmul(t1158, t1159)  # t1160: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t1170] = nvFusion50(t1160)\n",
      "  del t1160\n",
      "  t1174 = torch.matmul(t1170, t1156)  # t1174: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t1178] = nvFusion51(t1174)\n",
      "  del t1174\n",
      "  t1185 = torch.nn.functional.linear(t1178, t_encoder_layer_8_attention_output_dense_weight, t_encoder_layer_8_attention_output_dense_bias)  # t1185: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1189, t2613, t2618, t1211] = nvFusion52(t1185, t1102, t_encoder_layer_8_layernorm_after_weight, t_encoder_layer_8_layernorm_after_bias)\n",
      "  del t1185\n",
      "  t1218 = torch.nn.functional.linear(t1211, t_encoder_layer_8_intermediate_dense_weight, t_encoder_layer_8_intermediate_dense_bias)  # t1218: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t1223] = nvFusion53(t1218)\n",
      "  t1230 = torch.nn.functional.linear(t1223, t_encoder_layer_8_output_dense_weight, t_encoder_layer_8_output_dense_bias)  # t1230: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1234, t2643, t2648, t1260] = nvFusion54(t1230, t1189, t_encoder_layer_9_layernorm_before_weight, t_encoder_layer_9_layernorm_before_bias)\n",
      "  del t1230\n",
      "  t1272 = torch.nn.functional.linear(t1260, t_encoder_layer_9_attention_attention_query_weight, t_encoder_layer_9_attention_attention_query_bias)  # t1272: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1277 = torch.nn.functional.linear(t1260, t_encoder_layer_9_attention_attention_key_weight, t_encoder_layer_9_attention_attention_key_bias)  # t1277: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1286 = torch.nn.functional.linear(t1260, t_encoder_layer_9_attention_attention_value_weight, t_encoder_layer_9_attention_attention_value_bias)  # t1286: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1288, t1290, t1291] = nvFusion55(t1277, t1286, t1272)\n",
      "  del t1277, t1286, t1272\n",
      "  t1292 = torch.matmul(t1290, t1291)  # t1292: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t1302] = nvFusion56(t1292)\n",
      "  del t1292\n",
      "  t1306 = torch.matmul(t1302, t1288)  # t1306: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t1310] = nvFusion57(t1306)\n",
      "  del t1306\n",
      "  t1317 = torch.nn.functional.linear(t1310, t_encoder_layer_9_attention_output_dense_weight, t_encoder_layer_9_attention_output_dense_bias)  # t1317: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1321, t2723, t2728, t1343] = nvFusion58(t1317, t1234, t_encoder_layer_9_layernorm_after_weight, t_encoder_layer_9_layernorm_after_bias)\n",
      "  del t1317\n",
      "  t1350 = torch.nn.functional.linear(t1343, t_encoder_layer_9_intermediate_dense_weight, t_encoder_layer_9_intermediate_dense_bias)  # t1350: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t1355] = nvFusion59(t1350)\n",
      "  t1362 = torch.nn.functional.linear(t1355, t_encoder_layer_9_output_dense_weight, t_encoder_layer_9_output_dense_bias)  # t1362: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1366, t2753, t2758, t1392] = nvFusion60(t1362, t1321, t_encoder_layer_10_layernorm_before_weight, t_encoder_layer_10_layernorm_before_bias)\n",
      "  del t1362\n",
      "  t1404 = torch.nn.functional.linear(t1392, t_encoder_layer_10_attention_attention_query_weight, t_encoder_layer_10_attention_attention_query_bias)  # t1404: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1409 = torch.nn.functional.linear(t1392, t_encoder_layer_10_attention_attention_key_weight, t_encoder_layer_10_attention_attention_key_bias)  # t1409: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1418 = torch.nn.functional.linear(t1392, t_encoder_layer_10_attention_attention_value_weight, t_encoder_layer_10_attention_attention_value_bias)  # t1418: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1420, t1422, t1423] = nvFusion61(t1409, t1418, t1404)\n",
      "  del t1409, t1418, t1404\n",
      "  t1424 = torch.matmul(t1422, t1423)  # t1424: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t1434] = nvFusion62(t1424)\n",
      "  del t1424\n",
      "  t1438 = torch.matmul(t1434, t1420)  # t1438: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t1442] = nvFusion63(t1438)\n",
      "  del t1438\n",
      "  t1449 = torch.nn.functional.linear(t1442, t_encoder_layer_10_attention_output_dense_weight, t_encoder_layer_10_attention_output_dense_bias)  # t1449: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1453, t2833, t2838, t1475] = nvFusion64(t1449, t1366, t_encoder_layer_10_layernorm_after_weight, t_encoder_layer_10_layernorm_after_bias)\n",
      "  del t1449\n",
      "  t1482 = torch.nn.functional.linear(t1475, t_encoder_layer_10_intermediate_dense_weight, t_encoder_layer_10_intermediate_dense_bias)  # t1482: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t1487] = nvFusion65(t1482)\n",
      "  t1494 = torch.nn.functional.linear(t1487, t_encoder_layer_10_output_dense_weight, t_encoder_layer_10_output_dense_bias)  # t1494: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1498, t2863, t2868, t1524] = nvFusion66(t1494, t1453, t_encoder_layer_11_layernorm_before_weight, t_encoder_layer_11_layernorm_before_bias)\n",
      "  del t1494\n",
      "  t1536 = torch.nn.functional.linear(t1524, t_encoder_layer_11_attention_attention_query_weight, t_encoder_layer_11_attention_attention_query_bias)  # t1536: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1541 = torch.nn.functional.linear(t1524, t_encoder_layer_11_attention_attention_key_weight, t_encoder_layer_11_attention_attention_key_bias)  # t1541: \"cuda:0 f32[10, 197, 192]\"\n",
      "  t1550 = torch.nn.functional.linear(t1524, t_encoder_layer_11_attention_attention_value_weight, t_encoder_layer_11_attention_attention_value_bias)  # t1550: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1552, t1554, t1555] = nvFusion67(t1541, t1550, t1536)\n",
      "  del t1541, t1550, t1536\n",
      "  t1556 = torch.matmul(t1554, t1555)  # t1556: \"cuda:0 f32[10, 3, 197, 197]\"\n",
      "  [t1566] = nvFusion68(t1556)\n",
      "  del t1556\n",
      "  t1570 = torch.matmul(t1566, t1552)  # t1570: \"cuda:0 f32[10, 3, 197, 64]\"\n",
      "  [t1574] = nvFusion69(t1570)\n",
      "  del t1570\n",
      "  t1581 = torch.nn.functional.linear(t1574, t_encoder_layer_11_attention_output_dense_weight, t_encoder_layer_11_attention_output_dense_bias)  # t1581: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [t1585, t2943, t2948, t1607] = nvFusion70(t1581, t1498, t_encoder_layer_11_layernorm_after_weight, t_encoder_layer_11_layernorm_after_bias)\n",
      "  del t1581\n",
      "  t1614 = torch.nn.functional.linear(t1607, t_encoder_layer_11_intermediate_dense_weight, t_encoder_layer_11_intermediate_dense_bias)  # t1614: \"cuda:0 f32[10, 197, 768]\"\n",
      "  [t1619] = nvFusion71(t1614)\n",
      "  t1626 = torch.nn.functional.linear(t1619, t_encoder_layer_11_output_dense_weight, t_encoder_layer_11_output_dense_bias)  # t1626: \"cuda:0 f32[10, 197, 192]\"\n",
      "  [last_hidden_state, t2973, t2978, sequence_output, first_token_tensor] = nvFusion72(t1626, t1585, t_layernorm_weight, t_layernorm_bias)\n",
      "  del t1626\n",
      "  pooled_output = torch.nn.functional.linear(first_token_tensor, t_pooler_dense_weight, t_pooler_dense_bias)  # pooled_output: \"cuda:0 f32[10, 192]\"\n",
      "  [pooler_output] = nvFusion73(pooled_output)\n",
      "  del pooled_output\n",
      "  return {'output': transformers_modeling_outputs_BaseModelOutputWithPooling(last_hidden_state=sequence_output,pooler_output=pooler_output,hidden_states=None,attentions=None), 'flat_args': [pixel_values, t_embeddings_cls_token, bias, weight, t_embeddings_position_embeddings, t_encoder_layer_0_attention_attention_key_bias, t_encoder_layer_0_attention_attention_key_weight, t_encoder_layer_0_attention_attention_query_bias, t_encoder_layer_0_attention_attention_query_weight, t_encoder_layer_0_attention_attention_value_bias, t_encoder_layer_0_attention_attention_value_weight, t_encoder_layer_0_attention_output_dense_bias, t_encoder_layer_0_attention_output_dense_weight, t_encoder_layer_0_intermediate_dense_bias, t_encoder_layer_0_intermediate_dense_weight, t_encoder_layer_0_layernorm_after_bias, t_encoder_layer_0_layernorm_after_weight, t_encoder_layer_0_layernorm_before_bias, t_encoder_layer_0_layernorm_before_weight, t_encoder_layer_0_output_dense_bias, t_encoder_layer_0_output_dense_weight, t_encoder_layer_1_attention_attention_key_bias, t_encoder_layer_1_attention_attention_key_weight, t_encoder_layer_1_attention_attention_query_bias, t_encoder_layer_1_attention_attention_query_weight, t_encoder_layer_1_attention_attention_value_bias, t_encoder_layer_1_attention_attention_value_weight, t_encoder_layer_1_attention_output_dense_bias, t_encoder_layer_1_attention_output_dense_weight, t_encoder_layer_1_intermediate_dense_bias, t_encoder_layer_1_intermediate_dense_weight, t_encoder_layer_1_layernorm_after_bias, t_encoder_layer_1_layernorm_after_weight, t_encoder_layer_1_layernorm_before_bias, t_encoder_layer_1_layernorm_before_weight, t_encoder_layer_1_output_dense_bias, t_encoder_layer_1_output_dense_weight, t_encoder_layer_2_attention_attention_key_bias, t_encoder_layer_2_attention_attention_key_weight, t_encoder_layer_2_attention_attention_query_bias, t_encoder_layer_2_attention_attention_query_weight, t_encoder_layer_2_attention_attention_value_bias, t_encoder_layer_2_attention_attention_value_weight, t_encoder_layer_2_attention_output_dense_bias, t_encoder_layer_2_attention_output_dense_weight, t_encoder_layer_2_intermediate_dense_bias, t_encoder_layer_2_intermediate_dense_weight, t_encoder_layer_2_layernorm_after_bias, t_encoder_layer_2_layernorm_after_weight, t_encoder_layer_2_layernorm_before_bias, t_encoder_layer_2_layernorm_before_weight, t_encoder_layer_2_output_dense_bias, t_encoder_layer_2_output_dense_weight, t_encoder_layer_3_attention_attention_key_bias, t_encoder_layer_3_attention_attention_key_weight, t_encoder_layer_3_attention_attention_query_bias, t_encoder_layer_3_attention_attention_query_weight, t_encoder_layer_3_attention_attention_value_bias, t_encoder_layer_3_attention_attention_value_weight, t_encoder_layer_3_attention_output_dense_bias, t_encoder_layer_3_attention_output_dense_weight, t_encoder_layer_3_intermediate_dense_bias, t_encoder_layer_3_intermediate_dense_weight, t_encoder_layer_3_layernorm_after_bias, t_encoder_layer_3_layernorm_after_weight, t_encoder_layer_3_layernorm_before_bias, t_encoder_layer_3_layernorm_before_weight, t_encoder_layer_3_output_dense_bias, t_encoder_layer_3_output_dense_weight, t_encoder_layer_4_attention_attention_key_bias, t_encoder_layer_4_attention_attention_key_weight, t_encoder_layer_4_attention_attention_query_bias, t_encoder_layer_4_attention_attention_query_weight, t_encoder_layer_4_attention_attention_value_bias, t_encoder_layer_4_attention_attention_value_weight, t_encoder_layer_4_attention_output_dense_bias, t_encoder_layer_4_attention_output_dense_weight, t_encoder_layer_4_intermediate_dense_bias, t_encoder_layer_4_intermediate_dense_weight, t_encoder_layer_4_layernorm_after_bias, t_encoder_layer_4_layernorm_after_weight, t_encoder_layer_4_layernorm_before_bias, t_encoder_layer_4_layernorm_before_weight, t_encoder_layer_4_output_dense_bias, t_encoder_layer_4_output_dense_weight, t_encoder_layer_5_attention_attention_key_bias, t_encoder_layer_5_attention_attention_key_weight, t_encoder_layer_5_attention_attention_query_bias, t_encoder_layer_5_attention_attention_query_weight, t_encoder_layer_5_attention_attention_value_bias, t_encoder_layer_5_attention_attention_value_weight, t_encoder_layer_5_attention_output_dense_bias, t_encoder_layer_5_attention_output_dense_weight, t_encoder_layer_5_intermediate_dense_bias, t_encoder_layer_5_intermediate_dense_weight, t_encoder_layer_5_layernorm_after_bias, t_encoder_layer_5_layernorm_after_weight, t_encoder_layer_5_layernorm_before_bias, t_encoder_layer_5_layernorm_before_weight, t_encoder_layer_5_output_dense_bias, t_encoder_layer_5_output_dense_weight, t_encoder_layer_6_attention_attention_key_bias, t_encoder_layer_6_attention_attention_key_weight, t_encoder_layer_6_attention_attention_query_bias, t_encoder_layer_6_attention_attention_query_weight, t_encoder_layer_6_attention_attention_value_bias, t_encoder_layer_6_attention_attention_value_weight, t_encoder_layer_6_attention_output_dense_bias, t_encoder_layer_6_attention_output_dense_weight, t_encoder_layer_6_intermediate_dense_bias, t_encoder_layer_6_intermediate_dense_weight, t_encoder_layer_6_layernorm_after_bias, t_encoder_layer_6_layernorm_after_weight, t_encoder_layer_6_layernorm_before_bias, t_encoder_layer_6_layernorm_before_weight, t_encoder_layer_6_output_dense_bias, t_encoder_layer_6_output_dense_weight, t_encoder_layer_7_attention_attention_key_bias, t_encoder_layer_7_attention_attention_key_weight, t_encoder_layer_7_attention_attention_query_bias, t_encoder_layer_7_attention_attention_query_weight, t_encoder_layer_7_attention_attention_value_bias, t_encoder_layer_7_attention_attention_value_weight, t_encoder_layer_7_attention_output_dense_bias, t_encoder_layer_7_attention_output_dense_weight, t_encoder_layer_7_intermediate_dense_bias, t_encoder_layer_7_intermediate_dense_weight, t_encoder_layer_7_layernorm_after_bias, t_encoder_layer_7_layernorm_after_weight, t_encoder_layer_7_layernorm_before_bias, t_encoder_layer_7_layernorm_before_weight, t_encoder_layer_7_output_dense_bias, t_encoder_layer_7_output_dense_weight, t_encoder_layer_8_attention_attention_key_bias, t_encoder_layer_8_attention_attention_key_weight, t_encoder_layer_8_attention_attention_query_bias, t_encoder_layer_8_attention_attention_query_weight, t_encoder_layer_8_attention_attention_value_bias, t_encoder_layer_8_attention_attention_value_weight, t_encoder_layer_8_attention_output_dense_bias, t_encoder_layer_8_attention_output_dense_weight, t_encoder_layer_8_intermediate_dense_bias, t_encoder_layer_8_intermediate_dense_weight, t_encoder_layer_8_layernorm_after_bias, t_encoder_layer_8_layernorm_after_weight, t_encoder_layer_8_layernorm_before_bias, t_encoder_layer_8_layernorm_before_weight, t_encoder_layer_8_output_dense_bias, t_encoder_layer_8_output_dense_weight, t_encoder_layer_9_attention_attention_key_bias, t_encoder_layer_9_attention_attention_key_weight, t_encoder_layer_9_attention_attention_query_bias, t_encoder_layer_9_attention_attention_query_weight, t_encoder_layer_9_attention_attention_value_bias, t_encoder_layer_9_attention_attention_value_weight, t_encoder_layer_9_attention_output_dense_bias, t_encoder_layer_9_attention_output_dense_weight, t_encoder_layer_9_intermediate_dense_bias, t_encoder_layer_9_intermediate_dense_weight, t_encoder_layer_9_layernorm_after_bias, t_encoder_layer_9_layernorm_after_weight, t_encoder_layer_9_layernorm_before_bias, t_encoder_layer_9_layernorm_before_weight, t_encoder_layer_9_output_dense_bias, t_encoder_layer_9_output_dense_weight, t_encoder_layer_10_attention_attention_key_bias, t_encoder_layer_10_attention_attention_key_weight, t_encoder_layer_10_attention_attention_query_bias, t_encoder_layer_10_attention_attention_query_weight, t_encoder_layer_10_attention_attention_value_bias, t_encoder_layer_10_attention_attention_value_weight, t_encoder_layer_10_attention_output_dense_bias, t_encoder_layer_10_attention_output_dense_weight, t_encoder_layer_10_intermediate_dense_bias, t_encoder_layer_10_intermediate_dense_weight, t_encoder_layer_10_layernorm_after_bias, t_encoder_layer_10_layernorm_after_weight, t_encoder_layer_10_layernorm_before_bias, t_encoder_layer_10_layernorm_before_weight, t_encoder_layer_10_output_dense_bias, t_encoder_layer_10_output_dense_weight, t_encoder_layer_11_attention_attention_key_bias, t_encoder_layer_11_attention_attention_key_weight, t_encoder_layer_11_attention_attention_query_bias, t_encoder_layer_11_attention_attention_query_weight, t_encoder_layer_11_attention_attention_value_bias, t_encoder_layer_11_attention_attention_value_weight, t_encoder_layer_11_attention_output_dense_bias, t_encoder_layer_11_attention_output_dense_weight, t_encoder_layer_11_intermediate_dense_bias, t_encoder_layer_11_intermediate_dense_weight, t_encoder_layer_11_layernorm_after_bias, t_encoder_layer_11_layernorm_after_weight, t_encoder_layer_11_layernorm_before_bias, t_encoder_layer_11_layernorm_before_weight, t_encoder_layer_11_output_dense_bias, t_encoder_layer_11_output_dense_weight, t_layernorm_bias, t_layernorm_weight, t_pooler_dense_bias, t_pooler_dense_weight], 'flat_output': (None, None, sequence_output, pooler_output)}, ((attention_probs, first_token_tensor, hidden_states, input, input_tensor, last_hidden_state, layer_output, pixel_values, pooler_output, query_layer, t1024, t1026, t1027, t103, t1038, t1046, t1057, t1079, t1086, t1091, t1102, t1128, t1156, t1158, t1159, t1170, t1178, t1189, t1211, t1218, t122, t1223, t1234, t1260, t1288, t1290, t1291, t1302, t1310, t1321, t1343, t1350, t1355, t1366, t1392, t1420, t1422, t1423, t1434, t1442, t1453, t1475, t1482, t1487, t1498, t1524, t1552, t1554, t1555, t1566, t1574, t1585, t1607, t1614, t1619, t162, t167, t1675, t1679, t1736, t1741, t1763, t1768, t178, t1843, t1848, t1873, t1878, t1953, t1958, t1983, t1988, t204, t2063, t2068, t2093, t2098, t2173, t2178, t2203, t2208, t2283, t2288, t2313, t2318, t232, t234, t235, t2393, t2398, t2423, t2428, t246, t2503, t2508, t2533, t2538, t254, t2613, t2618, t2643, t2648, t265, t2723, t2728, t2753, t2758, t2833, t2838, t2863, t2868, t287, t294, t2943, t2948, t2973, t2978, t299, t310, t336, t364, t366, t367, t378, t386, t397, t419, t426, t431, t442, t468, t496, t498, t499, t510, t518, t529, t551, t558, t563, t574, t600, t628, t630, t631, t642, t650, t661, t683, t690, t695, t706, t732, t760, t762, t763, t774, t782, t793, t815, t822, t827, t838, t864, t892, t894, t895, t906, t914, t925, t947, t954, t959, t970, t996, t_encoder_layer_0_attention_attention_key_weight, t_encoder_layer_0_attention_attention_query_weight, t_encoder_layer_0_attention_attention_value_weight, t_encoder_layer_0_attention_output_dense_weight, t_encoder_layer_0_intermediate_dense_weight, t_encoder_layer_0_layernorm_after_weight, t_encoder_layer_0_layernorm_before_weight, t_encoder_layer_0_output_dense_weight, t_encoder_layer_10_attention_attention_key_weight, t_encoder_layer_10_attention_attention_query_weight, t_encoder_layer_10_attention_attention_value_weight, t_encoder_layer_10_attention_output_dense_weight, t_encoder_layer_10_intermediate_dense_weight, t_encoder_layer_10_layernorm_after_weight, t_encoder_layer_10_layernorm_before_weight, t_encoder_layer_10_output_dense_weight, t_encoder_layer_11_attention_attention_key_weight, t_encoder_layer_11_attention_attention_query_weight, t_encoder_layer_11_attention_attention_value_weight, t_encoder_layer_11_attention_output_dense_weight, t_encoder_layer_11_intermediate_dense_weight, t_encoder_layer_11_layernorm_after_weight, t_encoder_layer_11_layernorm_before_weight, t_encoder_layer_11_output_dense_weight, t_encoder_layer_1_attention_attention_key_weight, t_encoder_layer_1_attention_attention_query_weight, t_encoder_layer_1_attention_attention_value_weight, t_encoder_layer_1_attention_output_dense_weight, t_encoder_layer_1_intermediate_dense_weight, t_encoder_layer_1_layernorm_after_weight, t_encoder_layer_1_layernorm_before_weight, t_encoder_layer_1_output_dense_weight, t_encoder_layer_2_attention_attention_key_weight, t_encoder_layer_2_attention_attention_query_weight, t_encoder_layer_2_attention_attention_value_weight, t_encoder_layer_2_attention_output_dense_weight, t_encoder_layer_2_intermediate_dense_weight, t_encoder_layer_2_layernorm_after_weight, t_encoder_layer_2_layernorm_before_weight, t_encoder_layer_2_output_dense_weight, t_encoder_layer_3_attention_attention_key_weight, t_encoder_layer_3_attention_attention_query_weight, t_encoder_layer_3_attention_attention_value_weight, t_encoder_layer_3_attention_output_dense_weight, t_encoder_layer_3_intermediate_dense_weight, t_encoder_layer_3_layernorm_after_weight, t_encoder_layer_3_layernorm_before_weight, t_encoder_layer_3_output_dense_weight, t_encoder_layer_4_attention_attention_key_weight, t_encoder_layer_4_attention_attention_query_weight, t_encoder_layer_4_attention_attention_value_weight, t_encoder_layer_4_attention_output_dense_weight, t_encoder_layer_4_intermediate_dense_weight, t_encoder_layer_4_layernorm_after_weight, t_encoder_layer_4_layernorm_before_weight, t_encoder_layer_4_output_dense_weight, t_encoder_layer_5_attention_attention_key_weight, t_encoder_layer_5_attention_attention_query_weight, t_encoder_layer_5_attention_attention_value_weight, t_encoder_layer_5_attention_output_dense_weight, t_encoder_layer_5_intermediate_dense_weight, t_encoder_layer_5_layernorm_after_weight, t_encoder_layer_5_layernorm_before_weight, t_encoder_layer_5_output_dense_weight, t_encoder_layer_6_attention_attention_key_weight, t_encoder_layer_6_attention_attention_query_weight, t_encoder_layer_6_attention_attention_value_weight, t_encoder_layer_6_attention_output_dense_weight, t_encoder_layer_6_intermediate_dense_weight, t_encoder_layer_6_layernorm_after_weight, t_encoder_layer_6_layernorm_before_weight, t_encoder_layer_6_output_dense_weight, t_encoder_layer_7_attention_attention_key_weight, t_encoder_layer_7_attention_attention_query_weight, t_encoder_layer_7_attention_attention_value_weight, t_encoder_layer_7_attention_output_dense_weight, t_encoder_layer_7_intermediate_dense_weight, t_encoder_layer_7_layernorm_after_weight, t_encoder_layer_7_layernorm_before_weight, t_encoder_layer_7_output_dense_weight, t_encoder_layer_8_attention_attention_key_weight, t_encoder_layer_8_attention_attention_query_weight, t_encoder_layer_8_attention_attention_value_weight, t_encoder_layer_8_attention_output_dense_weight, t_encoder_layer_8_intermediate_dense_weight, t_encoder_layer_8_layernorm_after_weight, t_encoder_layer_8_layernorm_before_weight, t_encoder_layer_8_output_dense_weight, t_encoder_layer_9_attention_attention_key_weight, t_encoder_layer_9_attention_attention_query_weight, t_encoder_layer_9_attention_attention_value_weight, t_encoder_layer_9_attention_output_dense_weight, t_encoder_layer_9_intermediate_dense_weight, t_encoder_layer_9_layernorm_after_weight, t_encoder_layer_9_layernorm_before_weight, t_encoder_layer_9_output_dense_weight, t_layernorm_weight, t_pooler_dense_weight, value_layer), ())\n"
     ]
    }
   ],
   "source": [
    "forward_trace = thunder.last_traces(jwaver)[-1].python()\n",
    "print(forward_trace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
