{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心模块 Core Module\n",
    "\n",
    "> 主要定义与任务相关的核心组件和配置\n",
    "> \n",
    "> Defines core components and configurations related to tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description: \n",
    "\n",
    "核心模块包含任务相关的主要类和配置文件，如 ClassificationTask 和 ClassificationTaskConfig。其中配置文件通过 Pydantic 进行定义，帮助用户更好地构建图像分类任务的各个部分。\n",
    "\n",
    "The core module contains the primary classes and configuration files related to tasks, such as ClassificationTask and ClassificationTaskConfig, where the configurations are defined using Pydantic, allowing users to easily structure components of image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- ClassificationTask: 用于处理图像分类任务的 PyTorch Lightning 模块。\n",
    "- ClassificationTask: A PyTorch Lightning module for handling image classification tasks.\n",
    "- ClassificationTaskConfig: 使用 Pydantic 设计的配置类，用于初始化任务。\n",
    "- ClassificationTaskConfig: A configuration class designed with Pydantic for initializing the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nucleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\" # TODO this is optional for Foreigners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-03 01:48:41,138] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/home_program_files/miniconda3/envs/fastai/bin/../lib/gcc/x86_64-conda-linux-gnu/14.1.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ycm/home_program_files/miniconda3/envs/fastai/bin/../lib/gcc/x86_64-conda-linux-gnu/14.1.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[3;91mFalse\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig, ViTModel, ViTConfig\n",
    "from namable_classify.infra import print_model_pretty\n",
    "AutoModel.from_pretrained(\"google/vit-base-patch16-224-in21k\").training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel\n",
    "class ClassificationModelConfig(BaseModel):\n",
    "    provider: str = \"huggingface\"\n",
    "    checkpoint: str = \"google/vit-base-patch16-224-in21k\" # TODO 支持 hf  timm torch\n",
    "    head_strategy: str = \"linear\"\n",
    "    num_of_classes: int = -1\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel, AutoConfig, ViTModel, ViTConfig\n",
    "from transformers import AutoImageProcessor, BitImageProcessor, ViTImageProcessor\n",
    "from deepspeed.ops.adam import DeepSpeedCPUAdam\n",
    "\n",
    "class HuggingfaceModel(nn.Module):\n",
    "    \"\"\"Some Information about HuggingfaceModel\"\"\"\n",
    "    def __init__(self, config : ClassificationModelConfig, forward_with_hf_image_preprocessor=False):\n",
    "        super().__init__()\n",
    "        # self.image_preprocessor = BitImageProcessor.from_pretrained(config.model_checkpoint, use_fast=True)\n",
    "        self.image_preprocessor = AutoImageProcessor.from_pretrained(config.checkpoint)\n",
    "        self.backbone: ViTModel = AutoModel.from_pretrained(config.checkpoint) # TODO we now just consider ViTModel\n",
    "        self.backbone.train()\n",
    "        self.backbone_config: ViTConfig = self.backbone.config # 包括了 image_size 和 hidden_size 这两个重要信息\n",
    "        if config.head_strategy == \"linear\":\n",
    "            self.head = nn.Linear(self.backbone_config.hidden_size, config.num_of_classes)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only linear head is supported for now. \")\n",
    "        self.config = config\n",
    "        self.forward_with_hf_image_preprocessor = forward_with_hf_image_preprocessor\n",
    "        # 虽然huggingface的dummy inputs很多都是假的不是真的能测试这个模型，但是OpenDelta很矫情，还是认为要有。\n",
    "        self.dummy_inputs = self.backbone.dummy_inputs\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        if self.forward_with_hf_image_preprocessor:\n",
    "            x = self.image_preprocessor(images=x, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "        hf_output = self.backbone(x)\n",
    "        # hidden_state = hf_output.last_hidden_state\n",
    "        output = hf_output.pooler_output\n",
    "        output = self.head(output)\n",
    "        return output\n",
    "    \n",
    "from fastcore.basics import patch\n",
    "@patch\n",
    "def get_cls_model(self:ClassificationModelConfig):\n",
    "    if self.provider == \"huggingface\":\n",
    "        return HuggingfaceModel(self)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only huggingface is supported for now. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from pydantic import BaseModel\n",
    "from namable_classify.data import ClassificationDataConfig, ClassificationDataModule\n",
    "\n",
    "class ClassificationTaskConfig(BaseModel):\n",
    "    experiment_project: str = \"NamableClassify Development\" # 为了发表什么论文，正在探索什么IDEA？\n",
    "    experiment_task: str = \"Development Test\" # 为了证明我的IDEA有效，正在做哪个数据集、哪个架构的实验？\n",
    "    experiment_index: int = 0  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 表示是第几次重复实验 # which is also the random seed\n",
    "    label_smoothing: float = 0.1\n",
    "    cls_model_config: ClassificationModelConfig = ClassificationModelConfig()\n",
    "    dataset_config: ClassificationDataConfig = ClassificationDataConfig()\n",
    "    learning_rate: float = 3e-4\n",
    "    yuequ:str = \"full_finetune\"\n",
    "    yuequ_pe:float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def see_params_norm(self:nn.Module)->float:\n",
    "    params = torch.cat([param.view(-1) for param in self.parameters()])\n",
    "    # 计算范数，这里以2-范数为例\n",
    "    norm = torch.norm(params, p=2)\n",
    "    return norm.item()\n",
    "\n",
    "@patch\n",
    "def see_grad_norm(self:nn.Module)-> float:\n",
    "    grads = torch.cat([param.grad.view(-1) for param in self.parameters() if param.grad is not None])\n",
    "    # 计算范数，这里以2-范数为例\n",
    "    norm = torch.norm(grads, p=2)\n",
    "    return norm.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from namable_classify.help import runs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mtorch.utils.tensorboard.writer.SummaryWriter\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7fee1f6f7c40\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = pl_loggers.TensorBoardLogger(runs_path/\"test\")\n",
    "logger.experiment # .experiment 得到的是第三方平台的类型。\n",
    "# dir(logger) # pl的logger类型方法少很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS, STEP_OUTPUT, OptimizerLRScheduler\n",
    "from overrides import override\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deepspeed.ops.adam import DeepSpeedCPUAdam, FusedAdam \n",
    "from deepspeed.ops.lamb import FusedLamb\n",
    "\n",
    "from namable_classify.infra import print_model_pretty\n",
    "from namable_classify.infra import append_dict_list, ensure_array, logger\n",
    "from namable_classify.metrics import compute_classification_metrics, draw_classification_metrics\n",
    "import numpy as np\n",
    "from typing import Any, Optional\n",
    "class ClassificationTask(L.LightningModule):\n",
    "    def __init__(self, config: ClassificationTaskConfig)->None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(config.model_dump())\n",
    "        L.seed_everything(config.experiment_index) # use index as the seed for reproducibility\n",
    "        # 首先数据是可以加载的\n",
    "        self.lit_data:ClassificationDataModule = config.dataset_config.get_lightning_data_module()\n",
    "        # 数据怎么做Transform，取决于 Model的情况\n",
    "        # 现在我们加载Model，刚才有了数据之后，首先可以更新 cls_model_config\n",
    "        \n",
    "        config.cls_model_config.num_of_classes = self.lit_data.num_of_classes\n",
    "        self.cls_model:HuggingfaceModel = config.cls_model_config.get_cls_model()\n",
    "        \n",
    "        # 现在需要更新数据\n",
    "        model_image_size:tuple[int, int] = self.lit_data.set_transform_from_hf_image_preprocessor(hf_image_preprocessor=self.cls_model.image_preprocessor)\n",
    "        \n",
    "        # model_image_size:tuple[int, int] = (self.cls_model.image_preprocessor.size['height'], self.cls_model.image_preprocessor.size['width'])\n",
    "        self.example_input_array = torch.randn((1, self.cls_model.backbone.config.num_channels, \n",
    "                                                *model_image_size), requires_grad=True)\n",
    "        self.dummy_inputs = dict(input_ids=self.example_input_array) # for opendelta and huggingface\n",
    "        # self.dummy_inputs_is_correct = True # Used for boguan_yuequ (博观约取) 's auto opendelta \n",
    "        # 最后是训练策略\n",
    "        # self.softmax = nn.Softmax(dim=1)    \n",
    "        self.softmax = nn.Identity()\n",
    "        self.loss = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
    "        # nn.LogSoftmax(dim=1)\n",
    "        # https://blog.csdn.net/qq_43391414/article/details/118421352 logsoftmax+nll的速度快，但是没有label smoothing\n",
    "        \n",
    "        # 评价策略\n",
    "        self.evaluation_steps_outputs = dict()\n",
    "        \n",
    "        # self.automatic_optimization = False\n",
    "        self.automatic_optimization = True\n",
    "        \n",
    "        # 上面初始化后config有变化，所以需要重新保存一下。\n",
    "        self.save_hyperparameters(config.model_dump())\n",
    "        \n",
    "        # 之前的loss\n",
    "        self.previous_loss:Optional[float] = None\n",
    "        \n",
    "        # 参数高效微调，只会加载部分参数。 https://lightning.ai/docs/pytorch/stable/common/checkpointing_intermediate.html#resume-from-a-partial-checkpoint\n",
    "        self.strict_loading = False\n",
    "        \n",
    "    def state_dict(self):\n",
    "        # TODO 不稳定的API\n",
    "        # Only save parameters that require gradients\n",
    "        return {k: v for k, v in super().state_dict().items() if v.requires_grad}\n",
    "    \n",
    "    # @override\n",
    "    # def on_train_start(self) -> None:\n",
    "    #     # 更新一下最终的超参数\n",
    "    #     # self.save_hyperparameters(self.hparams)\n",
    "    #     # self.lit_data.save_hyperparameters(self.lit_data.hparams)\n",
    "    #     return super().on_train_start()\n",
    "    \n",
    "    def compute_model_logits(self, image_tensor:torch.Tensor)-> torch.Tensor:\n",
    "        return self.cls_model(image_tensor)\n",
    "    \n",
    "    @override\n",
    "    def forward(self, image_tensor:torch.Tensor, *args, **kwargs)-> torch.Tensor:\n",
    "        return self.softmax(self.compute_model_logits(image_tensor))\n",
    "\n",
    "    def forward_loss(self, image_tensor: torch.Tensor, label_tensor:torch.Tensor)->torch.Tensor:\n",
    "        probs = self(image_tensor)\n",
    "        # return F.nll_loss(logits, label_tensor)\n",
    "        return self.loss(probs, label_tensor)\n",
    "\n",
    "    @override\n",
    "    def training_step(self, batch, batch_idx=None, *args, **kwargs)-> STEP_OUTPUT:\n",
    "        # self.train() # 不必要\n",
    "        # opt = self.optimizers(use_pl_optimizer=False)\n",
    "        # opt = self.optimizers(use_pl_optimizer=True)\n",
    "        # opt.zero_grad()\n",
    "        \n",
    "        loss = self.forward_loss(*batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        if self.previous_loss is not None:\n",
    "            self.log(\"train_loss_delta\", float(loss) - self.previous_loss, prog_bar=True)\n",
    "        self.previous_loss = float(loss)\n",
    "        # print(\"Loss:\", loss.item())\n",
    "        # self.manual_backward(loss)\n",
    "        # loss.backward()\n",
    "        # self.log(\"grad_norm\", self.see_grad_norm(), prog_bar=True)\n",
    "        # old_params_norm = self.see_params_norm()\n",
    "        \n",
    "        # self.log(\"params_norm\", old_params_norm, prog_bar=True)\n",
    "        \n",
    "        # # print(\"Grad Norm:\", self.see_grad_norm())\n",
    "        # # print(\"Params Norm before step:\", self.see_params_norm())\n",
    "        # # print(\"Params of cls_model Norm before step:\", self.cls_model.see_params_norm())\n",
    "        # opt.step()\n",
    "        # # print(\"Params Norm after step:\", self.see_params_norm())\n",
    "        # # print(\"Params of cls_model Norm after step:\", self.cls_model.see_params_norm())\n",
    "        # params_norm_delta = self.see_params_norm() - old_params_norm\n",
    "        # self.log(\"params_norm_delta\", params_norm_delta, prog_bar=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # sch = self.lr_schedulers()\n",
    "        # self.log(\"lr\", sch.get_last_lr()[0], prog_bar=True)\n",
    "        # # https://www.restack.io/p/pytorch-lightning-answer-get-current-training-step-cat-ai\n",
    "        # # https://github.com/Lightning-AI/pytorch-lightning/pull/11599\n",
    "        # sch.step(self.global_step/self.trainer.estimated_stepping_batches/self.trainer.max_epochs)\n",
    "        \n",
    "        # self.log(\"global_step\", self.global_step, prog_bar=True)\n",
    "        # # self.log(\"epoch\", self.current_epoch, prog_bar=True)\n",
    "        # self.log(\"stepping_batches_of_one_epoch\", self.trainer.estimated_stepping_batches/self.trainer.max_epochs, prog_bar=True)\n",
    "        \n",
    "        # print()\n",
    "        # print(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    @override    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        # return torch.optim.SGD(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # return torch.optim.SGD(self.cls_model.parameters(), lr=self.hparams.learning_rate)\n",
    "        # print(\"Learning Rate:\", self.hparams.learning_rate)\n",
    "        # return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # return torch.optim.AdamW(self.cls_model.parameters(), lr=self.hparams.learning_rate)\n",
    "        \n",
    "        # optimizer = optim.SGD(self.cls_model.parameters(), lr=self.hparams.learning_rate)\n",
    "        # print(len(list(self.parameters())))\n",
    "        \n",
    "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, self.parameters()),\n",
    "                                lr=self.hparams.learning_rate)\n",
    "        # optimizer = optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # optimizer = FusedLamb(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # optimizer = DeepSpeedCPUAdam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # optimizer = FusedAdam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=self.hparams.learning_rate/10, \n",
    "        #                                               max_lr=self.hparams.learning_rate)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html\n",
    "        # https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling#9.CosineAnnealingWarmRestarts\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "        # return ([optimizer], [scheduler])\n",
    "        return optimizer\n",
    "        # return ([optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}])\n",
    "        # return L.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    # 现在我们已经定义好Training的逻辑了，已经可以跑训练了。然而，除了训练之外，我们需要评测模型的性能。\n",
    "    # @override\n",
    "    # def \n",
    "    def on_evaluation_epoch_start(self, stage:str=\"\"):\n",
    "        self.evaluation_steps_outputs = dict()\n",
    "        self.evaluation_steps_outputs[f'{stage}_batch_probs'] = []\n",
    "        self.evaluation_steps_outputs[f'{stage}_label_tensor'] = []\n",
    "            \n",
    "    def evaluation_step(self, batch, batch_idx=None, stage:str=\"\", *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        image_tensor, label_tensor = batch\n",
    "        batch_probs = self(image_tensor)\n",
    "        append_dict_list(self.evaluation_steps_outputs, f'{stage}_batch_probs', ensure_array(batch_probs))\n",
    "        append_dict_list(self.evaluation_steps_outputs, f'{stage}_label_tensor', ensure_array(label_tensor))\n",
    "        batch_loss = self.loss(batch_probs, label_tensor)\n",
    "        self.log(f\"{stage}_loss\", batch_loss, prog_bar=True)\n",
    "        return batch_loss\n",
    "            \n",
    "    def on_evaluation_epoch_end(self, stage:str=\"\"):\n",
    "        # https://github.com/Lightning-AI/pytorch-lightning/discussions/9845\n",
    "        # labels = self.lit_data.classes\n",
    "        labels = list(range(self.lit_data.num_of_classes))\n",
    "        # labels = None\n",
    "        # print(labels)\n",
    "        # stack 是 new axis， concat是existing axis\n",
    "        all_pred_probs = np.concatenate(self.evaluation_steps_outputs[f'{stage}_batch_probs'])\n",
    "        all_label_tensor = np.concatenate(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n",
    "        # logger.debug(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n",
    "        # logger.debug(all_label_tensor)\n",
    "        eval_dict = compute_classification_metrics(all_label_tensor, all_pred_probs, \n",
    "                                                #    logits_to_prob=False, \n",
    "                                                   logits_to_prob=True, \n",
    "                                                labels=labels)\n",
    "        eval_dict = {f\"{stage}_{k}\": v for k,v in eval_dict.items()}\n",
    "        self.log_dict(eval_dict)\n",
    "        # tensorboard 可视化\n",
    "        # draw_classification_metrics\n",
    "        figures, figure_names = draw_classification_metrics(all_label_tensor, all_pred_probs, \n",
    "                                              logits_to_prob=True, \n",
    "                                                labels=labels)\n",
    "        # TODO: bug\n",
    "        # tb_logger = self.get_logger_with_type(pl_loggers.TensorBoardLogger).experiment\n",
    "        tb_logger = self.trainer.loggers[0].experiment\n",
    "        for fig, name in zip(figures, figure_names):\n",
    "            tb_logger.add_figure(f\"{stage}/{name}\", fig, self.global_step)\n",
    "        # tb_logger.add_pr_curve(f\"{stage}/pr_curve\", all_label_tensor, all_pred_probs, self.global_step)\n",
    "        \n",
    "        \n",
    "        self.evaluation_steps_outputs.clear()\n",
    "        \n",
    "    def get_logger_with_type(self, t:type = pl_loggers.TensorBoardLogger)->pl_loggers.Logger:\n",
    "        # Get tensorboard logger\n",
    "        target_logger = None\n",
    "        for logger in self.trainer.loggers:\n",
    "            if isinstance(logger, t):\n",
    "                target_logger = logger\n",
    "                break\n",
    "        return target_logger\n",
    "\n",
    "    @override\n",
    "    def on_validation_epoch_start(self):\n",
    "        return self.on_evaluation_epoch_start(stage=\"val\")\n",
    "    \n",
    "    @override\n",
    "    def on_test_epoch_start(self):\n",
    "        return self.on_evaluation_epoch_start(stage=\"test\")\n",
    "\n",
    "    @override\n",
    "    def on_validation_epoch_end(self):\n",
    "        return self.on_evaluation_epoch_end(stage=\"val\")\n",
    "\n",
    "    @override\n",
    "    def on_test_epoch_end(self):\n",
    "        return self.on_evaluation_epoch_end(stage=\"test\")\n",
    "\n",
    "    @override\n",
    "    def validation_step(self, batch, batch_idx=None, *args, **kwargs):\n",
    "        return self.evaluation_step(batch, batch_idx, stage=\"val\")\n",
    "\n",
    "    @override\n",
    "    def test_step(self, batch, batch_idx=None, *args, **kwargs):\n",
    "        return self.evaluation_step(batch, batch_idx, stage=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Tue 2024-12-03 01:49:15.416953</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mTue 2024-12-03 01:49:15.416953\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Seed set to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                                   <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">seed.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py#54\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Seed set to \u001b[1;36m0\u001b[0m                                                                                   \u001b]8;id=225948;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py\u001b\\\u001b[2mseed.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=371786;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py#54\u001b\\\u001b[2m54\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Tue 2024-12-03 01:49:16.492410</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mTue 2024-12-03 01:49:16.492410\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ╭──────────────────────────── Model Tree for ClassificationTask ─────────────────────────────╮ <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "         │ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>                                                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>                                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>                                                                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, </span> │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │   <span style=\"color: #008080; text-decoration-color: #008080\">768]</span>                                                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>                                      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>                                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>                  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] </span>          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   │               <span style=\"color: #008080; text-decoration-color: #008080\">bias:[768]</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>                                  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>                                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m ╭──────────────────────────── Model Tree for ClassificationTask ─────────────────────────────╮ \u001b]8;id=271493;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\u001b\\\u001b[2mtorch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=536110;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n",
       "         │ \u001b[37mroot\u001b[0m                                                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ └── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m                                                           │ \u001b[2m           \u001b[0m\n",
       "         │     ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m                                                                │ \u001b[2m           \u001b[0m\n",
       "         │     │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, \u001b[0m │ \u001b[2m           \u001b[0m\n",
       "         │     │   │   \u001b[36m768]\u001b[0m                                                                           │ \u001b[2m           \u001b[0m\n",
       "         │     │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m                                      │ \u001b[2m           \u001b[0m\n",
       "         │     │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m                 │ \u001b[2m           \u001b[0m\n",
       "         │     │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m                                                           │ \u001b[2m           \u001b[0m\n",
       "         │     │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │     │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                           │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                   │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m       │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                         │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                     │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m                  │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                 │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m                   │ \u001b[2m           \u001b[0m\n",
       "         │     │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m          │ \u001b[2m           \u001b[0m\n",
       "         │     │   │               \u001b[36mbias:[768]\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │     │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                                  │ \u001b[2m           \u001b[0m\n",
       "         │     │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │     │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                                │ \u001b[2m           \u001b[0m\n",
       "         │     └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m                                         │ \u001b[2m           \u001b[0m\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Tue 2024-12-03 01:49:16.512205</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mTue 2024-12-03 01:49:16.512205\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-style: italic\">               Model ClassificationTask's Trainable Parameters Inspection               </span>       <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#55\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55</span></a>\n",
       "         ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ┃<span style=\"font-weight: bold\"> Number of Trainable Parameters </span>┃<span style=\"font-weight: bold\"> Number of Total Parameters  </span>┃<span style=\"font-weight: bold\"> Trainable Ratio (0-1) </span>┃       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │<span style=\"color: #008080; text-decoration-color: #008080\">    8.647e+07 (3.459e+08 bytes) </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 8.647e+07 (3.459e+08 bytes) </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             1.000e+00 </span>│       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         └────────────────────────────────┴─────────────────────────────┴───────────────────────┘       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m \u001b[3m               Model ClassificationTask's Trainable Parameters Inspection               \u001b[0m       \u001b]8;id=318046;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\u001b\\\u001b[2mtorch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=499748;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
       "         ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓       \u001b[2m           \u001b[0m\n",
       "         ┃\u001b[1m \u001b[0m\u001b[1mNumber of Trainable Parameters\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNumber of Total Parameters \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrainable Ratio (0-1)\u001b[0m\u001b[1m \u001b[0m┃       \u001b[2m           \u001b[0m\n",
       "         ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩       \u001b[2m           \u001b[0m\n",
       "         │\u001b[36m \u001b[0m\u001b[36m   8.647e+07 (3.459e+08 bytes)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m8.647e+07 (3.459e+08 bytes)\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            1.000e+00\u001b[0m\u001b[32m \u001b[0m│       \u001b[2m           \u001b[0m\n",
       "         └────────────────────────────────┴─────────────────────────────┴───────────────────────┘       \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = ClassificationTaskConfig(\n",
    "    # learning_rate=1e-3,\n",
    "    learning_rate=3e-4,\n",
    "    # learning_rate=1,\n",
    "    # learning_rate=1e9,\n",
    "    label_smoothing=0,\n",
    ")\n",
    "config\n",
    "cls_task = ClassificationTask(config)\n",
    "cls_task.print_model_pretty()\n",
    "cls_task.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:46.321794</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:46.321794\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Before 约取 <span style=\"font-weight: bold\">(</span>YueQu<span style=\"font-weight: bold\">)</span> , the model structure is:                                                <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nucleus.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Before 约取 \u001b[1m(\u001b[0mYueQu\u001b[1m)\u001b[0m , the model structure is:                                                \u001b]8;id=611720;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\u001b\\\u001b[2mnucleus.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=934973;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:46.343212</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:46.343212\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ╭───────────────────────────────── Model Tree for ViTModel ──────────────────────────────────╮ <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "         │ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>                                                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>                                              │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>                                                                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>                          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>                                          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>                                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>                                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m ╭───────────────────────────────── Model Tree for ViTModel ──────────────────────────────────╮ \u001b]8;id=295528;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\u001b\\\u001b[2mtorch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146534;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n",
       "         │ \u001b[37mroot\u001b[0m                                                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m     │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m                                              │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m                         │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m                                                                   │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                                   │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                           │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m               │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                        │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m                          │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m                           │ \u001b[2m           \u001b[0m\n",
       "         │ │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m        │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                                          │ \u001b[2m           \u001b[0m\n",
       "         │ └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m                                                                     │ \u001b[2m           \u001b[0m\n",
       "         │     └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m                                        │ \u001b[2m           \u001b[0m\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:46.356692</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:46.356692\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using `wave_high_shoulder` Algorithm from `The Deprecated bo_guan_yue_qu` Library.           <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nucleus.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Using `wave_high_shoulder` Algorithm from `The Deprecated bo_guan_yue_qu` Library.           \u001b]8;id=262674;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\u001b\\\u001b[2mnucleus.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953938;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:46.820801</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:46.820801\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> After 约取 <span style=\"font-weight: bold\">(</span>YueQu<span style=\"font-weight: bold\">)</span> , the model structure is:                                                 <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nucleus.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m After 约取 \u001b[1m(\u001b[0mYueQu\u001b[1m)\u001b[0m , the model structure is:                                                 \u001b]8;id=945989;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\u001b\\\u001b[2mnucleus.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=154100;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:46.968993</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:46.968993\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ╭─────────────────────── Model Tree for AlignedResidualWaveHighMaker ────────────────────────╮ <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "         │ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>                                                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">mountain </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>                                                                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #004664; text-decoration-color: #004664\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span> │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>                                          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 3, 16, 16] bias:[768]</span>                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>                                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[3072, 768] bias:[3072]</span>                      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 3072] bias:[768]</span>                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768] bias:[768]</span>    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768] bias:[768]</span>                                      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>                                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>                                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">waver </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>                                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 192] position_embeddings:[1, 197, 192]</span> │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>                                          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 3, 16, 16] bias:[192]</span>                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>                                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 192] bias:[768]</span>                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 768] bias:[192]</span>                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192] bias:[192]</span>    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192] bias:[192]</span>                                      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>                                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>                                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">mountain_peaks </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>                            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[3072, 768] bias:[3072]</span>                              │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 3072] bias:[768]</span>                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768] bias:[768]</span>            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">wavers </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                                    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>                            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 192] bias:[768]</span>                                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 768] bias:[192]</span>                                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192] bias:[192]</span>            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">mountain_peak_hooks </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │   └── <span style=\"color: #800000; text-decoration-color: #800000\">0-35</span><span style=\"color: #008000; text-decoration-color: #008000\">(PostAddHook)</span>                                                                  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">side_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>                                                          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>                                                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>                                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>                                                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 192] bias:[192]</span>                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 192] bias:[768]</span>                            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 768] bias:[192]</span>                            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192] bias:[192]</span>        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │ └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">waver_hooks </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>                                                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │     └── <span style=\"color: #800000; text-decoration-color: #800000\">0-35</span><span style=\"color: #008000; text-decoration-color: #008000\">(DimensionAdapterHook)</span>                                                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │         ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[192, 768]</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │         └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">decoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 192]</span>                                             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m ╭─────────────────────── Model Tree for AlignedResidualWaveHighMaker ────────────────────────╮ \u001b]8;id=942500;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\u001b\\\u001b[2mtorch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=891786;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n",
       "         │ \u001b[37mroot\u001b[0m                                                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mmountain \u001b[0m\u001b[32m(ViTModel)\u001b[0m                                                                    │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[38;2;0;70;100mcls_token:[1, 1, 768] \u001b[0m\u001b[38;2;0;70;100mposition_embeddings:[1, 197, 768]\u001b[0m │ \u001b[2m           \u001b[0m\n",
       "         │ │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m                                          │ \u001b[2m           \u001b[0m\n",
       "         │ │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 3, 16, 16] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                     │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m                                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m           │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                    │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                         │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[3072, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[3072]\u001b[0m                      │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 3072] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                       │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m    │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                                      │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m                                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                                    │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mwaver \u001b[0m\u001b[32m(ViTModel)\u001b[0m                                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 192] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 192]\u001b[0m │ \u001b[2m           \u001b[0m\n",
       "         │ │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m                                          │ \u001b[2m           \u001b[0m\n",
       "         │ │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[192, 3, 16, 16] \u001b[0m\u001b[36mbias:[192]\u001b[0m                     │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m                                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m           │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                    │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                         │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 192] \u001b[0m\u001b[36mbias:[768]\u001b[0m                        │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 768] \u001b[0m\u001b[36mbias:[192]\u001b[0m                        │ \u001b[2m           \u001b[0m\n",
       "         │ │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[192] \u001b[0m\u001b[36mbias:[192]\u001b[0m    │ \u001b[2m           \u001b[0m\n",
       "         │ │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                                      │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m                                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                                    │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mmountain_peaks \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                            │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                   │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │       │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                            │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[3072, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[3072]\u001b[0m                              │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 3072] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m                               │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m            │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mwavers \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                                    │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                               │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                   │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                                     │ \u001b[2m           \u001b[0m\n",
       "         │ │       │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                            │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 192] \u001b[0m\u001b[36mbias:[768]\u001b[0m                                │ \u001b[2m           \u001b[0m\n",
       "         │ │       ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │       │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 768] \u001b[0m\u001b[36mbias:[192]\u001b[0m                                │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[192] \u001b[0m\u001b[36mbias:[192]\u001b[0m            │ \u001b[2m           \u001b[0m\n",
       "         │ ├── \u001b[37mmountain_peak_hooks \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                       │ \u001b[2m           \u001b[0m\n",
       "         │ │   └── \u001b[31m0-35\u001b[0m\u001b[32m(PostAddHook)\u001b[0m                                                                  │ \u001b[2m           \u001b[0m\n",
       "         │ │       └── \u001b[37mside_model \u001b[0m\u001b[32m(ViTLayer)\u001b[0m                                                          │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m                                                   │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m                                           │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m               │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m                                                 │ \u001b[2m           \u001b[0m\n",
       "         │ │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 192] \u001b[0m\u001b[36mbias:[192]\u001b[0m                        │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 192] \u001b[0m\u001b[36mbias:[768]\u001b[0m                            │ \u001b[2m           \u001b[0m\n",
       "         │ │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │ │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 768] \u001b[0m\u001b[36mbias:[192]\u001b[0m                            │ \u001b[2m           \u001b[0m\n",
       "         │ │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[192] \u001b[0m\u001b[36mbias:[192]\u001b[0m        │ \u001b[2m           \u001b[0m\n",
       "         │ └── \u001b[37mwaver_hooks \u001b[0m\u001b[32m(ModuleList)\u001b[0m                                                               │ \u001b[2m           \u001b[0m\n",
       "         │     └── \u001b[31m0-35\u001b[0m\u001b[32m(DimensionAdapterHook)\u001b[0m                                                         │ \u001b[2m           \u001b[0m\n",
       "         │         ├── \u001b[37mencoder \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[192, 768]\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         │         └── \u001b[37mdecoder \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 192]\u001b[0m                                             │ \u001b[2m           \u001b[0m\n",
       "         ╰────────────────────────────────────────────────────────────────────────────────────────────╯ \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:47.015525</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:47.015525\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The parameter efficiency of wave_high_shoulder is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.109e-01</span>.                                 <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nucleus.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m The parameter efficiency of wave_high_shoulder is \u001b[1;36m3.109e-01\u001b[0m.                                 \u001b]8;id=105592;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py\u001b\\\u001b[2mnucleus.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=370977;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/nucleus.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 04:59:47.022836</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 04:59:47.022836\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-style: italic\">               Model ClassificationTask's Trainable Parameters Inspection               </span>       <a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#55\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55</span></a>\n",
       "         ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ┃<span style=\"font-weight: bold\"> Number of Trainable Parameters </span>┃<span style=\"font-weight: bold\"> Number of Total Parameters  </span>┃<span style=\"font-weight: bold\"> Trainable Ratio (0-1) </span>┃       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         │<span style=\"color: #008080; text-decoration-color: #008080\">    2.693e+07 (1.077e+08 bytes) </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 1.133e+08 (4.533e+08 bytes) </span>│<span style=\"color: #008000; text-decoration-color: #008000\">             2.377e-01 </span>│       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "         └────────────────────────────────┴─────────────────────────────┴───────────────────────┘       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m \u001b[3m               Model ClassificationTask's Trainable Parameters Inspection               \u001b[0m       \u001b]8;id=957361;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py\u001b\\\u001b[2mtorch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=214410;file:///home/ycm/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/logging/torch.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
       "         ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓       \u001b[2m           \u001b[0m\n",
       "         ┃\u001b[1m \u001b[0m\u001b[1mNumber of Trainable Parameters\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNumber of Total Parameters \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrainable Ratio (0-1)\u001b[0m\u001b[1m \u001b[0m┃       \u001b[2m           \u001b[0m\n",
       "         ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩       \u001b[2m           \u001b[0m\n",
       "         │\u001b[36m \u001b[0m\u001b[36m   2.693e+07 (1.077e+08 bytes)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m1.133e+08 (4.533e+08 bytes)\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m            2.377e-01\u001b[0m\u001b[32m \u001b[0m│       \u001b[2m           \u001b[0m\n",
       "         └────────────────────────────────┴─────────────────────────────┴───────────────────────┘       \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from boguan_yuequ.auto.nucleus import AutoYueQuAlgorithm\n",
    "# AutoYueQuAlgorithm(cls_task, config.yuequ, config.yuequ_pe)\n",
    "# AutoYueQuAlgorithm(cls_task, \"wave_high_shoulder\") # TODO 对 lightning module做peft的hook会出bug\n",
    "cls_task.cls_model.backbone = AutoYueQuAlgorithm(cls_task.cls_model.backbone, \"wave_high_shoulder\").adapted_module\n",
    "# AutoYueQuAlgorithm(cls_task, \"wave_high_ladder\")\n",
    "cls_task.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "trainer = L.Trainer()\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "tuner = Tuner(trainer)\n",
    "found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "                                          mode='binsearch', \n",
    "                                          init_val=64)\n",
    "found_batch_size, cls_task.lit_data.hparams.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "lr_finder = tuner.lr_find(cls_task, datamodule=cls_task.lit_data, max_lr=1e-2)\n",
    "print(lr_finder.results)\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "new_lr = lr_finder.suggestion()\n",
    "new_lr, cls_task.hparams.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 64\u001b[0m\u001b[1;36m0x480\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @patch\n",
    "# def get_early_stop_callback(self: ClassificationTask, monitor='valid_loss', min_delta=0, patience=1, mode='min'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thunder\n",
    "import torch\n",
    "import thunder\n",
    "# # complied_cls_task = thunder.jit(cls_task)\n",
    "# # cls_task.cls_model = thunder.jit(cls_task.cls_model)\n",
    "# # cls_task.cls_model.backbone = thunder.compile(cls_task.cls_model.backbone)\n",
    "# cls_task.optimizer_step = thunder.jit(cls_task.optimizer_step)\n",
    "# cls_task.training_step = thunder.jit(cls_task.training_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# size = cls_task.cls_model.image_preprocessor.size['height']\n",
    "# cls_task.example_input_array = torch.Tensor(1, cls_task.cls_model.backbone.config.num_channels, size, size)\n",
    "cls_task.example_input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.910440</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.910440\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Trainer will use only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> GPUs because it is running inside an interactive <span style=\"color: #800080; text-decoration-color: #800080\">/</span> notebook   <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "         environment. You may try to set `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Trainer</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">devices</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>` but please note that multi-GPU inside <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "         interactive <span style=\"color: #800080; text-decoration-color: #800080\">/</span> notebook environments is considered experimental and unstable. Your mileage  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "         may vary.                                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Trainer will use only \u001b[1;36m1\u001b[0m of \u001b[1;36m8\u001b[0m GPUs because it is running inside an interactive \u001b[35m/\u001b[0m notebook   \u001b]8;id=546678;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=273145;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "         environment. You may try to set `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdevices\u001b[0m=\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m` but please note that multi-GPU inside \u001b[2m               \u001b[0m\n",
       "         interactive \u001b[35m/\u001b[0m notebook environments is considered experimental and unstable. Your mileage  \u001b[2m               \u001b[0m\n",
       "         may vary.                                                                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.918823</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.918823\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Trainer already configured with model summary callbacks: <span style=\"font-weight: bold\">[&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>                          <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">'lightning.pytorch.callbacks.model_summary.ModelSummary'</span><span style=\"font-weight: bold\">&gt;]</span>. Skipping setting a default     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "         `ModelSummary` callback.                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Trainer already configured with model summary callbacks: \u001b[1m[\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                          \u001b]8;id=960489;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=14723;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "         \u001b[32m'lightning.pytorch.callbacks.model_summary.ModelSummary'\u001b[0m\u001b[1m>\u001b[0m\u001b[1m]\u001b[0m. Skipping setting a default     \u001b[2m               \u001b[0m\n",
       "         `ModelSummary` callback.                                                                   \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.955500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.955500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                                     <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                     \u001b]8;id=744754;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=864912;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.960848</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.960848\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores                                                   <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                   \u001b]8;id=641620;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=517553;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.965630</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.965630\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs                                                        <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                        \u001b]8;id=765752;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341001;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:56.970531</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:56.970531\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running in `fast_dev_run` mode: will run the requested loop using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">batch</span><span style=\"font-weight: bold\">(</span>es<span style=\"font-weight: bold\">)</span>. Logging and <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "         checkpointing is suppressed.                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Running in `fast_dev_run` mode: will run the requested loop using \u001b[1;36m1\u001b[0m \u001b[1;35mbatch\u001b[0m\u001b[1m(\u001b[0mes\u001b[1m)\u001b[0m. Logging and \u001b]8;id=961564;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=595078;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "         checkpointing is suppressed.                                                               \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:00:59.892093</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:00:59.892093\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> LOCAL_RANK: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> - CUDA_VISIBLE_DEVICES: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span>                                         <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cuda.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m LOCAL_RANK: \u001b[1;36m0\u001b[0m - CUDA_VISIBLE_DEVICES: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m                                         \u001b]8;id=842194;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py\u001b\\\u001b[2mcuda.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=569366;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name                                   | Type                         | Params | Mode  | In sizes         | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | cls_model                              | HuggingfaceModel             | 113 M  | train | [1, 3, 224, 224] | [1, 100] \n",
      "1 | cls_model.backbone                     | AlignedResidualWaveHighMaker | 113 M  | train | [1, 3, 224, 224] | ?        \n",
      "2 | cls_model.backbone.mountain            | ViTModel                     | 86.4 M | train | [1, 3, 224, 224] | ?        \n",
      "3 | cls_model.backbone.waver               | ViTModel                     | 5.6 M  | eval  | ?                | ?        \n",
      "4 | cls_model.backbone.mountain_peak_hooks | ModuleList                   | 16.0 M | eval  | ?                | ?        \n",
      "5 | cls_model.backbone.waver_hooks         | ModuleList                   | 10.6 M | eval  | ?                | ?        \n",
      "6 | cls_model.head                         | Linear                       | 76.9 K | train | [1, 768]         | [1, 100] \n",
      "7 | softmax                                | Identity                     | 0      | train | [1, 100]         | [1, 100] \n",
      "8 | loss                                   | CrossEntropyLoss             | 0      | train | ?                | ?        \n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "26.9 M    Trainable params\n",
      "86.4 M    Non-trainable params\n",
      "113 M     Total params\n",
      "453.285   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">Mon 2024-12-02 05:01:00.436257</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36mMon 2024-12-02 05:01:00.436257\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                                        <a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_summary.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py#94\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">94</span></a>\n",
       "           | Name                                   | Type                         | Params |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         Mode  | In sizes         | Out sizes                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         -------------------------------------------------------------------------------------- <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         -----------------------------------------                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | cls_model                              | HuggingfaceModel             | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> M  |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">]</span> | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">]</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | cls_model.backbone                     | AlignedResidualWaveHighMaker | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> M  |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">]</span> | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> | cls_model.backbone.mountain            | ViTModel                     | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86.4</span> M |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">]</span> | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> | cls_model.backbone.waver               | ViTModel                     | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.6</span> M  |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         eval  | ?                | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> | cls_model.backbone.mountain_peak_hooks | ModuleList                   | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.0</span> M |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         eval  | ?                | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> | cls_model.backbone.waver_hooks         | ModuleList                   | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.6</span> M |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         eval  | ?                | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> | cls_model.head                         | Linear                       | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.9</span> K |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">]</span>         | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">]</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> | softmax                                | Identity                     | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">]</span>         | <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">]</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> | loss                                   | CrossEntropyLoss             | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      |   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         train | ?                | ?                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         -------------------------------------------------------------------------------------- <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         -----------------------------------------                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.9</span> M    Trainable params                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86.4</span> M    Non-trainable params                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> M     Total params                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">453.285</span>   Total estimated model params size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m                                                                                        \u001b]8;id=917595;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py\u001b\\\u001b[2mmodel_summary.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=532614;file:///home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py#94\u001b\\\u001b[2m94\u001b[0m\u001b]8;;\u001b\\\n",
       "           | Name                                   | Type                         | Params |   \u001b[2m                   \u001b[0m\n",
       "         Mode  | In sizes         | Out sizes                                                   \u001b[2m                   \u001b[0m\n",
       "         -------------------------------------------------------------------------------------- \u001b[2m                   \u001b[0m\n",
       "         -----------------------------------------                                              \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m0\u001b[0m | cls_model                              | HuggingfaceModel             | \u001b[1;36m113\u001b[0m M  |   \u001b[2m                   \u001b[0m\n",
       "         train | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m1\u001b[0m | cls_model.backbone                     | AlignedResidualWaveHighMaker | \u001b[1;36m113\u001b[0m M  |   \u001b[2m                   \u001b[0m\n",
       "         train | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m2\u001b[0m | cls_model.backbone.mountain            | ViTModel                     | \u001b[1;36m86.4\u001b[0m M |   \u001b[2m                   \u001b[0m\n",
       "         train | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m3\u001b[0m | cls_model.backbone.waver               | ViTModel                     | \u001b[1;36m5.6\u001b[0m M  |   \u001b[2m                   \u001b[0m\n",
       "         eval  | ?                | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m4\u001b[0m | cls_model.backbone.mountain_peak_hooks | ModuleList                   | \u001b[1;36m16.0\u001b[0m M |   \u001b[2m                   \u001b[0m\n",
       "         eval  | ?                | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m5\u001b[0m | cls_model.backbone.waver_hooks         | ModuleList                   | \u001b[1;36m10.6\u001b[0m M |   \u001b[2m                   \u001b[0m\n",
       "         eval  | ?                | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m6\u001b[0m | cls_model.head                         | Linear                       | \u001b[1;36m76.9\u001b[0m K |   \u001b[2m                   \u001b[0m\n",
       "         train | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m         | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m7\u001b[0m | softmax                                | Identity                     | \u001b[1;36m0\u001b[0m      |   \u001b[2m                   \u001b[0m\n",
       "         train | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m         | \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m8\u001b[0m | loss                                   | CrossEntropyLoss             | \u001b[1;36m0\u001b[0m      |   \u001b[2m                   \u001b[0m\n",
       "         train | ?                | ?                                                           \u001b[2m                   \u001b[0m\n",
       "         -------------------------------------------------------------------------------------- \u001b[2m                   \u001b[0m\n",
       "         -----------------------------------------                                              \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m26.9\u001b[0m M    Trainable params                                                             \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m86.4\u001b[0m M    Non-trainable params                                                         \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m113\u001b[0m M     Total params                                                                 \u001b[2m                   \u001b[0m\n",
       "         \u001b[1;36m453.285\u001b[0m   Total estimated model params size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m                                       \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fe934be04f4fce9babef2b83de3422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "optimizer_step",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 22\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSummary\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(default_root_dir\u001b[38;5;241m=\u001b[39mruns_path, enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m                     enable_model_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      7\u001b[0m                     \u001b[38;5;66;03m# num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[38;5;66;03m# limit_val_batches=5\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                     )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1030\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1030\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         closure()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:159\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    162\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/__init__.py:774\u001b[0m, in \u001b[0;36mjit.<locals>.update_call_statistics.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m cs\u001b[38;5;241m.\u001b[39mlast_trace_host_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    776\u001b[0m     cs\u001b[38;5;241m.\u001b[39mlast_trace_host_stop \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/__init__.py:824\u001b[0m, in \u001b[0;36mjit.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     _recursive_jit_call_warning()\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m cache_entry, inps, pro_to_epi \u001b[38;5;241m=\u001b[39m \u001b[43mget_computation_and_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m check_storage_aliases(cache_entry, inps)\n\u001b[1;32m    828\u001b[0m result \u001b[38;5;241m=\u001b[39m cache_entry\u001b[38;5;241m.\u001b[39mcomputation_fn(\u001b[38;5;241m*\u001b[39minps)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/__init__.py:756\u001b[0m, in \u001b[0;36mjit.<locals>.decorate_computation_function.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 756\u001b[0m     cache_entry, inps, pro_to_epi \u001b[38;5;241m=\u001b[39m \u001b[43mget_computation_and_inputs_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m     decorated_computation_fn \u001b[38;5;241m=\u001b[39m cache_entry\u001b[38;5;241m.\u001b[39mcomputation_fn\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m decorator \u001b[38;5;129;01min\u001b[39;00m decorators:\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/langctxs.py:136\u001b[0m, in \u001b[0;36mlangctx.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     tok \u001b[38;5;241m=\u001b[39m set_langctx(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangctx)\n\u001b[0;32m--> 136\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/__init__.py:236\u001b[0m, in \u001b[0;36m_with_cache_info_ctx.<locals>.cache_info_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m tok \u001b[38;5;241m=\u001b[39m _cache_info_ctx\u001b[38;5;241m.\u001b[39mset({})\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     _cache_info_ctx\u001b[38;5;241m.\u001b[39mreset(tok)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/__init__.py:529\u001b[0m, in \u001b[0;36mjit.<locals>.get_computation_and_inputs\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m prologue_trc: TraceCtx\n\u001b[1;32m    528\u001b[0m computation_trc: TraceCtx\n\u001b[0;32m--> 529\u001b[0m jit_results: TraceResults \u001b[38;5;241m=\u001b[39m \u001b[43mthunder_general_jit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mad_hoc_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_hoc_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharp_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharp_edges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m prologue_trc \u001b[38;5;241m=\u001b[39m jit_results\u001b[38;5;241m.\u001b[39mprologue_trace\n\u001b[1;32m    537\u001b[0m computation_trc \u001b[38;5;241m=\u001b[39m jit_results\u001b[38;5;241m.\u001b[39mcomputation_trace\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/jit_ext.py:1744\u001b[0m, in \u001b[0;36mthunder_general_jit\u001b[0;34m(fn, args, kwargs, sharp_edges, ad_hoc_executor)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jit_ctx(ctx):\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracectx(computation_trace):\n\u001b[0;32m-> 1744\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mjfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m         prims\u001b[38;5;241m.\u001b[39mpython_return(result)\n\u001b[1;32m   1746\u001b[0m         computation_trace\u001b[38;5;241m.\u001b[39mset_current_source_location(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/interpreter.py:7231\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   7229\u001b[0m \u001b[38;5;66;03m# The below is \"raise e\" but deleting e from the scope\u001b[39;00m\n\u001b[1;32m   7230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   7232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   7233\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m e\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/interpreter.py:7191\u001b[0m, in \u001b[0;36minterpret.<locals>.fn_.<locals>.getfn.<locals>.fn_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m   7190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_2\u001b[39m(args, kwargs):\n\u001b[0;32m-> 7191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/interpreter.py:6506\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 6506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1308\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1279\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1283\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \n\u001b[1;32m   1307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39moptimizer_closure)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/thunder/core/interpreter.py:6506\u001b[0m, in \u001b[0;36m_call_dispatch.<locals>._impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl\u001b[39m(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 6506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[0;31mAttributeError\u001b[0m: optimizer_step"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from namable_classify.infra import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "trainer = L.Trainer(default_root_dir=runs_path, enable_checkpointing=True, \n",
    "                    enable_model_summary=True, \n",
    "                    # num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\n",
    "                    num_sanity_val_steps=0, # 防止 val 在训了好久train才发现崩溃\n",
    "                    callbacks=[\n",
    "                        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "                        EarlyStopping(monitor=\"val_acc1\", mode=\"max\", check_finite=True, \n",
    "                                      patience=5, \n",
    "                                      check_on_train_epoch_end=False,  # check on validation end\n",
    "                                      verbose=True),\n",
    "                        ModelSummary(max_depth=3),\n",
    "                               ]\n",
    "                    , fast_dev_run=True\n",
    "                    , profiler='simple'\n",
    "                    # , limit_train_batches=10, \n",
    "                    # limit_val_batches=5\n",
    "                    )\n",
    "trainer.fit(cls_task, datamodule=cls_task.lit_data)\n",
    "# TODO 第二轮的时候，第一轮还OK的batch size就突然会崩溃，可能因为 Validation 引入了新的内存？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "│   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "│       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "│   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "│       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "│           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "│           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "│           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "│           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "│   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "│       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "│   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "│       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "│           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "│           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "│           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "│           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "│           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "│           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "│           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "└── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "cls_task.cls_model.backbone.print_model_pretty()\n",
    "cls_task.cls_model.backbone.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
