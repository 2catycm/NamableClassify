{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主流程文件 Main Training Script\n",
    "\n",
    "> 主训练脚本入口，调用各模块进行模型训练\n",
    "> \n",
    "> The main entry point for running training, orchestrating all modules for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description:\n",
    "main 模块是项目的主训练入口。它结合了 core 模块中的任务定义和 data 模块中的数据加载功能，通过调用 PyTorch Lightning 的 Trainer 对模型进行训练。用户可以通过配置类快速切换不同的数据集、模型和训练策略，灵活完成实验任务。\n",
    "\n",
    "The main module serves as the primary entry point for training. It combines task definitions from the core module and data loading from the data module to execute model training via PyTorch Lightning’s Trainer. Users can flexibly switch between different datasets, models, and training strategies through configuration classes to perform experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- Trainer: PyTorch Lightning 的训练控制器，用于管理训练过程。  \n",
    "  \n",
    "  Trainer: The PyTorch Lightning controller for managing the training process.\n",
    "\n",
    "- ClassificationTask: 从 core 导入，用于模型训练的主要任务类。\n",
    "  \n",
    "  ClassificationTask: Imported from core, the primary task class for model training.\n",
    "\n",
    "- CIFAR100DataModule: 从 data 导入的数据加载模块。\n",
    "  \n",
    "  CIFAR100DataModule: Data loading module imported from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "from namable_classify.core import ClassificationTask, ClassificationTaskConfig\n",
    "config = ClassificationTaskConfig()\n",
    "# config.learning_rate = 1e-1\n",
    "# config.learning_rate = 1\n",
    "# config.learning_rate = 1e-3\n",
    "# config.learning_rate = 1e-5\n",
    "config.learning_rate = 3e-4\n",
    "config.experiment_index = 1\n",
    "# config.experiment_index = 0\n",
    "# config.learning_rate = 1e-6\n",
    "config.dataset_config.batch_size = 64\n",
    "config.yuequ = \"LORA\"\n",
    "cls_task = ClassificationTask(config)\n",
    "cls_task.print_model_pretty()\n",
    "import torch\n",
    "# cls_task.cls_model = torch.compile(cls_task.cls_model, mode='reduce-overhead')\n",
    "#  fullgraph=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 约取 (YueQu) , the model structure is: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LORA Algorithm from Hugging Face PEFT Library. \n",
      "peft_config: LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False, r=8, target_modules=['query', 'value'], lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n",
      "After 约取 (YueQu) , the model structure is: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #004664; text-decoration-color: #004664\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">query,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear)</span>\n",
       "    │   │           │   │   │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">base_layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   │   │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora_dropout </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleDict)</span>\n",
       "    │   │           │   │   │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora_A </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleDict)</span>\n",
       "    │   │           │   │   │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">default </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[8, 768]</span>\n",
       "    │   │           │   │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora_B </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleDict)</span>\n",
       "    │   │           │   │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">default </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 8]</span>\n",
       "    │   │           │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">key </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[38;2;0;70;100mcls_token:[1, 1, 768] \u001b[0m\u001b[38;2;0;70;100mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 3, 16, 16] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   ├── \u001b[31mquery,value\u001b[0m\u001b[32m(Linear)\u001b[0m\n",
       "    │   │           │   │   │   ├── \u001b[37mbase_layer \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   │           │   │   │   ├── \u001b[37mlora_dropout \u001b[0m\u001b[32m(ModuleDict)\u001b[0m\n",
       "    │   │           │   │   │   ├── \u001b[37mlora_A \u001b[0m\u001b[32m(ModuleDict)\u001b[0m\n",
       "    │   │           │   │   │   │   └── \u001b[37mdefault \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[8, 768]\u001b[0m\n",
       "    │   │           │   │   │   └── \u001b[37mlora_B \u001b[0m\u001b[32m(ModuleDict)\u001b[0m\n",
       "    │   │           │   │   │       └── \u001b[37mdefault \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 8]\u001b[0m\n",
       "    │   │           │   │   └── \u001b[37mkey \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[3072, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 3072] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[768, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[100, 768] \u001b[0m\u001b[38;2;0;70;100mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<boguan_yuequ.auto.AutoYueQuAlgorithm>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from boguan_yuequ.auto import AutoYueQuAlgorithm\n",
    "AutoYueQuAlgorithm(cls_task, config.yuequ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# import lightning as L\n",
    "# trainer = L.Trainer()\n",
    "# from lightning.pytorch.tuner import Tuner\n",
    "# tuner = Tuner(trainer)\n",
    "# found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "#                                         #   mode='binsearch', \n",
    "#                                           mode='power', \n",
    "#                                           init_val=64)\n",
    "# # found_batch_size, cls_task.lit_data.hparams.batch_size\n",
    "# print(f\"Found batch size: {found_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from namable_classify.utils import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, StochasticWeightAveraging, DeviceStatsMonitor, LearningRateMonitor, LearningRateFinder\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger, WandbLogger\n",
    "\n",
    "trainer = L.Trainer(default_root_dir=runs_path, enable_checkpointing=True, \n",
    "                    enable_model_summary=True, \n",
    "                    num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\n",
    "                    callbacks=[\n",
    "                        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "                        EarlyStopping(monitor=\"val_acc1\", mode=\"max\", check_finite=True, \n",
    "                                      patience=5, \n",
    "                                    #   patience=6, \n",
    "                                      check_on_train_epoch_end=False,  # check on validation end\n",
    "                                      verbose=True),\n",
    "                        ModelSummary(max_depth=3),\n",
    "                        # https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/\n",
    "                        # StochasticWeightAveraging(swa_lrs=1e-2), \n",
    "                        # DeviceStatsMonitor(cpu_stats=True)\n",
    "                        LearningRateMonitor(), \n",
    "                        # LearningRateFinder() # 有奇怪的bug\n",
    "                               ]\n",
    "                    , max_epochs=15\n",
    "                    # , gradient_clip_val=1.0, gradient_clip_algorithm=\"value\"\n",
    "                    , logger=[\n",
    "                        # TensorBoardLogger(save_dir=runs_path/\"tensorboard\"),\n",
    "                        TensorBoardLogger(save_dir=runs_path),\n",
    "                              CSVLogger(save_dir=runs_path), \n",
    "                              WandbLogger(project=\"namable_classify\", name=\"test\")\n",
    "                              ]\n",
    "                    # , profiler=\"simple\"\n",
    "                    # , fast_dev_run=True\n",
    "                    # limit_train_batches=10, limit_val_batches=5\n",
    "                    # strategy=\"ddp\", accelerator=\"gpu\", devices=4\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19be3ed7e73649f886d8bb7c0958b2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.017378008287493765\n",
      "Restoring states from the checkpoint path at /home/ycm/repos/research/cv/cls/NamableClassify/runs/.lr_find_ad3e3fcd-e3ae-4687-bfdc-bf8fe013adae.ckpt\n",
      "Restored all states from the checkpoint at /home/ycm/repos/research/cv/cls/NamableClassify/runs/.lr_find_ad3e3fcd-e3ae-4687-bfdc-bf8fe013adae.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [1e-08, 1.4454397707459274e-08, 1.7378008287493753e-08, 2.0892961308540398e-08, 2.51188643150958e-08, 3.019951720402016e-08, 3.630780547701014e-08, 4.36515832240166e-08, 5.248074602497726e-08, 6.309573444801934e-08, 7.585775750291837e-08, 9.120108393559096e-08, 1.0964781961431852e-07, 1.3182567385564074e-07, 1.5848931924611133e-07, 1.9054607179632475e-07, 2.2908676527677735e-07, 2.7542287033381663e-07, 3.311311214825911e-07, 3.9810717055349735e-07, 4.786300923226383e-07, 5.75439937337157e-07, 6.918309709189366e-07, 8.317637711026709e-07, 1e-06, 1.2022644346174132e-06, 1.445439770745928e-06, 1.7378008287493761e-06, 2.089296130854039e-06, 2.5118864315095797e-06, 3.0199517204020163e-06, 3.630780547701014e-06, 4.365158322401661e-06, 5.248074602497728e-06, 6.3095734448019305e-06, 7.585775750291836e-06, 9.120108393559096e-06, 1.0964781961431852e-05, 1.3182567385564076e-05, 1.584893192461114e-05, 1.9054607179632464e-05, 2.2908676527677725e-05, 2.7542287033381663e-05, 3.311311214825911e-05, 3.9810717055349735e-05, 4.786300923226385e-05, 5.7543993733715664e-05, 6.918309709189363e-05, 8.317637711026709e-05, 0.0001, 0.00012022644346174131, 0.0001445439770745928, 0.00017378008287493763, 0.0002089296130854041, 0.0002511886431509582, 0.0003019951720402019, 0.000363078054770101, 0.0004365158322401656, 0.0005248074602497723, 0.000630957344480193, 0.0007585775750291836, 0.0009120108393559097, 0.0010964781961431851, 0.0013182567385564075, 0.001584893192461114, 0.0019054607179632484, 0.0022908676527677745, 0.002754228703338169, 0.003311311214825908, 0.003981071705534969, 0.00478630092322638, 0.005754399373371567, 0.006918309709189364, 0.008317637711026709, 0.01, 0.012022644346174132, 0.01445439770745928, 0.017378008287493765, 0.02089296130854041, 0.025118864315095822, 0.030199517204020192, 0.036307805477010104, 0.04365158322401657, 0.05248074602497723, 0.0630957344480193, 0.07585775750291836, 0.09120108393559097, 0.10964781961431852, 0.13182567385564073, 0.15848931924611143, 0.19054607179632482, 0.2290867652767775, 0.2754228703338169, 0.3311311214825908, 0.3981071705534969, 0.47863009232263803, 0.5754399373371567, 0.6918309709189363, 0.8317637711026709, 1.0], 'loss': [2.325226562191739, 3.096082132376061, 3.4786957451789484, 3.717662848449812, 3.8780207250207757, 3.991016281214811, 4.0743235814006535, 4.1432345089733404, 4.186326123479825, 4.229621125029844, 4.266493560833004, 4.294480277226498, 4.321283904521442, 4.343358301839008, 4.362096585521345, 4.381001171710784, 4.3949562929999795, 4.405894531733751, 4.419226767142044, 4.430836902334703, 4.441139717902997, 4.4504036975928765, 4.457426248087999, 4.468539320586264, 4.476286841857377, 4.4831283163204025, 4.487931732908091, 4.49541018382703, 4.502344752446788, 4.505020175318871, 4.510038314182386, 4.515116425032137, 4.519274799207367, 4.523742919076383, 4.529964021078124, 4.532627363373022, 4.536117241339296, 4.5400910148063085, 4.54280259774669, 4.546262520563015, 4.549540440535761, 4.552014087428331, 4.554360630183876, 4.556859280787789, 4.559167881134988, 4.561081276835529, 4.5618063975986445, 4.564193588568543, 4.5663909739091855, 4.568149725332161, 4.569406426491967, 4.570081571724817, 4.5726508759160565, 4.573887262467499, 4.5753744495932045, 4.57683580965695, 4.577022579778503, 4.5787941997515835, 4.579908210737345, 4.581673379520714, 4.583616012308409, 4.584895483531549, 4.585704474427733, 4.58563607268995, 4.585967496841652, 4.586413484204251, 4.586191935177786, 4.587461420620402, 4.58785768301003, 4.588094143355252, 4.588346118132271, 4.587992408259592, 4.586854793993819, 4.585482643896524, 4.583591074679543, 4.582011682694797, 4.5807761850192055, 4.577231250687714, 4.575104326497686, 4.5759020211611166, 4.578784029098214, 4.57954013302148, 4.579696222454319, 4.581838136826024, 4.585038379039125, 4.586387477529773, 4.5871633343994604, 4.588646110750362, 4.589548721679048, 4.591067410818058, 4.593113592624137, 4.595090108252007, 4.595595905853829, 4.595614736660589, 4.596110302089537, 4.597359135524393, 4.59816879120299, 4.598953923905629, 4.599565399498272, 4.6008406246518145]}\n",
      "New learning rate:  0.017378008287493765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "lr_finder = tuner.lr_find(cls_task, datamodule=cls_task.lit_data, \n",
    "                        #   max_lr=1e-2\n",
    "                        method = \"fit\",\n",
    "                        min_lr = 1e-8,\n",
    "                        # min_lr = 1e-4,\n",
    "    max_lr = 1,\n",
    "    # num_training = 10,\n",
    "    num_training = 100,\n",
    "    mode = \"exponential\"\n",
    "    # mode = \"linear\"\n",
    "                        \n",
    "                          )\n",
    "print(lr_finder.results)\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "from matplotlib import pyplot as plt\n",
    "from namable_classify.utils import runs_figs_path\n",
    "plt.savefig(runs_figs_path/'lr_finder.png')\n",
    "# fig.show()\n",
    "new_lr = lr_finder.suggestion()\n",
    "# new_lr, cls_task.hparams.learning_rate\n",
    "print(\"New learning rate: \", new_lr)\n",
    "\n",
    "cls_task.hparams.learning_rate = new_lr/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cls_model_config\": {'provider': 'huggingface', 'checkpoint': 'google/vit-base-patch16-224-in21k', 'head_strategy': 'linear', 'num_of_classes': -1}\n",
       "\"dataset_config\":   {'dataset_root': Path('/home/ycm/repos/research/cv/cls/NamableClassify/data'), 'dataset_name': 'CIFAR100', 'batch_size': 64}\n",
       "\"experiment_index\": 1\n",
       "\"label_smoothing\":  0.1\n",
       "\"learning_rate\":    1e-08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_task.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                          | Type             | Params | Mode  | In sizes                                                                                     | Out sizes    \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | cls_model                     | HuggingfaceModel | 86.8 M | train | [1, 3, 224, 224]                                                                             | [1, 100]     \n",
      "1 | cls_model.backbone            | ViTModel         | 86.7 M | train | [1, 3, 224, 224]                                                                             | ?            \n",
      "2 | cls_model.backbone.embeddings | ViTEmbeddings    | 742 K  | train | [[1, 3, 224, 224], '?', '?']                                                                 | [1, 197, 768]\n",
      "3 | cls_model.backbone.encoder    | ViTEncoder       | 85.3 M | train | [[1, 197, 768], ['?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?'], '?', '?', '?'] | ?            \n",
      "4 | cls_model.backbone.layernorm  | LayerNorm        | 1.5 K  | train | [1, 197, 768]                                                                                | [1, 197, 768]\n",
      "5 | cls_model.backbone.pooler     | ViTPooler        | 590 K  | train | [1, 197, 768]                                                                                | [1, 768]     \n",
      "6 | cls_model.head                | Linear           | 76.9 K | train | [1, 768]                                                                                     | [1, 100]     \n",
      "7 | softmax                       | Identity         | 0      | train | [1, 100]                                                                                     | [1, 100]     \n",
      "8 | loss                          | CrossEntropyLoss | 0      | train | ?                                                                                            | ?            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "294 K     Trainable params\n",
      "86.5 M    Non-trainable params\n",
      "86.8 M    Total params\n",
      "347.044   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c560fec858424da8975284ec8d65b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "trainer.fit(cls_task, datamodule=cls_task.lit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "trainer.test(cls_task, datamodule=cls_task.lit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2603119857\u001b[0m (\u001b[33mhandicraft-computing\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2b4b9bd7a347d9ae00adb36d62b56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111255028905968, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241024_181539-uib873wc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/handicraft-computing/namable_classify/runs/uib873wc' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/handicraft-computing/namable_classify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/handicraft-computing/namable_classify' target=\"_blank\">https://wandb.ai/handicraft-computing/namable_classify</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/handicraft-computing/namable_classify/runs/uib873wc' target=\"_blank\">https://wandb.ai/handicraft-computing/namable_classify/runs/uib873wc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ycm/repos/research/cv/cls/NamableClassify/deprecated/lightning_logs/version_53/checkpoints/epoch=11-step=8448.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "Loaded model weights from the checkpoint at /home/ycm/repos/research/cv/cls/NamableClassify/deprecated/lightning_logs/version_53/checkpoints/epoch=11-step=8448.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38e8dfd93148e09bdd090f6d11dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8862000107765198     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9904000163078308     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9470000267028809     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9950000047683716     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc3          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9667999744415283     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_acc5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9819999933242798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   val_balanced_accuracy   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8862000107765198     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_cohen_kappa      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8850504755973816     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8865798711776733     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_hinge_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3084784150123596     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_log_loss        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5307707786560059     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1550344228744507     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   val_matthews_corrcoef   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8851269483566284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8938026428222656     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_recall         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8862000107765198     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_roc_auc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9969171285629272     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8862000107765198    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9904000163078308    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9470000267028809    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9950000047683716    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc3         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9667999744415283    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_acc5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9819999933242798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  val_balanced_accuracy  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8862000107765198    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_cohen_kappa     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8850504755973816    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8865798711776733    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_hinge_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3084784150123596    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_log_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5307707786560059    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1550344228744507    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  val_matthews_corrcoef  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8851269483566284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8938026428222656    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_recall        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8862000107765198    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_roc_auc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9969171285629272    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.1550344228744507,\n",
       "  'val_acc1': 0.8862000107765198,\n",
       "  'val_acc2': 0.9470000267028809,\n",
       "  'val_acc3': 0.9667999744415283,\n",
       "  'val_acc5': 0.9819999933242798,\n",
       "  'val_acc10': 0.9904000163078308,\n",
       "  'val_acc20': 0.9950000047683716,\n",
       "  'val_roc_auc': 0.9969171285629272,\n",
       "  'val_matthews_corrcoef': 0.8851269483566284,\n",
       "  'val_f1': 0.8865798711776733,\n",
       "  'val_precision': 0.8938026428222656,\n",
       "  'val_recall': 0.8862000107765198,\n",
       "  'val_log_loss': 0.5307707786560059,\n",
       "  'val_balanced_accuracy': 0.8862000107765198,\n",
       "  'val_cohen_kappa': 0.8850504755973816,\n",
       "  'val_hinge_loss': 0.3084784150123596}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from namable_classify.utils import lib_repo_path\n",
    "# trainer.test(cls_task, datamodule=cls_task.lit_data, \n",
    "trainer.validate(cls_task, datamodule=cls_task.lit_data, \n",
    "             ckpt_path=lib_repo_path/\"deprecated/lightning_logs/version_53/checkpoints/epoch=11-step=8448.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
