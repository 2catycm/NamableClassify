{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主流程文件 Main Training Script\n",
    "\n",
    "> 主训练脚本入口，调用各模块进行模型训练\n",
    "> \n",
    "> The main entry point for running training, orchestrating all modules for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description:\n",
    "main 模块是项目的主训练入口。它结合了 core 模块中的任务定义和 data 模块中的数据加载功能，通过调用 PyTorch Lightning 的 Trainer 对模型进行训练。用户可以通过配置类快速切换不同的数据集、模型和训练策略，灵活完成实验任务。\n",
    "\n",
    "The main module serves as the primary entry point for training. It combines task definitions from the core module and data loading from the data module to execute model training via PyTorch Lightning’s Trainer. Users can flexibly switch between different datasets, models, and training strategies through configuration classes to perform experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- Trainer: PyTorch Lightning 的训练控制器，用于管理训练过程。  \n",
    "  \n",
    "  Trainer: The PyTorch Lightning controller for managing the training process.\n",
    "\n",
    "- ClassificationTask: 从 core 导入，用于模型训练的主要任务类。\n",
    "  \n",
    "  ClassificationTask: Imported from core, the primary task class for model training.\n",
    "\n",
    "- CIFAR100DataModule: 从 data 导入的数据加载模块。\n",
    "  \n",
    "  CIFAR100DataModule: Data loading module imported from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "from namable_classify.core import ClassificationTask, ClassificationTaskConfig\n",
    "config = ClassificationTaskConfig()\n",
    "# config.learning_rate = 1e-1\n",
    "# config.learning_rate = 1\n",
    "config.learning_rate = 1e-3\n",
    "# config.learning_rate = 3e-4\n",
    "# config.learning_rate = 1e-6\n",
    "config.dataset_config.batch_size = 64\n",
    "cls_task = ClassificationTask(config)\n",
    "cls_task.print_model_pretty()\n",
    "import torch\n",
    "# cls_task.cls_model = torch.compile(cls_task.cls_model, mode='reduce-overhead')\n",
    "#  fullgraph=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# import lightning as L\n",
    "# trainer = L.Trainer()\n",
    "# from lightning.pytorch.tuner import Tuner\n",
    "# tuner = Tuner(trainer)\n",
    "# found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "#                                         #   mode='binsearch', \n",
    "#                                           mode='power', \n",
    "#                                           init_val=64)\n",
    "# # found_batch_size, cls_task.lit_data.hparams.batch_size\n",
    "# print(f\"Found batch size: {found_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# lr_finder = tuner.lr_find(cls_task, datamodule=cls_task.lit_data, \n",
    "#                         #   max_lr=1e-2\n",
    "#                           )\n",
    "# print(lr_finder.results)\n",
    "\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# from matplotlib import pyplot as plt\n",
    "# from namable_classify.utils import runs_figs_path\n",
    "# plt.savefig(runs_figs_path/'lr_finder.png')\n",
    "# # fig.show()\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# # new_lr, cls_task.hparams.learning_rate\n",
    "# print(\"New learning rate: \", new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cls_task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoardLogger, CSVLogger\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(default_root_dir\u001b[38;5;241m=\u001b[39mruns_path, enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m                     enable_model_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     10\u001b[0m                     num_sanity_val_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# 防止 val 在训了好久train才发现崩溃\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[38;5;66;03m# strategy=\"ddp\", accelerator=\"gpu\", devices=4\u001b[39;00m\n\u001b[1;32m     28\u001b[0m                     )\n\u001b[0;32m---> 29\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\u001b[43mcls_task\u001b[49m, datamodule\u001b[38;5;241m=\u001b[39mcls_task\u001b[38;5;241m.\u001b[39mlit_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cls_task' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from namable_classify.utils import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, StochasticWeightAveraging, DeviceStatsMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "trainer = L.Trainer(default_root_dir=runs_path, enable_checkpointing=True, \n",
    "                    enable_model_summary=True, \n",
    "                    num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\n",
    "                    callbacks=[\n",
    "                        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "                        EarlyStopping(monitor=\"val_acc1\", mode=\"max\", check_finite=True, \n",
    "                                      patience=5, \n",
    "                                      check_on_train_epoch_end=False,  # check on validation end\n",
    "                                      verbose=True),\n",
    "                        ModelSummary(max_depth=3),\n",
    "                        # StochasticWeightAveraging(swa_lrs=1e-2), \n",
    "                        DeviceStatsMonitor(cpu_stats=True)\n",
    "                               ]\n",
    "                    \n",
    "                    # , gradient_clip_val=1.0, gradient_clip_algorithm=\"value\"\n",
    "                    , logger=[TensorBoardLogger(save_dir=runs_path/\"tensorboard\"), CSVLogger(save_dir=runs_path)]\n",
    "                    # , profiler=\"simple\"\n",
    "                    # , fast_dev_run=True\n",
    "                    # limit_train_batches=10, limit_val_batches=5\n",
    "                    # strategy=\"ddp\", accelerator=\"gpu\", devices=4\n",
    "                    )\n",
    "trainer.fit(cls_task, datamodule=cls_task.lit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
