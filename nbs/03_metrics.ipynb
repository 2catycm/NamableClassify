{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> tu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a brief description of the technical component, and an overview that links to the main symbols in the page (you might want to use doclinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'Warning'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlineno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Insert an entry into the list of warnings filters (at the front).\n",
      "\n",
      "'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n",
      "            or \"once\"\n",
      "'message' -- a regex that the warning message must match\n",
      "'category' -- a class that the warning must be a subclass of\n",
      "'module' -- a regex that the module name must match\n",
      "'lineno' -- an integer line number, 0 matches all warnings\n",
      "'append' -- if true, append to the list of filters\n",
      "\u001b[0;31mFile:\u001b[0m      ~/program_files/managers/conda/envs/hf_ai/lib/python3.10/warnings.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.utils import default_on_exception, ensure_array\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, top_k_accuracy_score, matthews_corrcoef, f1_score, precision_score, recall_score, log_loss, balanced_accuracy_score, cohen_kappa_score, hinge_loss, accuracy_score\n",
    "\n",
    "from namable_classify.utils import MuteWarnings\n",
    "import warnings\n",
    "except_roc_auc_score = default_on_exception(default_value=-1)(roc_auc_score)\n",
    "\n",
    "def compute_classification_metrics(\n",
    "    y_true: np.ndarray,  # 1d array-like, or label indicator array / sparse matrix\n",
    "    y_pred_logits: np.ndarray = None,  # label indicator array / sparse matrix\n",
    "    logits_to_prob: bool = False,  # function to convert logits to probabilities\n",
    "    y_pred: np.ndarray = None,  # predicted labels, if None, will be computed from logits\n",
    "    labels:list[int|str]|None = None,  # list of labels\n",
    "    supress_warnings: bool = True,  # whether to suppress warnings\n",
    "    y_pred_metrics_only: bool = False,  # whether to compute only y_pred related metrics\n",
    "):\n",
    "        \n",
    "    if supress_warnings:\n",
    "        mute = MuteWarnings()\n",
    "        mute.mute()\n",
    "    if y_pred_logits is None:\n",
    "        assert y_pred_metrics_only == True, \"y_pred_logits is None, we can only compute y_pred related metrics! \"\n",
    "        assert y_pred is not None, \"y_pred_logits is None, y_pred should be specified! \"\n",
    "        # warnings.warn(\"y_pred_logits is None, will compute y_pred related metrics only! \")\n",
    "    y_true = ensure_array(y_true)\n",
    "    if not y_pred_metrics_only:\n",
    "        y_pred_logits = ensure_array(y_pred_logits)\n",
    "        # print(type(y_pred_logits)) # <class 'numpy.ndarray'>\n",
    "        # y_pred_probs = softmax(y_pred_logits)# label indicator array / sparse matrix\n",
    "        y_pred_probs = (\n",
    "            np.array(F.softmax(torch.Tensor(y_pred_logits), dim=1))\n",
    "            if logits_to_prob\n",
    "            else y_pred_logits\n",
    "        )  # label indicator array / sparse matrix\n",
    "    other_res = {}\n",
    "    if y_pred is None:\n",
    "        # 必然有 y_pred_logits\n",
    "        assert y_pred_logits is not None, \"y_pred_logits is None, cannot derive y_pred! \"\n",
    "        y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "    else:\n",
    "        # 额外计算一个acc\n",
    "        if not y_pred_metrics_only:\n",
    "            warnings.warn(\"y_pred is specified since it may be different from argmax(y_pred_logits), this may happen to prob SVM. \")\n",
    "        other_res[\"acc1_pred\"] = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        \n",
    "    # target_names = labels # dataset['train'].features[label_column_name].names\n",
    "    # report_dict = classification_report(y_true, y_pred_probs, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    if not y_pred_metrics_only:\n",
    "        top_k_res = {\n",
    "            f\"acc{k}\": top_k_accuracy_score(y_true, y_pred_probs, k=k, labels=labels)\n",
    "            for k in [1, 2, 3, 5, 10, 20]\n",
    "        }\n",
    "        prob_res = dict(\n",
    "            # roc_auc=roc_auc_score(\n",
    "            roc_auc=except_roc_auc_score(\n",
    "                y_true, y_pred_probs, average=\"macro\", multi_class=\"ovr\", labels=labels\n",
    "            ),  # ovr更难一些，会不平衡\n",
    "            hinge_loss=hinge_loss(y_true, y_pred_probs, labels=labels),\n",
    "            log_loss=log_loss(\n",
    "                y_true,\n",
    "                y_pred_probs,\n",
    "                labels=labels\n",
    "                ),\n",
    "            )\n",
    "    else: \n",
    "        top_k_res = {}\n",
    "        prob_res = {}\n",
    "\n",
    "    pred_res = dict(\n",
    "        matthews_corrcoef=matthews_corrcoef(y_true, y_pred),\n",
    "        f1=f1_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        precision=precision_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        recall=recall_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        balanced_accuracy=balanced_accuracy_score(y_true, y_pred),\n",
    "        cohen_kappa=cohen_kappa_score(y_true, y_pred, labels=labels),\n",
    "    )\n",
    "    if supress_warnings:\n",
    "        mute.resume()\n",
    "    \n",
    "    # return top_k_res| balance_res| report_dict\n",
    "    return top_k_res | pred_res | prob_res | other_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'acc1'\u001b[0m: \u001b[1;36m0.08\u001b[0m,\n",
       "    \u001b[32m'acc2'\u001b[0m: \u001b[1;36m0.15\u001b[0m,\n",
       "    \u001b[32m'acc3'\u001b[0m: \u001b[1;36m0.19\u001b[0m,\n",
       "    \u001b[32m'acc5'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "    \u001b[32m'acc10'\u001b[0m: \u001b[1;36m0.49\u001b[0m,\n",
       "    \u001b[32m'acc20'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'matthews_corrcoef'\u001b[0m: \u001b[1;36m0.03259827883336652\u001b[0m,\n",
       "    \u001b[32m'f1'\u001b[0m: \u001b[1;36m0.06344988344988345\u001b[0m,\n",
       "    \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.07928571428571429\u001b[0m,\n",
       "    \u001b[32m'recall'\u001b[0m: \u001b[1;36m0.07494588744588744\u001b[0m,\n",
       "    \u001b[32m'balanced_accuracy'\u001b[0m: \u001b[1;36m0.07494588744588744\u001b[0m,\n",
       "    \u001b[32m'cohen_kappa'\u001b[0m: \u001b[1;36m0.032190195665895205\u001b[0m,\n",
       "    \u001b[32m'roc_auc'\u001b[0m: \u001b[1;36m0.4935322122458186\u001b[0m,\n",
       "    \u001b[32m'hinge_loss'\u001b[0m: \u001b[1;36m1.1451513\u001b[0m,\n",
       "    \u001b[32m'log_loss'\u001b[0m: \u001b[1;36m3.3784022382628023\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_classification_metrics(torch.randint(0, 20, size=(100,)), \n",
    "                               torch.softmax(torch.randn(100, 20), dim=1), \n",
    "                               logits_to_prob=False, \n",
    "                               labels=list(range(20)), \n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1542695/3728250618.py:2: UserWarning: This is a warning\n",
      "  warnings.warn(\"This is a warning\")\n"
     ]
    }
   ],
   "source": [
    "[1,2,3].pop(0)\n",
    "warnings.warn(\"This is a warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuequ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
