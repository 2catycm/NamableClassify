{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto_experiment\n",
    "> automatically research on the relationship between the performance and meta parameters (a.k.a. hyperparameters or config) via searching (a.k.a. sweeping) experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/google-research/tuning_playbook for scientific research principles on meta parameters tuning. \n",
    "\n",
    "In addition to that guide, we also follow the paper \"Statistical Comparisons of Classifiers over Multiple Data Sets\", using statistical hypothesis testing to compare the performance of different models (produced by different meta parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp auto.examples.full_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.auto.experiment import fixed_meta_parameters, run_with_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# 先直接跑两个, 来不及写了\n",
    "\n",
    "import numpy as np\n",
    "# 设置采样的起始值和结束值\n",
    "start = np.log(1e-5)\n",
    "end = np.log(1e-1)\n",
    "learning_rates = np.logspace(start, end, num=30, base=np.e)\n",
    "np.random.shuffle(learning_rates)\n",
    "learning_rates = learning_rates.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000004e-05,\n",
       " 1.8873918221350988e-05,\n",
       " 0.07278953843983155,\n",
       " 0.0003290344562312673,\n",
       " 4.893900918477493e-05,\n",
       " 0.028072162039411812,\n",
       " 0.004175318936560405,\n",
       " 0.0008531678524172811,\n",
       " 0.002212216291070452,\n",
       " 0.0030391953823132017,\n",
       " 6.723357536499339e-05,\n",
       " 0.0004520353656360247,\n",
       " 1.3738237958832637e-05,\n",
       " 0.014873521072935129,\n",
       " 0.0001268961003167923,\n",
       " 0.05298316906283719,\n",
       " 0.00023950266199874884,\n",
       " 9.236708571873867e-05,\n",
       " 0.00017433288221999898,\n",
       " 2.5929437974046704e-05,\n",
       " 0.010826367338740551,\n",
       " 0.0057361525104486855,\n",
       " 0.10000000000000003,\n",
       " 0.020433597178569445,\n",
       " 0.0016102620275609408,\n",
       " 0.007880462815669924,\n",
       " 3.562247890262441e-05,\n",
       " 0.0006210169418915622,\n",
       " 0.001172102297533481,\n",
       " 0.038566204211634786]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# seed = 0\n",
    "seed = 2\n",
    "# seed = 1\n",
    "def learning_rate_exec(learning_rate):\n",
    "    parameters = fixed_meta_parameters.copy()\n",
    "    parameters.yuequ = 'full_finetune'\n",
    "    parameters.experiment_index = seed\n",
    "    parameters.learning_rate = learning_rate\n",
    "    return run_with_config(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "run_names = [f\"{lr:.2e}\" for lr in learning_rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.00e-05',\n",
       " '1.89e-05',\n",
       " '7.28e-02',\n",
       " '3.29e-04',\n",
       " '4.89e-05',\n",
       " '2.81e-02',\n",
       " '4.18e-03',\n",
       " '8.53e-04',\n",
       " '2.21e-03',\n",
       " '3.04e-03',\n",
       " '6.72e-05',\n",
       " '4.52e-04',\n",
       " '1.37e-05',\n",
       " '1.49e-02',\n",
       " '1.27e-04',\n",
       " '5.30e-02',\n",
       " '2.40e-04',\n",
       " '9.24e-05',\n",
       " '1.74e-04',\n",
       " '2.59e-05',\n",
       " '1.08e-02',\n",
       " '5.74e-03',\n",
       " '1.00e-01',\n",
       " '2.04e-02',\n",
       " '1.61e-03',\n",
       " '7.88e-03',\n",
       " '3.56e-05',\n",
       " '6.21e-04',\n",
       " '1.17e-03',\n",
       " '3.86e-02']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new running round 0\n",
      "executing run_name 6.723357536499339e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Full Finetuning Algorithm, not changing the model structure. \n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2603119857\u001b[0m (\u001b[33mhandicraft-computing\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c35048e7a57489696a54346a08b703e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011134987755212933, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241025_212552-zlaeje88</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/handicraft-computing/namable_classify/runs/zlaeje88' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/handicraft-computing/namable_classify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/handicraft-computing/namable_classify' target=\"_blank\">https://wandb.ai/handicraft-computing/namable_classify</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/handicraft-computing/namable_classify/runs/zlaeje88' target=\"_blank\">https://wandb.ai/handicraft-computing/namable_classify/runs/zlaeje88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb0bbdf13e4a718870a0a618298803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "from namable_classify.auto.run import auto_run\n",
    "auto_run(learning_rate_exec, learning_rates, run_names, f\"sweep_lr_full_finetune-{seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
