{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto_experiment for a single method\n",
    "> 为单个方法自动实验，优化掉荣誉超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp auto.experiment.single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from namable_classify.nucleus import ClassificationTask, ClassificationTaskConfig\n",
    "from boguan_yuequ.auto.nucleus import AutoYueQuAlgorithm\n",
    "import lightning as L\n",
    "from namable_classify.utils import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, StochasticWeightAveraging, DeviceStatsMonitor, LearningRateMonitor, LearningRateFinder, BatchSizeFinder\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger, WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'runs_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyTorchLightningPruningCallback\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLFlowLogger\n\u001b[0;32m----> 7\u001b[0m auto_exp_runs_path \u001b[38;5;241m=\u001b[39m \u001b[43mruns_path\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m auto_exp_runs_path\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_config\u001b[39m(\n\u001b[1;32m     12\u001b[0m     config: ClassificationTaskConfig,\n\u001b[1;32m     13\u001b[0m     trial: optuna\u001b[38;5;241m.\u001b[39mTrial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     tuning_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Seriously, 为了学术诚信规范，我们AI科研者不能用 \"test_acc1\" 来调参。\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     tuning_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runs_path' is not defined"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "# from clearml import Task\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from namable_classify.utils import logger\n",
    "import torch\n",
    "\n",
    "auto_exp_runs_path = runs_path / \"auto_experiment\"\n",
    "auto_exp_runs_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def run_with_config(\n",
    "    config: ClassificationTaskConfig,\n",
    "    trial: optuna.Trial = None,\n",
    "    tuning_metric=\"val_acc1\",  # Seriously, 为了学术诚信规范，我们AI科研者不能用 \"test_acc1\" 来调参。\n",
    "    tuning_mode=\"max\",\n",
    "):\n",
    "    logger.info(f\"running with config: {config}\")\n",
    "    L.seed_everything(config.experiment_index)\n",
    "    cls_task = ClassificationTask(config)\n",
    "    cls_task.print_model_pretty()\n",
    "    AutoYueQuAlgorithm(cls_task, config.yuequ, config.yuequ_pe)\n",
    "    # AutoYueQuAlgorithm(cls_task.cls_model, config.yuequ, config.yuequ_pe)\n",
    "    # Task.init(project_name=config.experiment_project, task_name=config.experiment_task)\n",
    "    # https://clear.ml/docs/latest/docs/guides/frameworks/pytorch_lightning/pytorch_lightning_example/\n",
    "\n",
    "    callbacks = [\n",
    "        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "        EarlyStopping(\n",
    "            monitor=tuning_metric,\n",
    "            mode=tuning_mode,\n",
    "            check_finite=True,\n",
    "            #   patience=5,\n",
    "            patience=10,\n",
    "            #   patience=6,\n",
    "            check_on_train_epoch_end=False,  # check on validation end\n",
    "            verbose=True,\n",
    "        ),\n",
    "        ModelSummary(max_depth=3),\n",
    "        # https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/\n",
    "        # StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "        # DeviceStatsMonitor(cpu_stats=True)\n",
    "        # LearningRateMonitor(),\n",
    "        # LearningRateFinder() # 有奇怪的bug\n",
    "        # BatchSizeFinder(init_val=32) # 用 \"power\" 减少调参不确定性; \n",
    "    ]\n",
    "    if trial is not None:\n",
    "        callbacks.append(PyTorchLightningPruningCallback(trial, monitor=tuning_metric))\n",
    "\n",
    "    lightning_loggers = [\n",
    "        TensorBoardLogger(save_dir=auto_exp_runs_path),\n",
    "        CSVLogger(save_dir=auto_exp_runs_path),\n",
    "        MLFlowLogger(experiment_name=f\"{config.experiment_project}/{config.experiment_task}\", \n",
    "                    #  .replace(\"_\", \"-\").replace(\" \", \"-\"), \n",
    "                     tracking_uri=\"http://10.103.10.55:5000\")\n",
    "        # WandbLogger(project=config.experiment_project, name=config.experiment_task),\n",
    "    ]\n",
    "    \n",
    "    torch.set_float32_matmul_precision(\"high\") # 尝试用 TF32\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=auto_exp_runs_path,\n",
    "        enable_checkpointing=True,\n",
    "        enable_model_summary=True,\n",
    "        num_sanity_val_steps=2,  # 防止 val 在训了好久train才发现崩溃\n",
    "        callbacks=callbacks\n",
    "        , max_epochs=30 \n",
    "        # , gradient_clip_val=1.0, gradient_clip_algorithm=\"value\"\n",
    "        ,\n",
    "        logger=lightning_loggers,\n",
    "        # , profiler=\"simple\"\n",
    "        # , fast_dev_run=True\n",
    "        # limit_train_batches=10, limit_val_batches=5\n",
    "        # strategy=\"ddp\", accelerator=\"gpu\", devices=4\n",
    "        accelerator=\"gpu\", devices=1, # 实验并行优于数据并行，尽量单卡训练\n",
    "        # accelerator=\"gpu\", devices=8, # 实验并行优于数据并行，尽量单卡训练\n",
    "        # precision=16 \n",
    "        # strategy=\"ddp\"\n",
    "    )\n",
    "    # batch size 和 learning rate\n",
    "    from lightning.pytorch.tuner import Tuner\n",
    "    tuner = Tuner(trainer)\n",
    "    found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "                                        #   mode='binsearch', \n",
    "                                          mode='power', \n",
    "                                          init_val=64)\n",
    "    cls_task.hparams.batch_size = found_batch_size = 64 * 8\n",
    "    linear_lr_scale = found_batch_size / 64\n",
    "    # linear_lr_scale *= 8 # 多卡训练\n",
    "    cls_task.hparams.learning_rate = config.learning_rate * linear_lr_scale\n",
    "    logger.info(f\"original learning rate: {config.learning_rate}, linear lr scale: {linear_lr_scale}, learning rate: {cls_task.hparams.learning_rate}\")\n",
    "\n",
    "    logger.info(f\"actual hyperparameters: {cls_task.hparams}\")\n",
    "    trainer.fit(cls_task, datamodule=cls_task.lit_data)\n",
    "    val_result = trainer.validate(cls_task, datamodule=cls_task.lit_data)\n",
    "    test_result = trainer.test(cls_task, datamodule=cls_task.lit_data)\n",
    "    # val_acc1 = val_result[0][\"val_acc1\"]\n",
    "    # test_acc1 = test_result[0][\"test_acc1\"]\n",
    "    # return val_acc1, test_acc1\n",
    "    return val_result, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.nucleus import ClassificationModelConfig, ClassificationTaskConfig, ClassificationDataConfig\n",
    "fixed_meta_parameters = ClassificationTaskConfig(\n",
    "    experiment_project = \"Homogeneous dwarf model is all you need for tuning pretrained giant model.\", \n",
    "    # experiment_name = \"Auto experiment\", \n",
    "    experiment_task = \"Auto experiment Stage 1 (single run, short epoches)\", \n",
    "    label_smoothing=0.1,  # 未必固定。\n",
    "    cls_model_config=ClassificationModelConfig(\n",
    "        # checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "    ), \n",
    "    dataset_config = ClassificationDataConfig(\n",
    "        # batch_size=64, # 经过前期经验, 这个方便站在61服务器跑, 大概10G显存。 固定基于这个调参\n",
    "        batch_size=16,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想要得到一个dataframe，这一次Study，每一次实验lightning存在那个目录，最后得到的val和test指标是什么，optuna建议进去的超参数是什么，其他超参数是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "study_results = [] # 准备装入 dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# 需要跑哪些backbone 和 对应的 pe呢？\n",
    "from boguan_yuequ.benchmarking import pe_list_tiny_for_all_size, backbone_names\n",
    "# from transformers import AutoModel\n",
    "# # tiny+tiny vs tiny full vs tiny full_lora 也是有意义的对比，所以不做截断。\n",
    "# for config, pe in zip(configs, pe_list_tiny_for_all_size):\n",
    "#     model = AutoModel.from_pretrained(config)\n",
    "#     yuequ = AutoYueQuAlgorithm(model, 'lora', pe)\n",
    "#     model = yuequ.adapted_model\n",
    "#     pe = yuequ.pe\n",
    "backbone_name2pe = {backbone_name:pe for pe, backbone_name in zip(pe_list_tiny_for_all_size, backbone_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WinKawaks/vit-tiny-patch16-224': 1.0,\n",
       " 'facebook/dinov2-small': 0.2525765133213994,\n",
       " 'facebook/dinov2-base': 0.06439934417512297,\n",
       " 'facebook/dinov2-large': 0.018329073267526527,\n",
       " 'facebook/dinov2-giant': 0.004909821625242288}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_name2pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# 需要跑哪些算法呢？\n",
    "# from boguan_yuequ.auto import huggingface_peft_budget_config_key, thu_nlp_opendelta_budget_config_key\n",
    "from boguan_yuequ.auto.integrations.peft import huggingface_peft_budget_config_key\n",
    "from boguan_yuequ.auto.integrations.opendelta import thunlp_opendelta_budget_config_key\n",
    "\n",
    "peft_to_try = [k.name for k in huggingface_peft_budget_config_key.keys()]\n",
    "delta_to_try = [k for k in thunlp_opendelta_budget_config_key.keys() if k.upper() not in peft_to_try]\n",
    "yuequ_to_try = peft_to_try + delta_to_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LORA',\n",
       " 'ADALORA',\n",
       " 'LOHA',\n",
       " 'OFT',\n",
       " 'VERA',\n",
       " 'FOURIERFT',\n",
       " 'VBLORA',\n",
       " 'adapter',\n",
       " 'delta_yuequ_prefix_tuning']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuequ_to_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"'optuna.study.Study'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A trial is a process of evaluating an objective function.\n",
      "\n",
      "This object is passed to an objective function and provides interfaces to get parameter\n",
      "suggestion, manage the trial's state, and set/get user-defined attributes of the trial.\n",
      "\n",
      "Note that the direct use of this constructor is not recommended.\n",
      "This object is seamlessly instantiated and passed to the objective function behind\n",
      "the :func:`optuna.study.Study.optimize()` method; hence library users do not care about\n",
      "instantiation of this object.\n",
      "\n",
      "Args:\n",
      "    study:\n",
      "        A :class:`~optuna.study.Study` object.\n",
      "    trial_id:\n",
      "        A trial ID that is automatically generated.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/program_files/miniconda3/envs/fastai/lib/python3.10/site-packages/optuna/trial/_trial.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "optuna.Trial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set()\n",
    "a.update({1:2, 2:3}.keys())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# full_finetune 和 新方法单列\n",
    "# 这里只跑baseline\n",
    "from boguan_yuequ.benchmarking import pe_list_tiny_for_all_size, backbone_names\n",
    "import optuna\n",
    "from namable_classify.utils import logger\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "import optuna.exceptions\n",
    "\n",
    "def objective(trial, num_of_repeated_experiments = 5):\n",
    "    # TODO 对每一个目标超参数 分开去做？ grid search\n",
    "    # for yuequ in yuequ_tried_algs:\n",
    "    \n",
    "    meta_parameters = fixed_meta_parameters.copy()\n",
    "    # 修改超参\n",
    "    \n",
    "    # 目标超参被建议\n",
    "    meta_parameters.yuequ = trial.suggest_categorical(\"yuequ\", yuequ_to_try)\n",
    "    # choice = trial.suggest_categorical(\"pe_and_backbone_choice\", list(range(len(backbone_names))))\n",
    "    backbone_name = trial.suggest_categorical(\"backbone\", backbone_names)\n",
    "    meta_parameters.cls_model_config.checkpoint = backbone_name\n",
    "    meta_parameters.yuequ_pe = backbone_name2pe[backbone_name]\n",
    "    trial.set_user_attr(\"parameter_efficiency\", meta_parameters.yuequ_pe) # 用于后续分析实验结果\n",
    "    \n",
    "    # 接下来是无关变量\n",
    "# f\"{yuequ}-learning_rate\"\n",
    "\n",
    "    # meta_parameters.learning_rate = trial.suggest_float(f\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    # meta_parameters.learning_rate = trial.suggest_float(f\"learning_rate\", 1e-5, 1e-2, log=True) # 正则化，建议的是Batch Size=64的学习率\n",
    "    meta_parameters.learning_rate = trial.suggest_float(f\"learning_rate\", 1e-4, 4e-2, log=True) # 正则化，建议的是Batch Size=64的学习率\n",
    "    \n",
    "    result_dict = dict()\n",
    "\n",
    "    metric_names = set()\n",
    "    # 重复试验\n",
    "    for experiment_index in range(num_of_repeated_experiments):\n",
    "        meta_parameters.experiment_index = experiment_index\n",
    "        # 当我们选定 experiment_index 之后，就不要随机建议参数了，现在我们元参数保持一样，重复5次随机实验。\n",
    "        try:\n",
    "            val_result, test_result = run_with_config(\n",
    "                meta_parameters, trial, \"val_acc1\", \"max\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(f\"Error in experiment {experiment_index}, May be you can\\n\"\n",
    "                         \"1. Stop the optuna study and you debug and fix the buggy code. \"\n",
    "                         \"2. Searched optuna trial is invalid as an input, so just prune this trial and continue. \"\n",
    "                         )\n",
    "            choice = Prompt.ask(\"What should we do now?\",\n",
    "                                choices=[\"1\", \"2\"], default=\"1\")\n",
    "            if choice == \"1\":\n",
    "                raise e\n",
    "            else:\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "        # 注意不要用 test_acc1 调参。\n",
    "        # 我们的原则是每一个目标超参验证集到最优, 然后再用最优的超参得到的模型(其实应该重新训练一遍)在测试集上测试。\n",
    "        # 在论文研究的第一阶段，应该调参。时间不够的话\n",
    "        \n",
    "        single_run_result = val_result[0] | test_result[0]\n",
    "        metric_names.update(single_run_result.keys())\n",
    "        single_run_result = {f\"{k}-run{experiment_index}\":v for k, v in single_run_result.items()}\n",
    "        for k, v in single_run_result.items():\n",
    "            trial.set_user_attr(k, v)\n",
    "        result_dict|=single_run_result\n",
    "        \n",
    "        trial.report(single_run_result[f\"val_acc1-run{experiment_index}\"], experiment_index)\n",
    "        # if trial.should_prune():\n",
    "        #     # Return the current predicted value instead of raising `TrialPruned`.\n",
    "        #     # This is a workaround to tell the Optuna about the evaluation\n",
    "        #     # results in pruned trials.\n",
    "        #     for metric_name in metric_names:\n",
    "        #         all_runs_results = [result_dict[f\"{metric_name}-run{i}\"] for i in range(num_of_repeated_experiments)]\n",
    "        #         result_dict[f\"{metric_name}-mean\"] = sum(all_runs_results) / len(all_runs_results)\n",
    "        #         trial.set_user_attr(f\"{metric_name}-mean\", result_dict[f\"{metric_name}-mean\"])\n",
    "        #     trial.set_user_attr(f\"num_of_repeated\", experiment_index+1)\n",
    "        #     return result_dict[\"val_acc1-mean\"]\n",
    "    # 计算一下平均数\n",
    "    for metric_name in metric_names:\n",
    "        all_runs_results = [result_dict[f\"{metric_name}-run{i}\"] for i in range(num_of_repeated_experiments)]\n",
    "        result_dict[f\"{metric_name}-mean\"] = sum(all_runs_results) / len(all_runs_results)\n",
    "        trial.set_user_attr(f\"{metric_name}-mean\", result_dict[f\"{metric_name}-mean\"])\n",
    "    trial.set_user_attr(f\"num_of_repeated\", num_of_repeated_experiments)\n",
    "    return result_dict[\"val_acc1-mean\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql+psycopg2://ycm:password@10.103.10.55:5432/namable_classify'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = 'ycm'\n",
    "password = 'password'\n",
    "# host = 'localhost'\n",
    "# host = '10.103.10.53'\n",
    "host = '10.103.10.55'\n",
    "port = 5432\n",
    "database_name = 'namable_classify'\n",
    "postgres_url = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database_name}'\n",
    "postgres_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+psycopg2://ycm:***@10.103.10.55:5432/namable_classify)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(postgres_url)\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16589/618639724.py:24: ExperimentalWarning: WilcoxonPruner is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  pruner=WilcoxonPruner()\n",
      "[I 2024-11-01 05:01:55,532] A new study created in RDB with name: peft baselines benchmark\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fixed_meta_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m\n\u001b[1;32m     12\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     13\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft baselines benchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# storage=sqlite_url, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# WilcoxonPruner(min_n_trials=10) # 不适合这个，这个 immediate 是fold的情况\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m study\u001b[38;5;241m.\u001b[39mset_user_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontributors\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYe Canming\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m study\u001b[38;5;241m.\u001b[39mset_user_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed_meta_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfixed_meta_parameters\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fixed_meta_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "from namable_classify.utils import runs_path\n",
    "from optuna.samplers import *\n",
    "from optuna.pruners import *\n",
    "# study_path = auto_exp_runs_path / \"optuna_studies.db\"\n",
    "# sqlite_url = f\"sqlite:///{study_path}\"\n",
    "# sqlite_url = f\"sqlite://{study_path}\"\n",
    "# TODO \n",
    "\n",
    "username = 'ycm'\n",
    "password = 'password'\n",
    "# host = 'localhost'\n",
    "host = '10.103.10.53'\n",
    "port = 5432\n",
    "database_name = 'namable_classify'\n",
    "postgres_url = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database_name}'\n",
    "# pip install psycopg2-binary \n",
    "# postgres_url = 'postgresql://myuser:mypassword@localhost/mydatabase'\n",
    "# TODO safety and privacy\n",
    "study = optuna.create_study(\n",
    "    # study_name=\"peft baselines benchmark\",  # old version\n",
    "    # study_name=\"peft baselines benchmark 11.3\", \n",
    "    study_name=\"peft baselines benchmark 11.7\", \n",
    "    # storage=sqlite_url, \n",
    "    storage=postgres_url, \n",
    "    load_if_exists=True, \n",
    "    direction=\"maximize\", \n",
    "    # https://pub.aimind.so/a-deep-dive-in-optunas-advance-features-2e495e71435c\n",
    "    # sampler=GPSampler(seed=42), \n",
    "    # sampler=TPESampler(seed=42), \n",
    "    # sampler=TPESampler(), \n",
    "    # https://github.com/optuna/optuna/issues/1647\n",
    "    sampler=CmaEsSampler(consider_pruned_trials = True), \n",
    "    pruner=HyperbandPruner()\n",
    "    # pruner=WilcoxonPruner()\n",
    "    # CmaEsSampler(seed=42),  我们实验数量应该小于1000\n",
    "    # WilcoxonPruner(min_n_trials=10) # 不适合这个，这个 immediate 是fold的情况\n",
    ")\n",
    "study.set_user_attr(\"contributors\", [\"Ye Canming\"])\n",
    "study.set_user_attr(\"fixed_meta_parameters\", fixed_meta_parameters.json())\n",
    "# 晚点再看\n",
    "# https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.MLflowCallback.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "# study.optimize(objective, n_trials=100)\n",
    "study.optimize(lambda trial: objective(trial, num_of_repeated_experiments=1), \n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuequ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
