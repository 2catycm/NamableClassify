{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto_experiment\n",
    "> automatically research on the relationship between the performance and meta parameters (a.k.a. hyperparameters or config) via searching (a.k.a. sweeping) experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/google-research/tuning_playbook for scientific research principles on meta parameters tuning. \n",
    "\n",
    "In addition to that guide, we also follow the paper \"Statistical Comparisons of Classifiers over Multiple Data Sets\", using statistical hypothesis testing to compare the performance of different models (produced by different meta parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp auto.experiment.infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.infra import runs_path\n",
    "from namable_classify.nucleus import ClassificationTask, ClassificationTaskConfig\n",
    "from boguan_yuequ.auto.nucleus import AutoYueQuAlgorithm\n",
    "import lightning as L\n",
    "from namable_classify.infra import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, StochasticWeightAveraging, DeviceStatsMonitor, LearningRateMonitor, LearningRateFinder, BatchSizeFinder\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger, WandbLogger\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from namable_classify.infra import logger\n",
    "import torch\n",
    "# from clearml import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "auto_exp_runs_path = runs_path / \"auto_experiment\"\n",
    "auto_exp_runs_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def run_with_config(\n",
    "    config: ClassificationTaskConfig,\n",
    "    trial: optuna.Trial = None,\n",
    "    tuning_metric=\"val_acc1\",  # Seriously, 为了学术诚信规范，我们AI科研者不能用 \"test_acc1\" 来调参。\n",
    "    tuning_mode=\"max\",\n",
    "):\n",
    "    logger.info(f\"running with config: {config}\")\n",
    "    L.seed_everything(config.experiment_index)\n",
    "    cls_task = ClassificationTask(config)\n",
    "    cls_task.print_model_pretty()\n",
    "    AutoYueQuAlgorithm(cls_task, config.yuequ, config.yuequ_pe)\n",
    "    # AutoYueQuAlgorithm(cls_task.cls_model, config.yuequ, config.yuequ_pe)\n",
    "    # Task.init(project_name=config.experiment_project, task_name=config.experiment_task)\n",
    "    # https://clear.ml/docs/latest/docs/guides/frameworks/pytorch_lightning/pytorch_lightning_example/\n",
    "\n",
    "    callbacks = [\n",
    "        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "        EarlyStopping(\n",
    "            monitor=tuning_metric,\n",
    "            mode=tuning_mode,\n",
    "            check_finite=True,\n",
    "            #   patience=5,\n",
    "            patience=10,\n",
    "            #   patience=6,\n",
    "            check_on_train_epoch_end=False,  # check on validation end\n",
    "            verbose=True,\n",
    "        ),\n",
    "        ModelSummary(max_depth=3),\n",
    "        # https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/\n",
    "        # StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "        # DeviceStatsMonitor(cpu_stats=True)\n",
    "        # LearningRateMonitor(),\n",
    "        # LearningRateFinder() # 有奇怪的bug\n",
    "        # BatchSizeFinder(init_val=32) # 用 \"power\" 减少调参不确定性; \n",
    "    ]\n",
    "    if trial is not None:\n",
    "        callbacks.append(PyTorchLightningPruningCallback(trial, monitor=tuning_metric))\n",
    "\n",
    "    lightning_loggers = [\n",
    "        TensorBoardLogger(save_dir=auto_exp_runs_path, log_graph=True),\n",
    "        CSVLogger(save_dir=auto_exp_runs_path),\n",
    "        MLFlowLogger(experiment_name=f\"{config.experiment_project}/{config.experiment_task}\", \n",
    "                    #  .replace(\"_\", \"-\").replace(\" \", \"-\"), \n",
    "                     tracking_uri=\"http://10.103.10.55:5000\")\n",
    "        # WandbLogger(project=config.experiment_project, name=config.experiment_task),\n",
    "    ]\n",
    "    \n",
    "    torch.set_float32_matmul_precision(\"high\") # 尝试用 TF32\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=auto_exp_runs_path,\n",
    "        enable_checkpointing=True,\n",
    "        enable_model_summary=True,\n",
    "        num_sanity_val_steps=2,  # 防止 val 在训了好久train才发现崩溃\n",
    "        callbacks=callbacks\n",
    "        , max_epochs=30 \n",
    "        # , gradient_clip_val=1.0, gradient_clip_algorithm=\"value\"\n",
    "        ,\n",
    "        logger=lightning_loggers,\n",
    "        # , profiler=\"simple\"\n",
    "        # , fast_dev_run=True\n",
    "        # limit_train_batches=10, limit_val_batches=5\n",
    "        # strategy=\"ddp\", accelerator=\"gpu\", devices=4\n",
    "        accelerator=\"gpu\", devices=1, # 实验并行优于数据并行，尽量单卡训练\n",
    "        # accelerator=\"gpu\", devices=8, # 实验并行优于数据并行，尽量单卡训练\n",
    "        # precision=16 \n",
    "        # strategy=\"ddp\"\n",
    "    )\n",
    "    # batch size 和 learning rate\n",
    "    from lightning.pytorch.tuner import Tuner\n",
    "    tuner = Tuner(trainer)\n",
    "    found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "                                        #   mode='binsearch', \n",
    "                                          mode='power', \n",
    "                                          init_val=64)\n",
    "    cls_task.hparams.batch_size = found_batch_size = 64 * 8\n",
    "    linear_lr_scale = found_batch_size / 64\n",
    "    # linear_lr_scale *= 8 # 多卡训练\n",
    "    cls_task.hparams.learning_rate = config.learning_rate * linear_lr_scale\n",
    "    logger.info(f\"original learning rate: {config.learning_rate}, linear lr scale: {linear_lr_scale}, learning rate: {cls_task.hparams.learning_rate}\")\n",
    "\n",
    "    logger.info(f\"actual hyperparameters: {cls_task.hparams}\")\n",
    "    trainer.fit(cls_task, datamodule=cls_task.lit_data)\n",
    "    val_result = trainer.validate(cls_task, datamodule=cls_task.lit_data)\n",
    "    test_result = trainer.test(cls_task, datamodule=cls_task.lit_data)\n",
    "    # val_acc1 = val_result[0][\"val_acc1\"]\n",
    "    # test_acc1 = test_result[0][\"test_acc1\"]\n",
    "    # return val_acc1, test_acc1\n",
    "    return val_result, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.nucleus import ClassificationModelConfig, ClassificationTaskConfig, ClassificationDataConfig\n",
    "fixed_meta_parameters = ClassificationTaskConfig(\n",
    "    experiment_project = \"Homogeneous dwarf model is all you need for tuning pretrained giant model.\", \n",
    "    # experiment_name = \"Auto experiment\", \n",
    "    experiment_task = \"Auto experiment Stage 1 (single run, short epoches)\", \n",
    "    label_smoothing=0.1,  # 未必固定。\n",
    "    cls_model_config=ClassificationModelConfig(\n",
    "        # checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "    ), \n",
    "    dataset_config = ClassificationDataConfig(\n",
    "        # batch_size=64, # 经过前期经验, 这个方便站在61服务器跑, 大概10G显存。 固定基于这个调参\n",
    "        batch_size=16,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "study_path = auto_exp_runs_path / \"optuna_studies.db\"\n",
    "sqlite_url = f\"sqlite:///{study_path}\"\n",
    "# sqlite_url = f\"sqlite://{study_path}\"\n",
    "\n",
    "# pip install psycopg2-binary \n",
    "\n",
    "@dataclass\n",
    "class PostgresDatabaseConfig:\n",
    "    username: str\n",
    "    password: str\n",
    "    host: str\n",
    "    port: int\n",
    "    database_name: str\n",
    "    postgres_protocol: str = 'postgresql+psycopg2'\n",
    "\n",
    "    @property\n",
    "    def sqlalchemy_url(self) -> str:\n",
    "#    postgres_url = 'postgresql://myuser:mypassword@localhost/mydatabase'\n",
    "    \n",
    "        return f'{self.postgres_protocol}://{self.username}:{self.password}@{self.host}:{self.port}/{self.database_name}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "import json\n",
    "from namable_classify.infra import runs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "database_config_path = runs_path / 'database_config.json'\n",
    "with open(database_config_path, 'r') as f:\n",
    "    config = PostgresDatabaseConfig(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(config.sqlalchemy_url)\n",
    "# engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 04:42:31,168] A new study created in RDB with name: peft baselines benchmark 11.29\n"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "from optuna.samplers import *\n",
    "from optuna.pruners import *\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    # study_name=\"peft baselines benchmark\",  # old version\n",
    "    # study_name=\"peft baselines benchmark 11.3\", \n",
    "    # study_name=\"peft baselines benchmark 11.7\", \n",
    "    study_name=\"peft baselines benchmark 11.29\", \n",
    "    # storage=config.sqlalchemy_url, \n",
    "    storage=sqlite_url, \n",
    "    load_if_exists=True, \n",
    "    direction=\"maximize\", \n",
    "    # https://pub.aimind.so/a-deep-dive-in-optunas-advance-features-2e495e71435c\n",
    "    # sampler=GPSampler(seed=42), \n",
    "    # sampler=TPESampler(seed=42), \n",
    "    # sampler=TPESampler(), \n",
    "    # https://github.com/optuna/optuna/issues/1647\n",
    "    sampler=CmaEsSampler(consider_pruned_trials = True), \n",
    "    pruner=HyperbandPruner()\n",
    "    # pruner=WilcoxonPruner()\n",
    "    # CmaEsSampler(seed=42),  我们实验数量应该小于1000\n",
    "    # WilcoxonPruner(min_n_trials=10) # 不适合这个，这个 immediate 是fold的情况\n",
    ")\n",
    "study.set_user_attr(\"contributors\", [\"Ye Canming\"])\n",
    "study.set_user_attr(\"fixed_meta_parameters\", fixed_meta_parameters.json())\n",
    "# 晚点再看\n",
    "# https://optuna-integration.readthedocs.io/en/stable/reference/generated/optuna_integration.MLflowCallback.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.3876\u001b[0m,  \u001b[1;36m0.2163\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mrequires_grad\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.randn((1, 2), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuequ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
