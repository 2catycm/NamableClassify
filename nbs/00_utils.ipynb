{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "> 通用工具函数和路径设置\n",
    ">\n",
    "> General utility functions and path settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description:\n",
    "\n",
    "utils 模块包含通用工具函数和项目中的关键路径设置，如 data_path。这些工具函数与项目的各个模块没有直接耦合，提供了项目中可复用的常用功能。\n",
    "\n",
    "The utils module contains general utility functions and key path settings for the project, such as data_path. These utility functions are decoupled from the project’s main modules and provide commonly used reusable functionality across the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- data_path: 数据存储路径的设置，用于配置数据集的根目录。\n",
    "\n",
    "  data_path: Defines the data storage path, used for setting the dataset root directory.\n",
    "\n",
    "\n",
    "- other_util_function: 其他工具函数，未来可以扩展。\n",
    "\n",
    "  other_util_function: Placeholder for other utility functions, expandable for future needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "import namable_classify\n",
    "lib_init_path = Path(inspect.getfile(namable_classify))\n",
    "lib_directory_path = lib_init_path.parent\n",
    "lib_repo_path = lib_directory_path.parent\n",
    "runs_path = lib_repo_path/'runs'\n",
    "runs_path.mkdir(exist_ok=True, parents=True)\n",
    "runs_figs_path = runs_path/'figs'\n",
    "runs_figs_path.mkdir(exist_ok=True, parents=True)\n",
    "data_path = lib_repo_path/'data'\n",
    "data_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.basics import patch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "@patch\n",
    "def print_trainable_parameters(model:nn.Module):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from bigmodelvis import Visualization\n",
    "@patch\n",
    "def print_model_pretty(self:nn.Module):\n",
    "    Visualization(self).structure_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import numpy as np\n",
    "def ensure_array(x: torch.TensorType | np.ndarray | list):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    else: # list\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# from scipy.special import softmax\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from loguru import logger\n",
    "def default_on_exception(default_value=None):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"An exception occurred: {e}\")\n",
    "                return default_value\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "roc_auc_score = default_on_exception(-1)(roc_auc_score)\n",
    "\n",
    "def compute_classification_metrics(\n",
    "    y_true: np.ndarray,  # 1d array-like, or label indicator array / sparse matrix\n",
    "    y_pred_logits: np.ndarray,  # label indicator array / sparse matrix\n",
    "    logits_to_prob: bool = False,  # function to convert logits to probabilities\n",
    "    labels:list[int|str]|None = None,  # list of labels\n",
    "):\n",
    "    y_true = ensure_array(y_true)\n",
    "    y_pred_logits = ensure_array(y_pred_logits)\n",
    "    # print(type(y_pred_logits)) # <class 'numpy.ndarray'>\n",
    "    # y_pred_probs = softmax(y_pred_logits)# label indicator array / sparse matrix\n",
    "    y_pred_probs = (\n",
    "        np.array(F.softmax(torch.Tensor(y_pred_logits), dim=1))\n",
    "        if logits_to_prob\n",
    "        else y_pred_logits\n",
    "    )  # label indicator array / sparse matrix\n",
    "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "    # target_names = labels # dataset['train'].features[label_column_name].names\n",
    "    # report_dict = classification_report(y_true, y_pred_probs, target_names=target_names, output_dict=True)\n",
    "    top_k_res = {\n",
    "        f\"acc{k}\": top_k_accuracy_score(y_true, y_pred_probs, k=k, labels=labels)\n",
    "        for k in [1, 2, 3, 5, 10, 20]\n",
    "    }\n",
    "    balance_res = dict(\n",
    "        roc_auc=roc_auc_score(\n",
    "            y_true, y_pred_probs, average=\"macro\", multi_class=\"ovr\", labels=labels\n",
    "        ),  # ovr更难一些，会不平衡\n",
    "        matthews_corrcoef=matthews_corrcoef(y_true, y_pred),\n",
    "        f1=f1_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        precision=precision_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        recall=recall_score(y_true, y_pred, average=\"macro\", labels=labels),\n",
    "        log_loss=log_loss(\n",
    "            y_true,\n",
    "            y_pred_probs,\n",
    "            labels=labels\n",
    "        ),\n",
    "        balanced_accuracy=balanced_accuracy_score(y_true, y_pred),\n",
    "        cohen_kappa=cohen_kappa_score(y_true, y_pred, labels=labels),\n",
    "        hinge_loss=hinge_loss(y_true, y_pred_probs, labels=labels),\n",
    "    )\n",
    "\n",
    "    # return top_k_res| balance_res| report_dict\n",
    "    return top_k_res | balance_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:2025: UndefinedMetricWarning: 'k' (20) greater than or equal to 'n_classes' (20) will result in a perfect score and is therefore meaningless.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc1': 0.04,\n",
       " 'acc2': 0.07,\n",
       " 'acc3': 0.14,\n",
       " 'acc5': 0.3,\n",
       " 'acc10': 0.48,\n",
       " 'acc20': 1.0,\n",
       " 'roc_auc': 0.4810993748925897,\n",
       " 'matthews_corrcoef': -0.016189245768220034,\n",
       " 'f1': 0.030357142857142853,\n",
       " 'precision': 0.034999999999999996,\n",
       " 'recall': 0.027424242424242427,\n",
       " 'log_loss': 3.4732603841931753,\n",
       " 'balanced_accuracy': 0.027424242424242427,\n",
       " 'cohen_kappa': -0.01608806096528359,\n",
       " 'hinge_loss': 1.1724018}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_classification_metrics(torch.randint(0, 20, size=(100,)), \n",
    "                               torch.softmax(torch.randn(100, 20), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def append_dict_list(dict, name, value):\n",
    "    dict[name] = dict.get(name, []) + [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def partial_with_self(method, *args, **kwargs):\n",
    "    def wrapped(self, *additional_args, **additional_kwargs):\n",
    "        # Combine provided args and kwargs with additional ones\n",
    "        all_args = args + additional_args\n",
    "        all_kwargs = kwargs | additional_kwargs\n",
    "        return method(self, *all_args, **all_kwargs)\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
