{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心模块 Core Module\n",
    "\n",
    "> 主要定义与任务相关的核心组件和配置\n",
    "> \n",
    "> Defines core components and configurations related to tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description: \n",
    "\n",
    "核心模块包含任务相关的主要类和配置文件，如 ClassificationTask 和 ClassificationTaskConfig。其中配置文件通过 Pydantic 进行定义，帮助用户更好地构建图像分类任务的各个部分。\n",
    "\n",
    "The core module contains the primary classes and configuration files related to tasks, such as ClassificationTask and ClassificationTaskConfig, where the configurations are defined using Pydantic, allowing users to easily structure components of image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- ClassificationTask: 用于处理图像分类任务的 PyTorch Lightning 模块。\n",
    "- ClassificationTask: A PyTorch Lightning module for handling image classification tasks.\n",
    "- ClassificationTaskConfig: 使用 Pydantic 设计的配置类，用于初始化任务。\n",
    "- ClassificationTaskConfig: A configuration class designed with Pydantic for initializing the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\" # TODO this is optional for Foreigners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig, ViTModel, ViTConfig\n",
    "from namable_classify.utils import print_model_pretty\n",
    "AutoModel.from_pretrained(\"google/vit-base-patch16-224-in21k\").training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel\n",
    "class ClassificationModelConfig(BaseModel):\n",
    "    provider: str = \"huggingface\"\n",
    "    checkpoint: str = \"google/vit-base-patch16-224-in21k\" # TODO 支持 hf  timm torch\n",
    "    head_strategy: str = \"linear\"\n",
    "    num_of_classes: int = -1\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel, AutoConfig, ViTModel, ViTConfig\n",
    "from transformers import AutoImageProcessor, BitImageProcessor, ViTImageProcessor\n",
    "\n",
    "class HuggingfaceModel(nn.Module):\n",
    "    \"\"\"Some Information about HuggingfaceModel\"\"\"\n",
    "    def __init__(self, config : ClassificationModelConfig, forward_with_hf_image_preprocessor=False):\n",
    "        super().__init__()\n",
    "        # self.image_preprocessor = BitImageProcessor.from_pretrained(config.model_checkpoint, use_fast=True)\n",
    "        self.image_preprocessor = AutoImageProcessor.from_pretrained(config.checkpoint)\n",
    "        self.backbone: ViTModel = AutoModel.from_pretrained(config.checkpoint) # TODO we now just consider ViTModel\n",
    "        self.backbone.train()\n",
    "        self.backbone_config: ViTConfig = self.backbone.config # 包括了 image_size 和 hidden_size 这两个重要信息\n",
    "        if config.head_strategy == \"linear\":\n",
    "            self.head = nn.Linear(self.backbone_config.hidden_size, config.num_of_classes)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only linear head is supported for now. \")\n",
    "        self.config = config\n",
    "        self.forward_with_hf_image_preprocessor = forward_with_hf_image_preprocessor\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        if self.forward_with_hf_image_preprocessor:\n",
    "            x = self.image_preprocessor(images=x, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "        hf_output = self.backbone(x)\n",
    "        # hidden_state = hf_output.last_hidden_state\n",
    "        output = hf_output.pooler_output\n",
    "        output = self.head(output)\n",
    "        return output\n",
    "    \n",
    "from fastcore.basics import patch\n",
    "@patch\n",
    "def get_cls_model(self:ClassificationModelConfig):\n",
    "    if self.provider == \"huggingface\":\n",
    "        return HuggingfaceModel(self)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only huggingface is supported for now. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from pydantic import BaseModel\n",
    "from namable_classify.data import ClassificationDataConfig, ClassificationDataModule\n",
    "\n",
    "class ClassificationTaskConfig(BaseModel):\n",
    "    experiment_index: int = 0  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 表示是第几次重复实验 # which is also the random seed\n",
    "    label_smoothing: float = 0.1\n",
    "    cls_model_config: ClassificationModelConfig = ClassificationModelConfig()\n",
    "    dataset_config: ClassificationDataConfig = ClassificationDataConfig()\n",
    "    learning_rate: float = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS, STEP_OUTPUT, OptimizerLRScheduler\n",
    "from overrides import override\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from namable_classify.utils import print_model_pretty\n",
    "from namable_classify.utils import partial_with_self, append_dict_list, compute_classification_metrics, ensure_array, logger\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "class ClassificationTask(L.LightningModule):\n",
    "    def __init__(self, config: ClassificationTaskConfig)->None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(config.model_dump())\n",
    "        L.seed_everything(config.experiment_index) # use index as the seed for reproducibility\n",
    "        # 首先数据是可以加载的\n",
    "        self.lit_data:ClassificationDataModule = config.dataset_config.get_lightning_data_module()\n",
    "        # 数据怎么做Transform，取决于 Model的情况\n",
    "        # 现在我们加载Model，刚才有了数据之后，首先可以更新 cls_model_config\n",
    "        \n",
    "        config.cls_model_config.num_of_classes = self.lit_data.num_of_classes\n",
    "        self.cls_model:HuggingfaceModel = config.cls_model_config.get_cls_model()\n",
    "        \n",
    "        # 现在需要更新数据\n",
    "        self.lit_data.set_transform_from_hf_image_preprocessor(hf_image_preprocessor=self.cls_model.image_preprocessor)\n",
    "        \n",
    "        model_image_size:tuple[int, int] = (self.cls_model.image_preprocessor.size['height'], self.cls_model.image_preprocessor.size['width'])\n",
    "        self.example_input_array = torch.Tensor(1, self.cls_model.backbone.config.num_channels, *model_image_size)\n",
    "        \n",
    "        # 最后是训练策略\n",
    "        self.softmax = nn.Softmax(dim=1)    \n",
    "        self.loss = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
    "        # nn.LogSoftmax(dim=1)\n",
    "        # https://blog.csdn.net/qq_43391414/article/details/118421352 logsoftmax+nll的速度快，但是没有label smoothing\n",
    "        \n",
    "        # 评价策略\n",
    "        self.evaluation_steps_outputs = dict()\n",
    "    \n",
    "    def compute_model_logits(self, image_tensor:torch.Tensor)-> torch.Tensor:\n",
    "        return self.cls_model(image_tensor)\n",
    "    \n",
    "    @override\n",
    "    def forward(self, image_tensor:torch.Tensor, *args, **kwargs)-> torch.Tensor:\n",
    "        return self.softmax(self.compute_model_logits(image_tensor))\n",
    "\n",
    "    def forward_loss(self, image_tensor: torch.Tensor, label_tensor:torch.Tensor)->torch.Tensor:\n",
    "        probs = self(image_tensor)\n",
    "        # return F.nll_loss(logits, label_tensor)\n",
    "        return self.loss(probs, label_tensor)\n",
    "    \n",
    "    @override\n",
    "    def training_step(self, batch, batch_idx=None, *args, **kwargs)-> STEP_OUTPUT:\n",
    "        loss = self.forward_loss(*batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    @override    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # return L.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    # 现在我们已经定义好Training的逻辑了，已经可以跑训练了。然而，除了训练之外，我们需要评测模型的性能。\n",
    "    # @override\n",
    "    # def \n",
    "    def on_evaluation_epoch_start(self, stage:str=\"\"):\n",
    "        self.evaluation_steps_outputs = dict()\n",
    "        self.evaluation_steps_outputs[f'{stage}_batch_probs'] = []\n",
    "        self.evaluation_steps_outputs[f'{stage}_label_tensor'] = []\n",
    "            \n",
    "    def evaluation_step(self, batch, batch_idx=None, stage:str=\"\", *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "        image_tensor, label_tensor = batch\n",
    "        batch_probs = self(image_tensor)\n",
    "        append_dict_list(self.evaluation_steps_outputs, f'{stage}_batch_probs', ensure_array(batch_probs))\n",
    "        append_dict_list(self.evaluation_steps_outputs, f'{stage}_label_tensor', ensure_array(label_tensor))\n",
    "        batch_loss = self.loss(batch_probs, label_tensor)\n",
    "        self.log(f\"{stage}_loss\", batch_loss, prog_bar=True)\n",
    "        return batch_loss\n",
    "            \n",
    "    def on_evaluation_epoch_end(self, stage:str=\"\"):\n",
    "        # https://github.com/Lightning-AI/pytorch-lightning/discussions/9845\n",
    "        # labels = self.lit_data.classes\n",
    "        labels = list(range(self.lit_data.num_of_classes))\n",
    "        # labels = None\n",
    "        # print(labels)\n",
    "        # stack 是 new axis， concat是existing axis\n",
    "        all_pred_probs = np.concatenate(self.evaluation_steps_outputs[f'{stage}_batch_probs'])\n",
    "        all_label_tensor = np.concatenate(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n",
    "        # logger.debug(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n",
    "        # logger.debug(all_label_tensor)\n",
    "        eval_dict = compute_classification_metrics(all_label_tensor, all_pred_probs, logits_to_prob=False, \n",
    "                                                labels=labels)\n",
    "        eval_dict = {f\"{stage}_{k}\": v for k,v in eval_dict.items()}\n",
    "        self.log_dict(eval_dict)\n",
    "        self.evaluation_steps_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        return self.on_evaluation_epoch_start(stage=\"val\")\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        return self.on_evaluation_epoch_start(stage=\"test\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        return self.on_evaluation_epoch_end(stage=\"val\")\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        return self.on_evaluation_epoch_end(stage=\"test\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        return self.evaluation_step(batch, batch_idx, stage=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx=None):\n",
    "        return self.evaluation_step(batch, batch_idx, stage=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">cls_model </span><span style=\"color: #008000; text-decoration-color: #008000\">(HuggingfaceModel)</span>\n",
       "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">backbone </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTModel)</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "    │   │       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "    │   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "    │   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "    │   │           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "    │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">head </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[100, 768] bias:[100]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "└── \u001b[37mcls_model \u001b[0m\u001b[32m(HuggingfaceModel)\u001b[0m\n",
       "    ├── \u001b[37mbackbone \u001b[0m\u001b[32m(ViTModel)\u001b[0m\n",
       "    │   ├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "    │   │   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "    │   │       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "    │   │       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "    │   │           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "    │   │           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "    │   │           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "    │   │           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "    │   │           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "    │   │           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   │           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   ├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    │   └── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "    └── \u001b[37mhead \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[100, 768] \u001b[0m\u001b[36mbias:[100]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = ClassificationTaskConfig()\n",
    "config\n",
    "cls_task = ClassificationTask(config)\n",
    "cls_task.print_model_pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 02:28:17.226\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 02:28:36.570\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Batch size 128 failed, trying batch size 96\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 02:28:43.353\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "Batch size 96 failed, trying batch size 80\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 02:28:52.788\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 80 succeeded, trying batch size 88\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 02:29:03.951\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 88)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = L.Trainer()\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "tuner = Tuner(trainer)\n",
    "found_batch_size = tuner.scale_batch_size(cls_task, datamodule=cls_task.lit_data, \n",
    "                                          mode='binsearch', \n",
    "                                          init_val=64)\n",
    "found_batch_size, cls_task.lit_data.hparams.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "\u001b[32m2024-10-16 01:57:11.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mon_evaluation_epoch_end\u001b[0m:\u001b[36m88\u001b[0m - \u001b[34m\u001b[1m[array([53, 61, 98, 87, 64, 24, 75, 96, 83, 91, 87, 51, 39, 33, 94, 65, 16,\n",
      "       30, 53, 14, 36, 61, 22, 88, 51, 97, 10,  5, 63, 74, 17, 37, 21,  5,\n",
      "       68, 99, 14,  4, 35,  4, 20, 57, 19, 19, 41, 61, 10, 59, 86, 73, 35,\n",
      "       58,  9,  4, 24, 46, 21, 60, 25,  2, 39, 40, 64, 16, 85, 88, 16, 61,\n",
      "       68, 79, 20, 72,  3, 69, 93, 96, 30, 96, 57, 63,  6, 45, 85, 29, 14,\n",
      "       25, 43, 13, 28,  8, 95]), array([18, 48, 71, 25, 68, 35, 24, 93, 82, 93, 10, 63, 51, 35, 86, 84, 37,\n",
      "       82, 81, 14, 34,  4, 56, 94, 13,  9, 59, 57, 23, 44, 14, 39, 30, 88,\n",
      "       25, 87, 65, 77, 65, 92, 72, 13, 81, 13, 73, 86,  2, 24, 77, 24, 42,\n",
      "       72, 26, 82, 47, 84, 18, 65, 75, 74, 38, 27, 63, 45,  1, 96, 18, 15,\n",
      "       99, 18, 78, 17, 41, 34, 79, 57, 12, 45,  5, 53, 65, 82, 46, 33, 36,\n",
      "       39, 65, 73, 89, 29,  2]), array([72, 85, 15, 36, 60, 36, 93,  3, 71, 49, 36, 13, 23, 89, 79,  7, 29,\n",
      "       15, 40, 92, 62, 21, 38, 33, 61, 88, 88, 48,  3, 12, 10, 80, 18,  0,\n",
      "       20, 46,  8, 12, 51, 87,  5, 59,  8, 62,  0, 11, 81, 83, 73, 62, 98,\n",
      "       78, 71, 54, 97, 53, 46, 20, 25, 87, 98, 84, 32,  5, 99, 58, 57, 34,\n",
      "       14, 49, 73, 53, 67, 41, 16, 56, 77, 27, 25, 98, 40, 10, 91, 86, 23,\n",
      "       54, 58, 15, 81, 17, 54]), array([59, 70, 56, 61, 55, 12, 55, 68, 12, 93,  6, 46, 64, 43, 45,  1, 44,\n",
      "       84, 35, 69, 32,  9, 78, 51,  6, 43, 49, 69, 74,  1, 94, 82, 58, 52,\n",
      "       59, 88, 21, 82, 22, 87, 82, 34,  7, 59, 49, 49, 88, 89, 31, 11, 42,\n",
      "       91, 67, 70,  1, 70, 14, 83, 67, 17, 99, 51, 18,  1, 64, 57, 97, 29,\n",
      "       19,  3, 71, 55, 32, 23,  3,  6, 89, 86, 26, 74, 38, 84, 79,  6, 10,\n",
      "       56, 23, 97, 83, 59,  2]), array([19, 81, 95, 72, 81, 18, 99, 18, 34, 10, 27,  4, 90, 65, 46, 15, 12,\n",
      "       58, 69, 21, 30, 11,  1, 14, 72, 56, 25, 59, 61, 43,  4, 21, 10, 69,\n",
      "        4, 75, 93, 15, 51, 90, 79, 80, 25, 15, 31, 57, 28, 32, 48, 88, 17,\n",
      "       30, 70,  5, 95, 99, 96,  2, 49, 98, 91, 89, 71,  0, 41, 33, 19, 85,\n",
      "       29, 46, 35, 45,  1, 89,  9, 39, 11, 41, 28, 16, 79, 57, 40, 29, 22,\n",
      "       28, 27, 95, 29, 86, 79]), array([51,  3, 31, 71, 79, 14, 31, 30, 75, 13, 28,  3, 94, 13, 25, 89, 82,\n",
      "       66, 39, 43, 94, 23,  4, 83, 24,  4, 92, 31, 88, 15, 66, 88, 58, 87,\n",
      "        6, 54, 60,  7, 22, 45, 78, 92, 15, 30, 10, 29, 75,  1, 39, 54, 11,\n",
      "       48, 86, 99, 67, 57, 92, 88, 14, 50, 16, 31, 94,  3, 83, 83, 67, 40,\n",
      "       30, 61,  2,  4, 91,  7, 12, 66, 61, 59, 26,  5,  2, 49, 99, 39, 51,\n",
      "       33, 61, 86, 18, 16, 77]), array([ 0, 92, 87, 18,  9, 16,  1,  4,  4, 98, 98, 31, 38, 16,  6,  8,  0,\n",
      "       25, 55, 20, 59, 47, 11, 86,  5, 46, 72, 20, 16, 15, 21, 15,  8, 16,\n",
      "       68, 35, 81, 62, 57, 53, 44, 63, 29, 45, 85, 57, 77, 56, 43, 76, 63,\n",
      "       34,  2, 37, 25, 61, 68, 63, 34, 38, 48, 49, 23, 84, 73, 83, 47, 54,\n",
      "       70, 22, 99, 99, 97, 15, 88,  1, 70,  0, 39, 78, 66, 57,  5, 52,  1,\n",
      "       63, 34,  2, 44, 47, 41]), array([65, 37, 67, 46, 35, 61, 71, 55, 31, 27, 92, 76, 33, 70,  1,  7, 29,\n",
      "       44,  6, 12, 87, 39, 31, 48, 43, 59,  8, 98, 87, 70, 38,  9, 58, 87,\n",
      "        1, 98, 67, 55, 23, 30, 37,  0, 49, 89, 47, 19, 57, 73, 84, 11, 31,\n",
      "       59,  5, 61, 26, 27,  9, 22, 37,  5, 70, 71, 92, 80,  6, 12, 82,  6,\n",
      "        8, 48,  0, 95, 98, 29, 83, 90, 93, 98, 46, 31,  6, 91, 50, 74, 29,\n",
      "       89, 11, 93, 52, 60, 35]), array([43, 65, 76, 43, 41, 45, 78,  8, 52, 51, 87, 15, 28, 31, 23, 95, 55,\n",
      "       51, 70, 62, 31, 90, 56, 72, 97, 89,  0, 75, 36, 61, 18, 52, 92, 44,\n",
      "       98, 19, 23,  0, 94, 72, 60, 11, 84, 18, 38, 99, 45, 97,  4, 62, 37,\n",
      "       80, 36, 11, 30, 32, 18, 77, 37,  3, 11, 11, 55,  9, 15, 20, 92, 79,\n",
      "       34, 10, 17, 99, 33, 89, 52, 65, 25, 39, 77, 73, 55, 45,  0, 39, 60,\n",
      "       33, 16, 26, 57, 62, 53]), array([14, 51, 98, 62, 45, 68, 67, 25,  2, 33, 61, 61, 11, 25, 80, 19, 29,\n",
      "       20, 76, 67, 93, 89, 39, 88, 41, 28, 78, 22, 73,  7, 96, 31,  9, 86,\n",
      "       14, 59, 61, 86, 27, 63, 41, 40, 42, 92, 49,  1, 65,  1, 44, 54, 66,\n",
      "       89, 92, 23,  4, 77, 91, 42, 47, 47, 38, 40, 66, 29, 28, 58, 43, 46,\n",
      "       27, 52, 73, 58, 34, 90, 84,  0, 13, 99, 32, 22, 11, 78, 29, 43, 29,\n",
      "       79, 78, 80, 38, 91, 14]), array([84, 50, 70, 32, 45, 95, 85, 60, 97, 90, 72, 47, 42,  0,  0, 68, 88,\n",
      "       42, 74, 47,  9, 26, 70, 79, 58,  6, 39, 56, 38,  0,  0, 86, 98, 49,\n",
      "       56,  7, 29, 52, 48, 93, 76, 30, 31, 91, 21, 22, 57, 52, 90, 59, 81,\n",
      "       58, 98, 40, 47, 75, 20, 80, 29, 99, 18, 59, 35, 10, 13, 30, 58, 40,\n",
      "       19, 55, 26, 75, 90, 59, 61, 63, 69, 33, 68, 60, 58, 77, 27, 33, 27,\n",
      "       41, 87, 62, 85, 84, 90]), array([76, 62, 86, 74, 52, 76,  4,  4, 87, 13, 23,  8, 41, 40, 43, 96, 17,\n",
      "       68, 45, 37,  2, 83,  9, 77, 29, 77, 36, 67, 35, 46, 87, 97, 95, 59,\n",
      "       46, 45, 36,  2, 70, 13, 97,  1, 46, 24, 13,  2, 42, 93, 59, 24, 35,\n",
      "       21, 95,  6, 27, 68, 61, 38, 32, 62, 30, 90, 49, 78,  8,  2, 19, 23,\n",
      "       69, 92,  5, 86, 10, 36, 46, 59, 83, 39, 43, 90, 52, 32, 57, 31, 47,\n",
      "        0, 29,  7, 35, 72, 82]), array([77, 78, 67, 39, 63, 98, 57, 59, 13, 42, 25, 24, 62,  3, 78, 70,  3,\n",
      "       10, 26, 65, 83, 25, 52, 14, 89, 85, 45, 34, 22,  1, 31, 64, 49, 42,\n",
      "        7, 89, 84, 20, 62, 56, 12, 79, 89, 65, 78, 31, 82, 71,  7, 84, 34,\n",
      "       52, 65, 72, 11, 83, 90, 76, 18, 43, 78, 26, 39, 45, 38, 92, 68, 53,\n",
      "       70, 81, 92, 38, 23, 69, 39, 29, 35, 91, 66, 68, 86, 57, 53, 67, 68,\n",
      "       68, 58, 16, 40,  3, 49]), array([46, 35, 53, 49, 42, 62, 20, 24, 70, 26, 43, 48, 90, 50, 72, 41,  4,\n",
      "        4, 28, 64, 73, 89,  8,  4, 51, 85, 42, 95, 10, 12,  2, 35, 95, 26,\n",
      "       12, 83, 16, 19, 91,  3, 52, 31,  9, 99,  2, 99,  6, 73, 96, 43, 97,\n",
      "        9, 74, 69, 43, 83, 84, 19, 67, 86, 24, 88, 69, 53, 98,  9, 21, 30,\n",
      "        6, 37, 37, 86, 14,  1, 76, 95, 72, 81, 31, 58, 45, 68, 54, 69, 44,\n",
      "       42, 98, 56, 81,  7, 71]), array([58, 69, 77, 21, 65, 56, 85, 25, 23, 13, 64, 68, 96, 10, 78, 84, 82,\n",
      "       65, 93, 22, 27, 62, 33, 24, 13, 26, 36, 81, 90, 77, 92, 42, 99, 79,\n",
      "       20, 21, 75, 81, 13, 91, 98, 10, 85, 84, 94, 90,  8, 86, 11, 88, 31,\n",
      "       74, 55, 65, 68, 53,  2, 59, 43, 49, 38, 82, 58, 78,  7,  7, 26,  2,\n",
      "       42,  8, 79, 58, 10, 32,  8, 51, 92, 53, 32,  0, 18,  3, 35, 76, 84,\n",
      "       77, 13, 87, 97, 35, 90]), array([31, 66, 11, 29, 12,  0, 21, 97, 70, 63, 42, 99, 23, 68, 75, 84,  1,\n",
      "       16, 39, 50, 28, 88, 92, 99, 64, 53,  0, 50, 20, 85, 17, 99, 25, 29,\n",
      "       41, 40, 78, 29, 70, 28, 33, 71, 89, 17, 69, 59, 88, 16, 65, 32, 82,\n",
      "       11, 14, 33, 48, 57,  3, 69, 81, 66, 78, 52, 64, 45, 23, 14, 66, 76,\n",
      "       25, 47, 96, 49, 22, 60, 24, 55, 62, 50, 52, 74, 20, 22, 71, 29, 89,\n",
      "        8, 72,  3, 48, 11, 26]), array([52, 14, 85, 28,  6, 32, 66, 77, 77, 82, 81, 27,  1, 96,  7, 48, 75,\n",
      "       37,  5, 70, 20, 99, 90, 43, 29, 30, 54, 46, 44,  6, 63, 22, 22, 93,\n",
      "        8, 98, 49, 53, 29, 41, 23,  1, 49, 57, 75, 19,  8, 51, 43, 20, 60,\n",
      "       12, 11, 10, 14, 58,  0, 56, 69, 20, 43, 17, 13, 42,  0,  7, 54, 54,\n",
      "       45, 25, 35, 47,  0, 16, 94, 25, 58, 72, 95, 93, 44, 42,  8, 74, 69,\n",
      "       49, 87, 40, 14,  1, 70]), array([69, 14, 44,  0, 30, 48, 17, 47, 34,  3, 19, 27,  1, 58, 85,  7, 85,\n",
      "       58, 66, 79, 58, 50, 32,  6, 62, 14, 93,  3, 65, 85, 38, 97, 72,  5,\n",
      "        2, 35, 64, 22, 79,  4, 60, 25, 90, 16, 71, 44, 85, 54, 85, 56, 98,\n",
      "       42, 97, 10, 21,  6, 26, 37, 46, 82, 29, 39, 49, 69, 88, 28,  9, 72,\n",
      "       65, 11, 53, 84, 59, 51, 64, 27, 92, 23, 73, 16, 33, 65, 53, 64, 67,\n",
      "       20, 46, 17, 62, 74, 48]), array([77,  5,  0, 74, 18, 62, 37, 48, 28, 94, 45, 59, 21,  8, 90, 17, 96,\n",
      "       98, 87, 17, 80, 75, 40, 13, 46, 69, 19, 13, 28,  9, 57, 87, 97, 32,\n",
      "       24, 88,  0, 44, 52, 70, 41, 48, 17, 61, 63, 53, 20, 71, 59,  5, 42,\n",
      "       99, 14, 65, 71, 62,  3, 38,  2, 26, 61, 98, 83, 88,  8, 19, 42,  3,\n",
      "       16, 30, 82, 10, 80, 73, 74, 64, 40, 40, 48, 55, 17,  3, 27, 50, 61,\n",
      "       61, 83, 92, 82, 27, 75]), array([94, 47, 49, 13,  0, 68, 32, 54, 40, 38, 64, 29, 24, 58, 38, 10,  3,\n",
      "       13, 77, 34, 21, 34, 51, 97, 22,  3,  9, 25, 97, 37, 56, 80, 62, 11,\n",
      "       76, 60, 32, 22, 40, 32, 16, 88, 97, 29, 58, 28, 11, 23, 47, 96, 28,\n",
      "       11,  5, 70, 69, 82, 95, 30, 55, 87, 33, 57, 90, 77, 73, 21, 94, 38,\n",
      "       49, 42, 81, 65, 82, 63, 53, 54, 36, 83, 28, 88, 68, 75, 97,  3, 50,\n",
      "       49, 31, 35, 18, 63, 18]), array([32, 36, 44, 73, 97, 44, 83, 33,  9, 51, 51, 86, 41, 78,  7, 26, 65,\n",
      "       40, 42, 17, 27, 41, 43, 54, 43, 85, 54, 52, 38,  8, 91, 98, 85, 68,\n",
      "       90, 65, 29, 88, 41, 12, 93, 95, 50, 60, 93, 51, 22,  6, 76, 73, 24,\n",
      "        7, 13, 98, 80, 16, 33, 52, 67, 42, 17, 22, 94, 79, 46, 56, 86, 52,\n",
      "       86,  7, 93,  1, 66, 69, 12, 47, 91, 62, 85, 57, 89,  2, 86, 79, 73,\n",
      "       57, 68, 77,  7, 10, 50]), array([66, 81, 12, 92, 96, 92, 33, 25, 19, 85, 87, 88, 22, 70, 40, 62, 13,\n",
      "       57, 98, 26, 17, 79, 39, 50, 14, 22, 29, 70, 21, 30,  1,  8,  5, 90,\n",
      "       23, 51, 86, 95, 98, 45, 21, 41, 75,  0,  3, 20, 54, 93, 86, 25, 58,\n",
      "       11, 75, 41,  1, 84, 96, 20, 56, 91, 69, 63, 49,  9, 67, 90, 93, 25,\n",
      "       86,  6, 24, 72,  9, 55,  8, 88, 42, 36, 51, 99, 94, 72, 92, 40, 89,\n",
      "       89, 48,  2,  9, 67,  9]), array([88, 22, 92, 17, 33, 86, 76, 58, 92, 99, 16, 38, 91,  6, 49, 54, 93,\n",
      "        6, 38, 79, 59, 23, 63, 17, 41,  7, 23, 42, 99,  9,  6, 55, 39,  8,\n",
      "        2, 95,  1, 13, 10, 15, 88, 78, 93, 19,  7,  2, 12, 16, 60, 22, 52,\n",
      "        9, 84, 31, 14, 58, 74, 47, 41, 51, 53, 81, 63, 88, 64, 82, 22,  5,\n",
      "       80, 14, 39,  5, 55, 63, 41, 90, 30, 86, 65, 98,  0, 51,  1, 33, 62,\n",
      "       84, 83, 94, 48, 36, 91]), array([56, 69, 55, 24,  4, 99, 86, 35, 56, 12, 84, 83, 89, 77,  4, 39,  0,\n",
      "        5, 33, 60, 65, 75, 37, 55, 60, 38, 41, 92, 40, 17, 96, 99, 95, 95,\n",
      "       31, 42, 73,  5, 35, 65, 34, 30, 69, 58, 40, 25,  8, 93, 94, 44,  5,\n",
      "       38, 76, 20, 10, 61, 70, 76, 84, 10, 61,  4, 47, 13, 24, 88, 81, 67,\n",
      "       13, 57, 38,  9,  2, 75, 12, 30, 89, 50,  6, 77,  6, 75, 98, 77, 88,\n",
      "       84, 29, 70, 39, 36, 26]), array([23, 70, 11, 70, 93, 49,  6, 73, 85, 40, 37, 62, 48, 42, 31,  9, 42,\n",
      "        0, 78, 23, 85, 45, 18, 59, 69, 44, 13, 26, 71, 32, 36, 71, 72, 23,\n",
      "       99, 14, 57, 24, 72, 75, 90,  0,  9, 51, 63, 15, 17, 91, 96, 53, 73,\n",
      "       58, 11, 77,  2, 78, 27,  1, 44, 34, 43, 43, 23, 92, 89, 61, 16, 94,\n",
      "        2, 27, 85, 14, 56,  3, 33,  7, 55,  2,  8, 82, 42, 71, 72, 28, 13,\n",
      "       42, 34, 46, 14, 48, 27]), array([10, 74, 15, 33,  3, 25,  2, 30, 49, 25, 71, 16, 29, 92, 97,  6,  9,\n",
      "       95, 81, 70, 31, 40, 83, 75, 83, 83, 94, 42, 32, 65, 60,  0, 21, 12,\n",
      "       93, 31, 89, 38, 53, 14, 63, 45, 55, 50, 34, 35, 90, 91, 30, 18, 83,\n",
      "       19,  6, 30, 45, 42,  5, 61, 10, 18, 17, 93, 50, 97, 81, 59, 68, 14,\n",
      "       13,  2, 93,  7, 91, 56, 51, 13, 72, 37,  0, 60,  9, 22, 73, 56, 32,\n",
      "       16, 42, 57, 37, 27,  6]), array([67, 21, 87, 95, 59,  9, 99, 58, 94, 83, 54, 28, 27, 74, 35, 59, 41,\n",
      "       19, 20, 63, 47, 25, 84, 65, 31, 99, 49, 62, 16, 81, 30, 52, 36, 52,\n",
      "       92, 33, 49, 38,  5, 24, 67, 84, 12, 89, 90, 78, 13, 68, 20, 56, 85,\n",
      "        6, 52, 11,  8, 12, 21, 65, 22, 93, 91, 20, 60, 84, 90, 93, 22, 28,\n",
      "       99, 78,  6,  7,  4,  0, 74, 99, 10, 50, 81,  0,  3, 13, 14, 38, 25,\n",
      "       86, 55, 80, 84, 65, 92]), array([82,  5, 71, 70, 71, 52, 32, 69,  5, 43, 14, 73, 58, 36, 98, 59, 50,\n",
      "       25, 18, 54, 28,  8, 88, 96, 33, 55, 19, 32, 98, 91, 91, 65, 53, 56,\n",
      "       86, 63, 69, 97, 35, 44, 65, 57, 99, 53, 30, 99, 23, 59, 80, 49, 88,\n",
      "        4, 43, 97, 73,  7, 10, 55,  5, 44, 77, 60, 34, 58, 78, 19,  6, 66,\n",
      "       19, 61, 54, 68, 13, 33, 67, 35, 97, 88, 31, 63, 92, 97, 45, 86,  3,\n",
      "       75, 46, 70, 76, 44, 76]), array([67, 10, 72, 12, 64,  7, 52, 94, 26, 44,  2, 67, 33,  0, 62, 70, 60,\n",
      "        9, 73, 87, 57, 66, 35,  5, 80, 90, 96, 40,  7, 65, 99, 86, 70, 16,\n",
      "       26, 17, 52, 84,  2, 20, 28, 90, 40, 26, 80, 51, 60, 52, 66, 59, 73,\n",
      "       71, 55, 77, 95, 96,  4, 13, 49, 34, 28, 83, 12, 87, 97, 87, 79, 45,\n",
      "       51, 26, 36, 16, 73, 47,  6, 28, 40, 53, 74, 25, 79, 12, 98, 75, 69,\n",
      "       74, 22, 55, 87, 67, 15]), array([29, 68, 39, 10, 15, 49, 22, 86, 85, 49, 57, 89, 18, 33, 45, 67, 93,\n",
      "       51, 78, 50, 62, 80, 35, 15, 96, 79, 11, 53, 33, 16, 76, 93, 75, 45,\n",
      "       27, 51, 41,  2, 63, 51, 12, 20, 83, 69, 62, 69, 54, 67, 40, 64, 37,\n",
      "       89, 47, 63, 94, 18, 58,  8, 69, 59, 93, 62, 98,  8, 85, 78, 78, 98,\n",
      "       79, 22, 53, 49, 27, 93, 73,  7, 77, 56, 31, 23, 44, 24, 57, 29, 90,\n",
      "       37,  0, 56, 70, 21, 28]), array([61, 79, 11, 97, 98, 26, 44, 82, 88, 41, 20,  3, 55, 62, 86,  8, 51,\n",
      "       96, 16, 66, 73, 81, 24, 62, 79, 23, 94, 55, 71, 10, 82, 49, 31, 75,\n",
      "       65, 41, 65, 23,  9, 74, 94, 52, 18, 56,  7, 95, 39, 61, 58, 36, 66,\n",
      "        8, 39,  1, 29, 26, 96, 20, 33, 55,  1, 88, 54, 84, 53, 38, 62, 14,\n",
      "       31, 98, 53, 27, 13, 16, 98, 66,  4, 73, 52, 72, 56, 74, 17, 87, 49,\n",
      "       43,  0, 40, 61, 94, 10]), array([84, 56, 28, 52, 80, 24, 21, 32, 16, 10, 27, 47, 78, 20, 59, 97, 12,\n",
      "       42, 69, 17, 62, 50, 65,  2,  0, 11, 93, 18, 32, 85, 57, 58, 13, 93,\n",
      "       58,  4, 59, 35, 73, 21, 50, 64, 67, 50, 71, 20,  3,  6, 70, 76, 67,\n",
      "       71, 77, 33, 99, 31, 27, 16,  2, 61, 36, 88, 88, 98, 20, 23, 85, 16,\n",
      "       20, 90, 47,  5, 51, 48, 53, 88, 83, 32, 39, 15, 32, 41, 40, 63, 11,\n",
      "       29, 27, 72, 75,  0, 15]), array([78, 16, 75, 78, 21, 85, 31,  7, 47, 29, 13, 84, 46, 58, 42, 46, 16,\n",
      "        2, 36, 71, 99,  6, 53, 26, 88, 64, 45, 96, 38, 72, 41, 90,  9, 21,\n",
      "       79, 60, 45, 36, 60, 42, 90, 64, 35, 47,  4, 18, 85,  3, 69,  5, 46,\n",
      "        5, 40, 23, 45, 93, 97, 75, 63, 64, 43, 51, 30, 11,  4, 89, 18, 90,\n",
      "       75, 12, 27, 45, 41, 25, 33, 28,  8, 50, 76, 56, 26, 38, 27, 23, 93,\n",
      "       31, 42, 84, 81, 40, 41]), array([66, 89, 61, 94, 36, 39, 75, 85, 45, 45, 79, 51, 98,  0, 51, 71, 82,\n",
      "       86, 93, 92, 75, 50, 32, 80, 36, 72,  9,  1, 73, 88, 82,  9, 71, 28,\n",
      "       19, 20, 10, 78, 69, 88, 44, 79, 41, 51, 37, 93, 99, 55, 16, 96, 74,\n",
      "       48, 62, 22, 79,  0, 11, 84, 46, 43, 45, 82, 92, 24, 40, 16, 32, 13,\n",
      "       98, 40, 81, 71, 94, 69, 36, 39, 43, 33, 93, 68,  3,  2, 99, 13, 49,\n",
      "       31, 50, 91, 71, 24,  8]), array([68, 54, 74, 33, 34, 34, 68,  9, 47, 23, 92, 74, 47, 15, 65, 90, 85,\n",
      "       54, 39, 79, 73, 51, 50, 10, 67, 93, 79, 88,  3,  5, 30, 48, 90, 40,\n",
      "       27, 89,  3, 66, 22, 44, 18,  7, 85, 72, 13, 37, 30, 69, 28, 83, 94,\n",
      "       88, 53, 25, 71, 27, 44, 80, 97, 83, 28, 20, 13, 66, 90, 35, 53, 31,\n",
      "       15, 61, 70, 96, 93, 99, 46, 42, 91, 31, 98, 97, 24, 94, 13,  0, 15,\n",
      "       45,  9, 35,  3, 22, 90]), array([76,  2, 37, 12, 11, 86, 29,  0, 72, 99, 75, 26, 74, 50, 44, 31, 85,\n",
      "       61, 42, 93, 48, 18, 42, 32,  9, 60,  7, 26, 50, 23, 55, 79, 36, 35,\n",
      "       41, 19, 65,  0,  4, 32,  2, 97, 14, 75, 68, 74, 66, 52, 47, 66, 42,\n",
      "        5, 51, 69, 20, 65, 73, 47, 45,  9, 60, 28, 75, 59, 68, 42, 53, 32,\n",
      "       67,  9, 26, 61, 60, 59, 17, 59, 15, 94, 94, 93, 67, 77, 52, 66, 18,\n",
      "       84, 76, 83, 99, 28, 30]), array([35, 86, 24, 54, 80, 34, 75, 23,  5, 27, 16, 27, 98, 37, 35,  7, 23,\n",
      "       53, 82, 89, 99, 99, 26, 62, 23, 58, 76, 75, 49, 28, 23, 54,  7, 96,\n",
      "       96, 53, 18, 97, 47, 20, 25, 35, 66, 62, 29, 89, 16, 88, 77, 42, 18,\n",
      "        8,  3, 89, 50, 92, 32, 48, 83, 18, 90, 60, 71, 81, 90, 97, 36, 57,\n",
      "       98, 84,  6, 14,  3, 42, 89, 90, 33, 24, 15, 78, 57, 40, 45, 43, 57,\n",
      "       99, 73, 82, 73, 74, 43]), array([79,  2, 62,  5, 13, 22, 40, 68, 87,  4, 28, 97, 95,  7, 60, 58, 98,\n",
      "       83, 63, 72, 27, 22, 38, 89, 13, 45, 83, 33, 11, 47, 26, 12, 33, 13,\n",
      "       38, 87, 45, 91, 86, 42, 85,  0, 64, 21, 93, 93, 20, 42, 39,  1, 86,\n",
      "       98, 62, 38, 74, 30,  2, 71, 20, 30, 29, 26, 32, 93, 87, 60, 22,  5,\n",
      "       76, 87, 60,  8, 62, 92, 92, 34, 57, 38, 22, 64, 26, 59,  3, 24, 39,\n",
      "       34, 75, 75, 18, 60, 66]), array([41, 79, 76, 64, 67, 30, 75, 63, 70, 73, 63, 83, 21, 89, 22, 12, 93,\n",
      "       11, 44,  9, 90, 52, 47, 86, 75, 99, 83, 16, 94, 87, 31, 40, 35, 96,\n",
      "       18, 86, 37, 30, 80, 54,  7, 36, 80, 89, 56, 96, 75, 50, 67, 65, 44,\n",
      "       35, 63,  3, 28, 61, 97, 64, 63, 89, 74, 74,  0, 29, 49, 58, 86, 28,\n",
      "       48, 49, 71, 58, 56, 33, 30,  7, 98, 65, 35, 72, 51, 79, 22, 93, 11,\n",
      "       19, 35,  8, 23, 49, 66]), array([25, 33, 17, 84, 57,  6,  9,  8, 68, 72, 44, 36, 20, 54, 31, 34, 80,\n",
      "       89,  6, 28, 68, 70, 91, 91, 35, 39, 39, 91, 29, 50, 78, 51, 38, 71,\n",
      "       45, 73, 71, 77, 11, 50, 62, 88, 46, 50,  1, 57, 39, 28,  5, 37, 53,\n",
      "       33, 24, 78, 87,  5, 24, 77, 97, 29, 58, 43, 81, 26,  2, 94, 12, 69,\n",
      "       41, 12, 54, 89, 60, 17, 72, 66, 48, 63, 31, 37, 16, 46, 86, 60, 91,\n",
      "       95, 86, 79, 76, 64, 56]), array([98,  4, 13, 34, 86, 18, 80,  0, 30, 98, 43, 20, 34,  0, 95, 38, 17,\n",
      "       50, 80, 77,  8, 39, 26, 85, 60, 83, 32, 12, 37, 64, 22,  0,  2, 16,\n",
      "       72, 36, 53, 15, 41, 92, 23, 19, 21, 62, 47,  8, 57, 10, 77, 22, 75,\n",
      "       76, 78, 49, 60, 64, 68, 47, 54, 58, 68, 15, 56, 66, 46, 10, 10, 47,\n",
      "       61,  0, 92, 70, 68, 60,  5, 15, 15, 85, 53, 72,  3, 79, 94, 74, 25,\n",
      "       88, 28, 98, 59, 70, 50]), array([ 4,  5, 75, 28, 49, 54, 19, 61, 54, 67, 52, 43, 91, 62, 43, 86, 99,\n",
      "       94, 24,  0, 96, 32, 93,  2, 98, 72, 43, 78, 93, 27, 62, 59, 95, 95,\n",
      "       90, 26, 37, 76, 98, 26, 85, 94, 12, 47,  6, 73, 15, 60, 40, 58,  8,\n",
      "       30, 95, 61, 60, 35, 98, 97, 27, 44, 23, 86, 88, 55, 60, 65, 43, 23,\n",
      "       25, 18, 36, 73, 44, 88, 52, 95, 44, 63, 21, 36, 95, 69, 22, 34, 12,\n",
      "       28, 82, 19, 11, 92, 43]), array([90, 89, 37, 39, 90, 29, 28, 82, 45, 89, 91, 14, 71, 96, 14, 78, 83,\n",
      "       15, 58, 95, 99, 16,  3, 12, 37, 12,  0, 98, 78, 65, 88, 26, 96, 30,\n",
      "       73, 45, 30,  4, 13, 54, 77, 36, 67,  5, 34, 46, 93, 42, 79, 19, 65,\n",
      "       73, 88, 51, 95, 24, 68, 51, 33, 11, 35, 60, 48, 70, 40,  8, 22, 19,\n",
      "       28, 14, 97, 86,  4, 37, 23, 88, 95, 40, 27, 67, 15, 43, 82, 36, 62,\n",
      "       95, 48, 26, 16,  1, 29]), array([63,  0, 32, 79, 17, 35, 44, 90, 14, 66, 52, 31, 35, 70, 48, 19, 88,\n",
      "       39, 75,  8, 20, 49, 72, 95, 65, 60,  7, 30, 78, 12, 17, 72, 55, 96,\n",
      "       39, 38, 82, 60, 74, 22, 13, 10, 64, 42, 56, 75, 93, 42, 44, 65,  9,\n",
      "       97, 73, 83, 15, 37, 92, 30, 49, 69, 64, 44, 68, 26, 75, 39, 62, 40,\n",
      "       23, 91, 36, 73, 59, 33, 40, 46, 34,  9, 28, 97, 64, 13, 37, 50, 48,\n",
      "       78, 43, 47,  3, 93, 79]), array([99, 11, 94, 27, 65, 70, 85, 30, 34, 76, 32, 17, 94, 65, 69, 88,  3,\n",
      "       15,  9, 74, 31, 51, 63, 96,  3, 40, 35, 67, 75, 78, 96, 70, 40, 47,\n",
      "       30, 50, 94,  8, 67, 94, 78, 55, 33, 57, 37, 41,  9,  0, 92, 88, 58,\n",
      "       98, 96,  6, 74, 55, 32, 53, 63, 35, 59, 31, 30, 47, 32, 39, 91, 10,\n",
      "       79,  7, 32, 21, 64, 97, 56, 27, 88, 64, 46, 78, 70, 37, 41, 22, 53,\n",
      "       13, 13, 96, 32,  9, 33]), array([ 4,  1, 63, 89, 15, 30, 82,  0, 60, 65, 56, 41, 41, 36, 16, 58, 48,\n",
      "       73, 49, 56, 42, 72, 11, 58, 86, 75, 12, 56, 92, 19, 23, 27, 87, 17,\n",
      "       91, 33,  8, 45, 16, 42, 43, 72, 17,  7, 57, 23, 28,  0, 56,  9, 35,\n",
      "       11, 28, 26, 94,  6,  1,  9, 90, 60, 75, 79,  3, 56, 21, 50,  8, 30,\n",
      "       31, 29, 82, 60, 98, 62, 82, 48, 34,  5, 88, 57, 46, 55,  7, 15, 97,\n",
      "       57, 96, 90, 90, 71, 70]), array([60, 33, 52, 33, 36, 45, 18, 63, 85, 45, 44, 19, 57,  0, 37, 64, 74,\n",
      "        6, 91,  5,  9, 56, 51, 81, 72, 70, 10, 90, 52, 86, 51,  9, 49,  2,\n",
      "       75, 91, 63, 46,  7, 73, 22,  7, 37, 41, 18, 31, 55, 24, 65, 31, 76,\n",
      "        4, 66, 20, 73, 33, 16, 26, 65, 93, 33, 69,  1,  5, 88,  1, 92,  8,\n",
      "       29, 78, 55, 55, 79, 48, 94, 94, 59, 81, 47, 24, 95,  1, 45, 40, 64,\n",
      "       78, 43,  4, 30, 16, 18]), array([99, 65,  7, 51, 81, 28, 57, 25, 19,  9, 68, 52, 78, 38,  2, 72, 24,\n",
      "       69, 25, 19, 16, 88, 84, 58, 99, 98, 34, 16, 22, 77, 64, 32, 39, 75,\n",
      "       83, 20, 24, 64, 73, 24, 52, 62, 61, 76, 81, 59, 47, 13,  1, 26, 36,\n",
      "       91, 97, 77,  8, 44, 47, 29, 59, 60, 31, 65, 25, 11, 14, 45, 23, 15,\n",
      "       20,  6, 12, 88, 39, 72, 79, 47, 48, 28, 97, 15, 88, 48, 18, 91, 71,\n",
      "       25, 20, 73, 31, 48, 36]), array([81,  8, 28, 33, 27,  4, 36, 89, 49,  2, 27,  3, 67, 55, 78, 95, 70,\n",
      "       38, 30, 81,  4,  0, 89,  5, 87, 86, 68,  0,  1, 75, 11, 17, 69,  1,\n",
      "        1, 67, 24, 50, 18, 76, 34, 35, 66, 54, 72, 27,  3, 19, 45, 55, 31,\n",
      "       28, 67, 81, 25, 74, 75, 47, 90, 85, 57, 93, 91, 66, 59, 36, 14,  3,\n",
      "        1, 60, 94, 16, 66, 15, 39, 46, 88, 52, 80,  6, 73, 46, 49, 88, 42,\n",
      "       69, 87, 23, 91, 56, 55]), array([14, 23, 48, 42, 66, 73, 60, 77, 13, 59, 73, 21, 39, 87, 20, 73, 41,\n",
      "       32, 60, 96, 31, 51, 91, 42, 73,  6, 65,  8, 87, 18, 58, 88, 47, 12,\n",
      "       68,  2, 79, 97, 43, 60, 25, 52, 64, 66, 29, 32, 13, 23, 24, 23, 55,\n",
      "        1, 36, 43, 30, 59, 84, 69, 16, 29, 78, 21, 98, 73,  0,  0, 10, 86,\n",
      "        3, 96, 19, 34, 78, 97, 60, 20, 99, 77, 76, 23, 53, 11, 89, 40, 54,\n",
      "       55, 18, 89, 51, 63,  9]), array([ 7, 61,  6,  1, 59, 73,  8,  5, 36, 87, 44, 32,  0, 26, 73, 26, 48,\n",
      "       37, 72, 40, 96, 97, 60, 23, 65, 16, 11, 99, 80, 92, 40, 14, 74, 16,\n",
      "       35, 50, 49, 28, 43, 25, 10, 76, 51, 15, 43, 73, 66, 65, 85, 29,  3,\n",
      "       87, 10, 93, 10, 52, 28, 64, 59, 27,  6, 93, 18, 12, 83, 68,  3, 39,\n",
      "       55, 19, 86, 11, 69, 75, 43, 24, 72, 65,  4, 52, 75, 96, 73,  8,  5,\n",
      "       53, 35,  4, 97, 92, 64]), array([96, 32, 62,  6, 37, 63,  9, 44, 13, 76, 26, 10,  5, 62, 84, 79, 74,\n",
      "       33, 52, 57, 43, 10, 96,  2, 10, 66, 30, 88, 31, 77, 87, 35, 91,  6,\n",
      "       31, 68, 20, 75, 16, 26, 90,  2, 66, 31, 71, 36, 54, 27, 33, 37, 24,\n",
      "       69, 13, 98, 76, 36, 14, 92, 25, 19, 35, 85, 25, 30, 72, 98,  8, 12,\n",
      "       92, 42, 10, 91, 54, 79, 72, 15, 63, 70, 43, 57, 41, 47,  7, 12, 52,\n",
      "       78,  0, 31, 80, 67, 28]), array([33, 64, 91,  8, 66, 90, 72, 86,  2, 40, 77, 22, 76, 59, 88, 66, 72,\n",
      "       34, 20, 79, 90, 61, 72, 79, 10, 56, 29, 51, 69, 20, 78, 98, 35, 87,\n",
      "       64, 63, 72, 14, 79, 24, 75, 71, 30, 15, 88, 36, 49, 78, 89, 52, 49,\n",
      "       20,  9, 53, 35, 95, 65, 19, 24, 11, 29, 46, 30, 53, 64, 32, 48, 38,\n",
      "       52,  0, 14, 75, 70, 67, 25, 85,  9, 37, 24, 11, 34, 61, 67, 89, 31,\n",
      "       78, 77,  2, 22, 15,  8]), array([39, 68, 16, 47, 53, 37,  1, 45, 12, 58, 59, 71, 16,  5, 70, 87, 57,\n",
      "       68, 91, 43, 77, 94, 31, 43, 98, 40, 56, 61,  5, 94, 27, 24,  3, 80,\n",
      "       58, 32, 88, 42, 50, 71, 36, 24, 41, 80, 46, 90, 68, 12, 89, 77, 92,\n",
      "       25, 91, 94, 58, 36, 55, 30, 82, 36, 19, 69, 68, 97, 12, 23, 86, 82,\n",
      "        3, 65, 44, 78, 49, 79, 22, 17, 47, 92, 92, 93, 57, 26, 78, 30, 22,\n",
      "       85, 80, 69, 55, 62, 25]), array([66, 71, 53, 16, 54,  6, 85, 90, 11, 10, 60, 37, 42, 66, 39, 77,  0,\n",
      "       56, 24, 31, 20,  4, 75, 54, 58, 82, 83, 72, 64, 15, 37, 66, 11, 75,\n",
      "        9, 35, 10, 67, 12, 34, 69, 84, 39, 72, 70, 75, 79, 58, 88, 95, 52,\n",
      "        7, 22, 77, 40, 19, 18,  0, 31, 31, 13, 89, 79, 22, 18, 29, 43, 83,\n",
      "       35, 29, 40, 14, 48, 96, 69, 30, 27, 11, 57, 73, 41, 54, 67, 38,  8])]\u001b[0m\n",
      "\u001b[32m2024-10-16 01:57:11.196\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mon_evaluation_epoch_end\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1m[53 61 98 ... 67 38  8]\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3824d81443ee46e39a3d105d8df29d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.0009549925860214355\n",
      "Restoring states from the checkpoint path at /home/ycm/repos/research/cv/cls/NamableClassify/nbs/.lr_find_ab7b2b77-ac06-4c1e-bb85-5d354d820071.ckpt\n",
      "Restored all states from the checkpoint at /home/ycm/repos/research/cv/cls/NamableClassify/nbs/.lr_find_ab7b2b77-ac06-4c1e-bb85-5d354d820071.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': [1e-08, 1.3182567385564071e-08, 1.5135612484362082e-08, 1.7378008287493757e-08, 1.9952623149688796e-08, 2.2908676527677733e-08, 2.630267991895382e-08, 3.019951720402016e-08, 3.4673685045253164e-08, 3.981071705534973e-08, 4.570881896148751e-08, 5.248074602497726e-08, 6.025595860743578e-08, 6.918309709189366e-08, 7.943282347242814e-08, 9.120108393559099e-08, 1.0471285480508999e-07, 1.2022644346174127e-07, 1.380384264602885e-07, 1.5848931924611136e-07, 1.8197008586099835e-07, 2.0892961308540398e-07, 2.398832919019491e-07, 2.7542287033381663e-07, 3.162277660168379e-07, 3.630780547701014e-07, 4.1686938347033557e-07, 4.786300923226385e-07, 5.495408738576244e-07, 6.309573444801932e-07, 7.244359600749902e-07, 8.317637711026711e-07, 9.549925860214362e-07, 1.0964781961431853e-06, 1.2589254117941667e-06, 1.4454397707459273e-06, 1.6595869074375605e-06, 1.9054607179632473e-06, 2.187761623949553e-06, 2.511886431509581e-06, 2.884031503126605e-06, 3.3113112148259103e-06, 3.801893963205612e-06, 4.36515832240166e-06, 5.011872336272723e-06, 5.754399373371571e-06, 6.606934480075958e-06, 7.585775750291836e-06, 8.709635899560806e-06, 1e-05, 1.1481536214968829e-05, 1.3182567385564076e-05, 1.5135612484362087e-05, 1.7378008287493764e-05, 1.995262314968881e-05, 2.290867652767775e-05, 2.63026799189538e-05, 3.0199517204020145e-05, 3.4673685045253154e-05, 3.9810717055349715e-05, 4.5708818961487496e-05, 5.248074602497725e-05, 6.025595860743578e-05, 6.918309709189367e-05, 7.943282347242818e-05, 9.120108393559102e-05, 0.00010471285480509002, 0.00012022644346174137, 0.00013803842646028838, 0.00015848931924611126, 0.00018197008586099826, 0.00020892961308540387, 0.000239883291901949, 0.0002754228703338166, 0.00031622776601683794, 0.0003630780547701014, 0.00041686938347033556, 0.00047863009232263854, 0.0005495408738576249, 0.0006309573444801936, 0.0007244359600749906, 0.0008317637711026704, 0.0009549925860214355, 0.0010964781961431847, 0.0012589254117941668, 0.0014454397707459273, 0.0016595869074375604, 0.0019054607179632475, 0.002187761623949553, 0.0025118864315095807, 0.0028840315031266072, 0.0033113112148259126, 0.003801893963205615, 0.004365158322401657, 0.005011872336272719, 0.005754399373371567, 0.006606934480075957, 0.007585775750291835, 0.008709635899560806, 0.01], 'loss': [2.3258300742717677, 3.1009918945109063, 3.48847308453537, 3.720789071506314, 3.8757345358901976, 3.986380770438311, 4.069279176760646, 4.133722028688504, 4.185291799650325, 4.227433125241227, 4.262529833384668, 4.29217397918291, 4.317590929927723, 4.339598414837188, 4.358854449438306, 4.37580073193795, 4.39081637539971, 4.404243397486217, 4.416348441504291, 4.42727057596635, 4.43719046804216, 4.446222072044699, 4.454494400754837, 4.46209815641023, 4.469097709896266, 4.475577902690051, 4.481577703184915, 4.487164550843696, 4.492351350642525, 4.497209443390794, 4.501742335093516, 4.505986842287543, 4.509983433240054, 4.513752115460606, 4.517270239326826, 4.520608965085518, 4.5237624177181655, 4.526740908646433, 4.529557445764211, 4.532234587107009, 4.5347819096420325, 4.537210294899866, 4.5395196040927015, 4.541709034947812, 4.543811629819558, 4.545808985003076, 4.547705083984957, 4.54953964009439, 4.551290277131782, 4.552963353272431, 4.554562747692457, 4.556082578752435, 4.557551634688109, 4.558964340725415, 4.560318087753498, 4.56162871690919, 4.56288037801756, 4.56408374857466, 4.565243336451251, 4.566356015485473, 4.567423350850684, 4.568448694577022, 4.569429722514036, 4.570374418455105, 4.571290105414179, 4.572169255754065, 4.573032330034298, 4.57385235486907, 4.5746439242147465, 4.5753988780548855, 4.576111187706242, 4.57680162568325, 4.5774147706228625, 4.578011424319713, 4.5785803992693745, 4.579086078594417, 4.579562620656903, 4.579973828759111, 4.5802700252251665, 4.580444146467838, 4.580375926975633, 4.58043003039907, 4.580355525025427, 4.579929439415402, 4.580462816801658, 4.581170675833564, 4.581761723773773, 4.582356989306, 4.582910847752491, 4.58342521750865, 4.583939696898105, 4.584467975069688, 4.5849480235834505, 4.58548218372294, 4.585971851508801, 4.586424569201925, 4.586553212639029, 4.587120292154643, 4.587893941384637, 4.588165937066641]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0009549925860214355, 0.0009549925860214355)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = tuner.lr_find(cls_task, datamodule=cls_task.lit_data, max_lr=1e-2)\n",
    "print(lr_finder.results)\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "new_lr = lr_finder.suggestion()\n",
    "new_lr, cls_task.hparams.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @patch\n",
    "# def get_early_stop_callback(self: ClassificationTask, monitor='valid_loss', min_delta=0, patience=1, mode='min'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size = cls_task.cls_model.image_preprocessor.size['height']\n",
    "# cls_task.example_input_array = torch.Tensor(1, cls_task.cls_model.backbone.config.num_channels, size, size)\n",
    "cls_task.example_input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                          | Type             | Params | Mode  | In sizes                                                                                     | Out sizes    \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | cls_model                     | HuggingfaceModel | 86.5 M | train | [1, 3, 224, 224]                                                                             | [1, 100]     \n",
      "1 | cls_model.backbone            | ViTModel         | 86.4 M | train | [1, 3, 224, 224]                                                                             | ?            \n",
      "2 | cls_model.backbone.embeddings | ViTEmbeddings    | 742 K  | train | [[1, 3, 224, 224], '?', '?']                                                                 | [1, 197, 768]\n",
      "3 | cls_model.backbone.encoder    | ViTEncoder       | 85.1 M | train | [[1, 197, 768], ['?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?'], '?', '?', '?'] | ?            \n",
      "4 | cls_model.backbone.layernorm  | LayerNorm        | 1.5 K  | train | [1, 197, 768]                                                                                | [1, 197, 768]\n",
      "5 | cls_model.backbone.pooler     | ViTPooler        | 590 K  | train | [1, 197, 768]                                                                                | [1, 768]     \n",
      "6 | cls_model.head                | Linear           | 76.9 K | train | [1, 768]                                                                                     | [1, 100]     \n",
      "7 | softmax                       | Softmax          | 0      | train | [1, 100]                                                                                     | [1, 100]     \n",
      "8 | loss                          | CrossEntropyLoss | 0      | train | ?                                                                                            | ?            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "86.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 M    Total params\n",
      "345.865   Total estimated model params size (MB)\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79008a73ad4f2ca4e7e81c1ace54e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab25a0d5c64b7f96b063399a767a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-16 02:29:31.700\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnamable_classify.utils\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m77\u001b[0m - \u001b[33m\u001b[1mAn exception occurred: Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from namable_classify.utils import runs_path\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "trainer = L.Trainer(default_root_dir=runs_path, enable_checkpointing=True, \n",
    "                    enable_model_summary=True, \n",
    "                    num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\n",
    "                    callbacks=[\n",
    "                        # EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "                        EarlyStopping(monitor=\"val_acc1\", mode=\"max\", check_finite=True, \n",
    "                                      patience=5, \n",
    "                                      check_on_train_epoch_end=False,  # check on validation end\n",
    "                                      verbose=True),\n",
    "                        ModelSummary(max_depth=3),\n",
    "                               ]\n",
    "                    , fast_dev_run=True\n",
    "                    # limit_train_batches=10, limit_val_batches=5\n",
    "                    )\n",
    "trainer.fit(cls_task, datamodule=cls_task.lit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEmbeddings) </span><span style=\"color: #008080; text-decoration-color: #008080\">cls_token:[1, 1, 768] position_embeddings:[1, 197, 768]</span>\n",
       "│   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">patch_embeddings </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPatchEmbeddings)</span>\n",
       "│       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">projection </span><span style=\"color: #008000; text-decoration-color: #008000\">(Conv2d) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3, 16, 16] bias:[768]</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTEncoder)</span>\n",
       "│   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
       "│       └── <span style=\"color: #800000; text-decoration-color: #800000\">0-11</span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTLayer)</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTAttention)</span>\n",
       "│           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">attention </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfAttention)</span>\n",
       "│           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">query,key,value</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTSelfOutput)</span>\n",
       "│           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">intermediate </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTIntermediate)</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[3072, 768] bias:[3072]</span>\n",
       "│           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTOutput)</span>\n",
       "│           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 3072] bias:[768]</span>\n",
       "│           └── <span style=\"color: #800000; text-decoration-color: #800000\">layernorm_before,layernorm_after</span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layernorm </span><span style=\"color: #008000; text-decoration-color: #008000\">(LayerNorm) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768] bias:[768]</span>\n",
       "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pooler </span><span style=\"color: #008000; text-decoration-color: #008000\">(ViTPooler)</span>\n",
       "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dense </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #008080; text-decoration-color: #008080\">weight:[768, 768] bias:[768]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mroot\u001b[0m\n",
       "├── \u001b[37membeddings \u001b[0m\u001b[32m(ViTEmbeddings) \u001b[0m\u001b[36mcls_token:[1, 1, 768] \u001b[0m\u001b[36mposition_embeddings:[1, 197, 768]\u001b[0m\n",
       "│   └── \u001b[37mpatch_embeddings \u001b[0m\u001b[32m(ViTPatchEmbeddings)\u001b[0m\n",
       "│       └── \u001b[37mprojection \u001b[0m\u001b[32m(Conv2d) \u001b[0m\u001b[36mweight:[768, 3, 16, 16] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "├── \u001b[37mencoder \u001b[0m\u001b[32m(ViTEncoder)\u001b[0m\n",
       "│   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
       "│       └── \u001b[31m0-11\u001b[0m\u001b[32m(ViTLayer)\u001b[0m\n",
       "│           ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTAttention)\u001b[0m\n",
       "│           │   ├── \u001b[37mattention \u001b[0m\u001b[32m(ViTSelfAttention)\u001b[0m\n",
       "│           │   │   └── \u001b[31mquery,key,value\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           │   └── \u001b[37moutput \u001b[0m\u001b[32m(ViTSelfOutput)\u001b[0m\n",
       "│           │       └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           ├── \u001b[37mintermediate \u001b[0m\u001b[32m(ViTIntermediate)\u001b[0m\n",
       "│           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[3072, 768] \u001b[0m\u001b[36mbias:[3072]\u001b[0m\n",
       "│           ├── \u001b[37moutput \u001b[0m\u001b[32m(ViTOutput)\u001b[0m\n",
       "│           │   └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 3072] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "│           └── \u001b[31mlayernorm_before,layernorm_after\u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "├── \u001b[37mlayernorm \u001b[0m\u001b[32m(LayerNorm) \u001b[0m\u001b[36mweight:[768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n",
       "└── \u001b[37mpooler \u001b[0m\u001b[32m(ViTPooler)\u001b[0m\n",
       "    └── \u001b[37mdense \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[36mweight:[768, 768] \u001b[0m\u001b[36mbias:[768]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_task.cls_model.backbone.print_model_pretty()\n",
    "cls_task.cls_model.backbone.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
