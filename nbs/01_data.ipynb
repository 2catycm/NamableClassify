{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载模块 Data Module\n",
    "\n",
    "<!-- > 我们支持多种数据集（如 CIFAR100、VTAB 等），将 数据加载 的逻辑拆分到单独的笔记本中，这样可以保持模块化，数据处理和训练逻辑分离，增强可维护性和扩展性。 -->\n",
    "> 处理数据加载和预处理的模块\n",
    "> \n",
    "> Handles data loading and preprocessing for datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介/Description:\n",
    "数据模块主要负责数据集的加载与预处理。DatasetConfig 使用 Pydantic 进行配置管理，以保证数据集参数的正确性，并通过 ClassificationDataModule 实现 PyTorch Lightning 的数据模块封装。此模块支持自定义数据转换，并为不同的数据集（如 CIFAR100）提供灵活的加载方案。\n",
    "\n",
    "The data module focuses on handling dataset loading and preprocessing. DatasetConfig is managed through Pydantic for configuration accuracy, and ClassificationDataModule encapsulates the PyTorch Lightning DataModule. This module supports custom data transforms and offers flexible loading schemes for various datasets such as CIFAR100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要符号/Main symbols:\n",
    "\n",
    "- DatasetConfig: Pydantic 定义的配置类，用于数据模块的参数管理。\n",
    "  \n",
    "  DatasetConfig: A Pydantic configuration class for managing data module parameters.\n",
    "\n",
    "- ClassificationDataModule: 用于 PyTorch Lightning 的数据模块封装，支持训练、验证、测试数据加载。\n",
    "  \n",
    "  ClassificationDataModule: A PyTorch Lightning DataModule wrapper supporting train, validation, and test data loading.\n",
    "  \n",
    "- CIFAR100DataModule: 基于 ClassificationDataModule 的具体数据模块实现，加载 CIFAR100 数据集。\n",
    "  \n",
    "  CIFAR100DataModule: A concrete implementation of ClassificationDataModule for loading the CIFAR100 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from namable_classify.utils import data_path, Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ClassificationDataConfig(BaseModel):\n",
    "    # protocol: str = 'torch'\n",
    "    # dataset_name: str = 'cifar100'\n",
    "    dataset_root: Path = data_path\n",
    "    dataset_name: str = 'CIFAR100'\n",
    "    batch_size:int=1\n",
    "# TODO 支持多个来源的数据集自动加载\n",
    "# from torchvision.datasets import __all__, CIFAR100\n",
    "# __all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Callable\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import lightning as L\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class ClassificationDataModule(L.LightningDataModule):\n",
    "    num_of_classes = None\n",
    "    classes = None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config:ClassificationDataConfig) -> 'ClassificationDataModule':\n",
    "        return cls(**config.model_dump())\n",
    "    def __init__(self, **config:ClassificationDataConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.save_hyperparameters(dict(num_of_classes=self.num_of_classes))\n",
    "        self.workers = 31 # TODO 根据CPU自动设置\n",
    "    #     self.__sub_init__()\n",
    "    #     # self.config = config\n",
    "    # def __sub_init__(self, a=1, b=2) -> None:\n",
    "    #     print(\"Hello\")\n",
    "    #     self.save_hyperparameters(dict(a=a, b=b))\n",
    "    # @property\n",
    "    # def num_classes(self) -> int:\n",
    "    #     return self.hparams.num_classes\n",
    "    # @num_classes.setter\n",
    "    # def num_classes(self, value:int) -> None:\n",
    "    #     self.hparams.num_classes = value\n",
    "        \n",
    "    # @property\n",
    "    # def transform(self) -> Callable: #TODO 类型标注不知道怎么写\n",
    "    #     return self.hparams.transform\n",
    "    \n",
    "    # @transform.setter\n",
    "    # def transform(self, value:Callable) -> None:\n",
    "    #     self.hparams.transform = value\n",
    "    \n",
    "    \n",
    "        \n",
    "    def train_dataloader(self)->TRAIN_DATALOADERS:\n",
    "        return DataLoader(self.train_ds, batch_size=self.hparams.batch_size, \n",
    "                          num_workers=self.workers, shuffle=True, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self)->EVAL_DATALOADERS:\n",
    "        return DataLoader(self.val_ds, batch_size=self.hparams.batch_size, num_workers=self.workers, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self)->EVAL_DATALOADERS:\n",
    "        return DataLoader(self.test_ds, batch_size=self.hparams.batch_size, num_workers=self.workers, pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self)->EVAL_DATALOADERS:\n",
    "        return DataLoader(self.predict_ds, batch_size=self.hparams.batch_size, num_workers=self.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"batch_size\":     1\n",
       "\"dataset_name\":   CIFAR100\n",
       "\"dataset_root\":   /home/ycm/repos/research/cv/cls/NamableClassify/data\n",
       "\"num_of_classes\": None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "L.seed_everything(42)\n",
    "cdm = ClassificationDataModule.from_config(ClassificationDataConfig())\n",
    "cdm.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "def sksplit_for_torch(ds_full:torch.utils.data.Dataset, test_size:float=0.2, stratify_targets=None, random_state=None):\n",
    "    indexes = list(range(len(ds_full)))\n",
    "    stratify_targets = stratify_targets or (ds_full.targets if hasattr(ds_full, 'targets') else [int(ds_full[i][1]) for i in indexes])\n",
    "    train_indexes, val_indexes = train_test_split(indexes, test_size=test_size,\n",
    "                                                    stratify=stratify_targets, random_state=random_state)\n",
    "    return torch.utils.data.Subset(ds_full, train_indexes), torch.utils.data.Subset(ds_full, val_indexes)\n",
    "    # return random_split(\n",
    "                #     ds_full, [, ], \n",
    "                #     generator=torch.Generator().manual_seed(L.seed_everything()), \n",
    "                # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_full = CIFAR100(data_path, train=True)\n",
    "train_ds, val_ds = sksplit_for_torch(ds_full, test_size=0.1)\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import lightning as L\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST, QMNIST, KMNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100, CIFAR10\n",
    "# CIFAR100.url = # Tsinghua mirrorURL\n",
    "class TorchVisionDataModule(ClassificationDataModule):\n",
    "    # 目前支持的情况是，train test两个split，没有val，需要自己分val的情况\n",
    "    torchvision_cls = CIFAR100\n",
    "    num_of_classes = 100\n",
    "    def __init__(self, \n",
    "                 train_transform=None, # 需要后续设置\n",
    "                 test_transform=None, # 需要后续设置\n",
    "                 train_val_split=0.9, # 训练集和验证集的比例\n",
    "                 **config:ClassificationDataConfig) -> None:\n",
    "        super().__init__(**config)\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    @property\n",
    "    def dataset_name(self):\n",
    "        return self.torchvision_cls.__name__\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        train_ds = self.torchvision_cls(self.hparams.dataset_root, train=True, download=True)\n",
    "        test_ds = self.torchvision_cls(self.hparams.dataset_root, train=False, download=True)\n",
    "        self.classes = train_ds.classes\n",
    "        assert len(self.classes)==self.num_of_classes, f\"Number of classes in dataset is {len(self.classes)}, but {self.num_of_classes} is expected.\"\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        match (stage):\n",
    "            case (\"fit\") | (\"validate\"):\n",
    "                # 还有个 validate 但是fit的时候我们就设置好了，所以直接跳过\n",
    "                if not hasattr(self, \"val_ds\"):\n",
    "                    ds_full = self.torchvision_cls(self.hparams.dataset_root, train=True, transform=self.hparams.train_transform)\n",
    "                    self.train_ds, self.val_ds = sksplit_for_torch(ds_full, 1-self.hparams.train_val_split, random_state=0) # 不和Lighning seed everything一起\n",
    "                else:\n",
    "                    print(\"Validation loader has been setup before. \")\n",
    "                pass\n",
    "            case (\"test\"):\n",
    "                self.test_ds = self.torchvision_cls(self.hparams.dataset_root, train=False, transform=self.hparams.test_transform)\n",
    "            case (\"predict\"):\n",
    "                self.predict_ds = self.torchvision_cls(self.hparams.dataset_root, train=False, transform=self.hparams.test_transform)\n",
    "\n",
    "class CIFAR100DataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = CIFAR100\n",
    "    num_of_classes = 100\n",
    "    \n",
    "class MNISTDataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = MNIST\n",
    "    num_of_classes = 10\n",
    "    \n",
    "class CIFAR10DataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = CIFAR10\n",
    "    num_of_classes = 10\n",
    "    \n",
    "class FashionMNISTDataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = FashionMNIST\n",
    "    num_of_classes = 10\n",
    "    \n",
    "class QMNISTDataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = QMNIST\n",
    "    num_of_classes = 10\n",
    "    \n",
    "class KMNISTTDataModule(TorchVisionDataModule):\n",
    "    torchvision_cls = KMNIST\n",
    "    num_of_classes = 10\n",
    "\n",
    "# ImageNet有所不同  \n",
    "# ？论文中 ImageNet test到底用不用\n",
    "# class ImageNetDataModule(TorchVisionDataModule):\n",
    "#     torchvision_cls = ImageNet\n",
    "#     num_of_classes = 1000\n",
    "# , EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
      "\n",
      "Args:\n",
      "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
      "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
      "        otherwise from ``t10k-images-idx3-ubyte``.\n",
      "    download (bool, optional): If True, downloads the dataset from the internet and\n",
      "        puts it in root directory. If dataset is already downloaded, it is not\n",
      "        downloaded again.\n",
      "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
      "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "    target_transform (callable, optional): A function/transform that takes in the\n",
      "        target and transforms it.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/mnist.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "# ImageNet?\n",
    "import torchvision\n",
    "torchvision.datasets?\n",
    "FashionMNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [01:38<00:00, 267649.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 212781.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/ycm/repos/research/cv/cls/NamableClassify/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 1048576/4422102 [01:08<03:41, 15219.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fashion_mnist_data \u001b[38;5;241m=\u001b[39m FashionMNISTDataModule\u001b[38;5;241m.\u001b[39mfrom_config(ClassificationDataConfig(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfashion_mnist_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fashion_mnist_data\u001b[38;5;241m.\u001b[39mhparams\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mTorchVisionDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# download\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     test_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorchvision_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mdataset_root, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mclasses\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/mnist.py:188\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download (trying next):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/utils.py:395\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    393\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 395\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/utils.py:132\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 132\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/program_files/managers/conda/envs/hf_ai/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fashion_mnist_data = FashionMNISTDataModule.from_config(ClassificationDataConfig(dataset_name='MNIST'))\n",
    "fashion_mnist_data.prepare_data()\n",
    "fashion_mnist_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"batch_size\":      1\n",
       "\"dataset_name\":    MNIST\n",
       "\"dataset_root\":    /home/ycm/repos/research/cv/cls/NamableClassify/data\n",
       "\"num_of_classes\":  10\n",
       "\"test_transform\":  None\n",
       "\"train_transform\": None\n",
       "\"train_val_split\": 0.9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = MNISTDataModule.from_config(ClassificationDataConfig(dataset_name='MNIST'))\n",
    "mnist_data.prepare_data()\n",
    "mnist_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"batch_size\":      1\n",
       "\"dataset_name\":    CIFAR100\n",
       "\"dataset_root\":    /home/ycm/repos/research/cv/cls/NamableClassify/data\n",
       "\"num_of_classes\":  100\n",
       "\"test_transform\":  None\n",
       "\"train_transform\": None\n",
       "\"train_val_split\": 0.9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100_data = CIFAR100DataModule.from_config(ClassificationDataConfig(dataset_name=\"CIFAR100\"))\n",
    "cifar100_data.prepare_data()\n",
    "cifar100_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/torchvision/datasets/cifar.py'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getfile(CIFAR100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO VTAB dataset\n",
    "# vtab_dir: str = \"/home/ai_pitch_perfector/datasets/vtab-1k/\"\n",
    "# subset_name: str = \"cifar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClassificationDataModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnamable_classify\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CutoutPIL\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patch\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@patch\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_transform_from_hf_image_preprocessor\u001b[39m(\u001b[38;5;28mself\u001b[39m:\u001b[43mClassificationDataModule\u001b[49m, hf_image_preprocessor:AutoImageProcessor, model_image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_image_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hf_image_preprocessor, ViTImageProcessor):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ClassificationDataModule' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# https://neptune.ai/blog/data-augmentation-in-python\n",
    "# https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
    "# https://sebastianraschka.com/blog/2023/data-augmentation-pytorch.html # 结论是Trivial最好\n",
    "from transformers import AutoImageProcessor, BitImageProcessor, ViTImageProcessor\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    "    RandomRotation,\n",
    "    RandomGrayscale,\n",
    "    Grayscale,\n",
    "    AutoAugment,\n",
    "    RandAugment,\n",
    "    AugMix,\n",
    "    TrivialAugmentWide,\n",
    ")\n",
    "from namable_classify.data.transforms import CutoutPIL\n",
    "from fastcore.basics import patch\n",
    "@patch\n",
    "def set_transform_from_hf_image_preprocessor(self:ClassificationDataModule, hf_image_preprocessor:AutoImageProcessor, model_image_size=None):\n",
    "    if model_image_size is None:\n",
    "        if isinstance(hf_image_preprocessor, ViTImageProcessor):\n",
    "            model_image_size:tuple[int, int] = (hf_image_preprocessor.size['height'], hf_image_preprocessor.size['width'])\n",
    "        elif isinstance(hf_image_preprocessor, BitImageProcessor):\n",
    "            model_image_size:tuple[int, int] = (hf_image_preprocessor.crop_size['height'], hf_image_preprocessor.crop_size['width'])\n",
    "    normalize = Normalize(mean=hf_image_preprocessor.image_mean, std=hf_image_preprocessor.image_std)\n",
    "    self.hparams.train_transform = Compose(\n",
    "        [\n",
    "            # # RandomResizedCrop(image_processor.size[\"height\"]),\n",
    "            # RandomResizedCrop(image_processor.crop_size[\"height\"]),\n",
    "            # RandomHorizontalFlip(),\n",
    "            # # RandomRotation((-30, 30)),\n",
    "            # # RandomGrayscale(),\n",
    "            # # AddPepperNoise(0.5, p=0.1),\n",
    "            # Grayscale(num_output_channels=3),\n",
    "\n",
    "            Resize(model_image_size),\n",
    "            # CutoutPIL(cutout_factor=1/4), # cifar 32x32  随机把中间8x8正方形变成空白 \n",
    "            # CutoutPIL(cutout_factor=0.5),\n",
    "            # RandAugment(),\n",
    "            TrivialAugmentWide(),\n",
    "            \n",
    "            # resize\n",
    "            # center_crop\n",
    "            \n",
    "            # rescale\n",
    "            # normalize\n",
    "            \n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.hparams.test_transform = Compose(\n",
    "        [\n",
    "            # Resize(image_processor.size[\"height\"]),\n",
    "            # Resize(image_processor.crop_size[\"height\"]),\n",
    "            # # CenterCrop(image_processor.size[\"height\"]),\n",
    "            # CenterCrop(image_processor.crop_size[\"height\"]),\n",
    "            # Grayscale(num_output_channels=3),\n",
    "            \n",
    "            Resize(model_image_size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values([224, 224])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, BitImageProcessor\n",
    "model_checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = BitImageProcessor.from_pretrained(model_checkpoint, use_fast=True)\n",
    "image_processor\n",
    "image_processor.crop_size.values() # height, width\n",
    "# image_processor.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.basics import patch\n",
    "@patch\n",
    "def get_lightning_data_module(self:ClassificationDataConfig):\n",
    "    if self.dataset_name == 'MNIST':\n",
    "        return MNISTDataModule.from_config(self)\n",
    "    elif self.dataset_name == 'CIFAR100':\n",
    "        return CIFAR100DataModule.from_config(self)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {self.dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"batch_size\":      1\n",
       "\"dataset_name\":    CIFAR100\n",
       "\"dataset_root\":    /home/ycm/repos/research/cv/cls/NamableClassify/data\n",
       "\"num_of_classes\":  100\n",
       "\"test_transform\":  None\n",
       "\"train_transform\": None\n",
       "\"train_val_split\": 0.9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_data = ClassificationDataConfig(dataset_name=\"CIFAR100\").get_lightning_data_module()\n",
    "lit_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"batch_size\":      1\n",
       "\"dataset_name\":    CIFAR100\n",
       "\"dataset_root\":    /home/ycm/repos/research/cv/cls/NamableClassify/data\n",
       "\"num_of_classes\":  100\n",
       "\"test_transform\":  Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")\n",
       "\"train_transform\": Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    <namable_classify.data.transforms.CutoutPIL object>\n",
       "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")\n",
       "\"train_val_split\": 0.9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_data.set_transform_from_hf_image_preprocessor(image_processor)\n",
    "lit_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/11-vision-transformer.html\n",
    "# 这里的可视化不错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
